\documentclass{article}

\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry} 

\usepackage[utf8]{inputenc}   % otra alternativa para los caracteres acentuados y la "Ã±"
\usepackage[           spanish % para poder usar el espaÃ±ol
                      ,es-tabla % para los captions de las tablas
                       ]{babel}   
\decimalpoint %para usar el punto decimal en vez de coma para los nÃºmeros con decimales

%\usepackage{beton}
%\usepackage[T1]{fontenc}

\usepackage{parskip}
\usepackage{xcolor}

\usepackage{caption}

\usepackage{enumerate} % paquete para poder personalizar fÃ¡cilmente la apariencia de las listas enumerativas

\usepackage{graphicx} % figuras
\usepackage{subfigure} % subfiguras

\usepackage{amsfonts}
\usepackage{amsmath}

\usepackage{listings}
\lstset
{ %Formatting for code in appendix
    language=python,
    basicstyle=\footnotesize,
    stepnumber=1,
    showstringspaces=false,
    tabsize=1,
    breaklines=true,
    breakatwhitespace=false,
}

\definecolor{gris}{RGB}{220,220,220}
	
\usepackage{float} % para controlar la situaciÃ³n de los entornos flotantes

\restylefloat{figure}
\restylefloat{table} 
\setlength{\parindent}{0mm}


\usepackage[bookmarks=true,
            bookmarksnumbered=false, % true means bookmarks in 
                                     % left window are numbered
            bookmarksopen=false,     % true means only level 1
                                     % are displayed.
            colorlinks=true,
            allcolors=blue,
            urlcolor=blue]{hyperref}
\definecolor{webblue}{rgb}{0, 0, 0.5}  % less intense blue

\usepackage[ruled,vlined]{algorithm2e}
\SetKwInOut{Parameter}{parameter}


\title{\Huge Metaheurísticas: Práctica 2 \\ Técnicas de Búsqueda basadas en Poblaciones \\ para el Problema de la Máxima Diversidad \vspace{10mm}}

\author{\huge David Cabezas Berrido \vspace{10mm} \\
	\huge 20079906D \vspace{10mm} \\  
  \huge Grupo 2: Viernes \vspace{10mm} \\ 
  \huge dxabezas@correo.ugr.es \vspace{10mm}}

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage

\section{Descripción y formulación del problema}

Nos enfrentamos al \textbf{Problema de la Máxima Diversidad} (\textbf{Maximum Diversity Problem, MDP}). El problema consiste en seleccionar
un subconjunto $m$ elementos de un conjunto de $n>m$ elementos de forma que se \textbf{maximice} la \emph{diversidad} entre los
 elementos escogidos.
 
 Disponemos de una matriz $D=(d_{ij})$ de dimensión $n\times n$ que contiene las distancias entre los elementos, la entrada $(i,j)$ contiene el
 valor $d_{ij}$, que corresponde a la distancia entre el elemento $i$-ésimo y el $j$-ésimo. Obviamente, la matriz $D$ es simétrica y con
 diagonal nula.
 
 Existen distintas formas de medir la diversidad, que originan distintas variantes del problema. En nuestro caso, la diversidad será la suma
 de las distancias entre cada par de elementos seleccionados.

De manera formal, se puede formular el problema de la siguiente forma:

\begin{description}
	\item Maximizar 
	\begin{equation} \label{eq:objetivo}
		f(x)=\sum_{i=1}^{n-1}\sum_{j=i+1}^n d_{ij} x_i x_j
	\end{equation}
	\item sujeto a 
	\begin{align*}
		\sum_{i=1}^n x_i &= m \\
		x_i&= \{0,1\}, \quad\forall i=1,\ldots, n.
	\end{align*}
\end{description}

Una solución al problema es un vector binario $x$ que indica qué elementos son seleccionados, seleccionamos el elemento $i$-ésimo si $x_i=1$.

Sin embargo, esta formulación es poco eficiente y para la mayoría de algoritmos proporcionaremos otra equivalente pero más eficiente.

El problema es \textbf{NP-completo} y el tamaño del espacio de soluciones es $\dbinom{n}{m}$, de modo que es conveniente recurrir al uso de metaheurísticas
para atacarlo.

\pagebreak

\section{Aplicación de los algoritmos}

Los algoritmos para resolver este problema tendrán como entradas la matriz $D$ ($n\times n$) y el valor $m$. La salida será un contenedor
(vector, conjunto, \ldots) con los índices de los elementos seleccionados, y no un vector binario como el que utilizamos para la formulación.
 En nuestro caso (algoritmos implementados en esta práctica) utilizaremos vectores de enteros para representar soluciones.

\textbf{Nota:} Al contrario de lo recomendado, mantenemos la representación entera (vector de enteros con los elementos seleccionados) en lugar de cambiar a la binaria para las soluciones.
Esto conlleva la traducción de los operadores a la nueva representación. Sin embargo, aunque la descripción detallada de los operadores es
algo más compleja, entender su funcionamiento es bastante más fácil con la representación entera. 

La evaluación de la calidad de una solución se hará
sumando la contribución de cada uno de los elementos, y dividiremos la evaluación en dos funciones. En lugar de calcular la función evaluación como en
\eqref{eq:objetivo}, lo haremos así:
\begin{equation} \label{eq:objetivo-fact}
f(x)=\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^m d(i,j)=\frac{1}{2}\sum_{i=1}^{m}\operatorname{contrib}(i)
\end{equation}
La diferencia es que contamos la distancia entre cada dos elementos $i,j$ dos veces, distancia del elemento $i$-ésimo al $j$-ésimo y del $j$-ésimo al
$i$-ésimo. Esto es obviamente más lento que con $j>i$ en la sumatoria, pero nos permite factorizar la evaluación de la solución como suma de las
 contribuciones de los elementos, lo cuál será útil para reaprovechar cálculos al evaluar soluciones para la Búsqueda Local.
 Además, representar la solución como un vector de $m$ índices y no un vector binario de longitud $n$ presenta una clara ventaja: las sumatorias van hasta
 $m$ en lugar de $n$. No tenemos que computar distancias para luego multiplicarlas por cero como sugería la formulación en \eqref{eq:objetivo}.

Presentamos el pseudocódigo de la función para calcular la contribución de un elemento $x_i$.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de índices $S$.}
	\KwIn{La matriz de distancias $D$.}
	\KwIn{Un entero $e$ correspondiente al índice del elemento.}
	\KwOut{La contribución del elemento $e$, como se describe en \eqref{eq:objetivo-fact}.}
	$contrib \gets 0$\;
	\For{$s$ \textbf{in} $S$} {
		$contrib \gets contrib + D[e,s]$ \tcp*{Sumo las distancias del elemento $e$ a cada elemento de $S$}
	}
	\Return{$contrib$}\;
	\caption{{\sc Contrib} calcula la contribución de un elemento en una solución.}
	\label{alg:contrib}
\end{algorithm}

Nótese que el elemento $e$ no tiene que pertenecer al conjunto $S$. Esto obviamente no ocurrirá cuando se vaya a evaluar una solución
al completo invocando esta función con la que describiremos a continuación. Pero, de esta forma, permite conocer cómo influirá en la evaluación el añadir
 un nuevo elemento sin necesidad de añadirlo realmente. 
 
 Ahora presentamos el pseudocódigo de la función para evaluar una solución completa.
 
 \begin{algorithm}[H]
 	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
 	\KwIn{Un vector de índices $S$.}
 	\KwIn{La matriz de distancias $D$.}
 	\KwOut{El valor de la función objetivo sobre la solución compuesta por $S$, como se describe en \eqref{eq:objetivo-fact}.}
 	$fitness \gets 0$\;
 	\For{$e$ \textbf{in} $S$} {
 		$fitness \gets fitness + \operatorname{contrib}(S,D,e)$ \tcp*{Sumo la contribución de cada elemento de la solución}
 	}
 	\Return{$fitness/2$} \tcp*{Hemos contado cada distancia dos veces}
 	\caption{{\sc Fitness} calcula la evaluación de una solución.}
 	\label{alg:eval}
 \end{algorithm}

Podemos definir la distancia de un elemento $e$ a un conjunto $S$ como:

\begin{equation} \label{eq:distance-elem-set}
	d(e,S)=\sum_{s\in S} d(e,s)
\end{equation}

Esta expresión nos será de utilidad para la implementación de los algoritmos.

Gracias a la existencia del Algoritmo \ref{alg:contrib}, podemos obtener esta expresión como $\operatorname{contrib}(S,D,e)$.

En esta práctica, implementamos cuatro variantes de algoritmos genéticos (dos generacionales y dos estacionarios) y tres variantes
de meméticos. Compararemos estos algoritmos entre sí y con los algoritmos Greedy y Búsqueda Local con Primer Mejor de la práctica anterior.

Para los pseudocódigos que siguen, suponemos la matriz de distancias $D$ y los parámetros $n$ y $m$ accesibles.
El conjunto de todos los elementos es el $\{0,\ldots,n-1\}$, para cuando nos refiramos a elementos de fuera de un subconjunto de ellos.

Inicializamos la población con soluciones aleatorias, usamos la siguiente función.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwOut{Una solución válida del MDP obtenida aleatoriamente.}
	$E \gets \{0,\ldots, n-1\}$ \tcp*{Vector con todos los elementos.}
	$\operatorname{shuffle}(E)$\;
	$S \gets \emptyset$ \tcp*{La solución empieza vacía.}
	\While{$|S|<m$}{
		$S \gets S\cup \{E[|S|]\}$ \tcp*{Seleccionamos los $m$ primeros elementos de $E$, que son aleatorios.}
	}
	\Return{$S$}\;
	\caption{{\sc RandomSol} proporciona una solución válida aleatoria}
	\label{alg:randomsol}
\end{algorithm}

\subsection{Operadores de los algoritmos genéticos}

Usaremos dos operadores de cruce distintos. El primero es el \textbf{cruce uniforme}, que dados dos padres mantiene los elementos
seleccionados por ambos (intersección) y por ninguno. Los elementos que sólo son seleccionados por uno de los padres se introducen
con un 0.5 de probabilidad, pudiendo dar lugar a soluciones con más de $m$ elementos seleccionados. Es por ello que se aplica un
\textbf{operador de reparación} posteriormente, que elimina (cuando sobran elementos) o añade (cuando faltan) siempre el elemento
que más contribuye (dentro o fuera de la solución, según haya que eliminar o añadir).

Cuando escribimos operaciones de conjuntos sobre vectores entendemos que no es relevante el orden
de los elementos. Con la unión entre un vector y un elemento, podemos añadir el elemento al final, por ejemplo.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de índices $S$.}
	\KwOut{El vector $S$ reparado (no lo devuelve, modifica el existente).}
	\While{$|S|>m$}{
		$g\gets\text{Elemento de $S$ que maximiza $\operatorname{contrib}(S,D,g)$}$\;
		$S\gets S\backslash\{g\}$\;
	}
	\While{$|S|<m$}{
		$g\gets\text{Elemento de fuera de $S$ que maximiza $\operatorname{contrib}(S,D,g)$}$\;
		$S\gets S\cup\{g\}$\;
	}
	\caption{{\sc Repair} repara un vector solución que puede no contener $m$ elementos (puede ser no válida).}
	\label{alg:reparacion}
\end{algorithm}

A continuación, proporcionamos el pseudocódigo del algoritmo de cruce uniforme.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Dos vectores de índices $S_1,S_2$.}
	\KwOut{Un vector solución $S$ (hijo).}
	$S\gets\emptyset$\;
	\ForEach{$e$ in $0,\ldots,n-1$}{
		\If{$e\in S_1$ and $e\in S_2$}{
			$S\gets S\cup\{e\}$\;
		}
		\ElseIf{$e\notin S_1$ and $e\notin S_2$}{
			No se incluye el elemento (no se hace nada).
		}
		\Else{
			Con probabilidad 0.5: $S\gets S\cup\{e\}$\;
		}
	}
	$\operatorname{repair}(S)$ \tcp*{La solución puede no ser factible.}
	\Return{$S$}
	\caption{{\sc UniformCross} genera un hijo cruzando dos padres.}
	\label{alg:uniform-cross}
\end{algorithm}

El otro operador de cruce que consideramos es el cruce basado en posición. Este operador respeta los seleccionados y descartados
por ambos padres, y completa con un subconjunto aleatorio de los elementos que sólo están seleccionados por uno de los padres hasta
obtener un vector con $m$ elementos seleccionados.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Dos vectores de índices $S_1,S_2$.}
	\KwOut{Un vector solución $S$ (hijo).}
	$S\gets\emptyset$\;
	$W\gets\emptyset$ \tcp*{Candidatos a completar la solución.}
	\ForEach{$e$ in $0,\ldots,n-1$}{
		\If{$e\in S_1$ and $e\in S_2$}{
			$S\gets S\cup\{e\}$\;
		}
		\ElseIf{$e\notin S_1$ and $e\notin S_2$}{
			No se incluye el elemento (no se hace nada).
		}
		\Else{
			$W\gets W\cup\{e\}$\;
		}
	}
	$W \gets \operatorname{shuffle}(W)$\;
	\While{$|S|<m$}{
		$e\gets W[0]$ \tcp*{Primer elemento de $W$, es aleatorio.}
		$S\gets S\cup\{e\}$\;
		$W\gets W\backslash\{e\}$\;
	}
	\Return{$S$}
	\caption{{\sc PositionCross} genera un hijo cruzando dos padres.}
	\label{alg:position-cross}
\end{algorithm}

Con la implementación que hemos hecho, ambos operadores sólo generan un hijo, por lo que llamaremos a estos operador dos veces cada vez que crucemos dos padres. Sería más eficiente generar dos hijos en cada ejecución para aprovechar parte de los cálculos.

Necesitamos también un operador de mutación. Éste saca un elemento aleatorio de una solución y mete un elemento aleatorio de fuera.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector solución $S$.}
	\KwOut{La solución $S$ modificada, la modifica en lugar de devolverla.}
	$e_{out}\gets\text{numero aleatorio entre $0$ y $m-1$}$ \tcp*{Posición del elemento a eliminar.}
	$e_{in}\gets\text{elemento aleatorio (número aleatorio entre $0$ y $n-1$)}$\;
	\While{$e_{in}\in S$}{
		$e_{in}\gets\text{elemento aleatorio}$ \tcp*{Forzamos que sea de fuera.}
	}
	$S[e_{out}]\gets e_{in}$\tcp*{Sustituimos el elemento a eliminar por el nuevo.}
	\caption{{\sc Mutate} modifica una solución cambiando un elemento.}
	\label{alg:mutate}
\end{algorithm}

Por último, necesitamos un operador de selección para elegir a los padres en cada iteración. Se hace uno de torneos binarios, donde se elige el mejor de dos soluciones aleatorias.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{El índice de la mejor solución entre dos elegidas aleatoriamente.}
	$i_1\gets\text{número aleatorio entre 0 y $|P|$}$\;
	$i_2\gets\text{número aleatorio entre 0 y $|P|$}$\;
	$sol_1\gets P[i_1]$\;
	$sol_2\gets P[i_2]$\;
	\tcc{$sol.fitness$ almacena el resultado de $\operatorname{fitness}(sol)$ por razones de eficiencia.}
	\If{$sol_1.fitness > sol_2.fitness$}{
		\Return{$i_1$}
	}
	\Else{
		\Return{$i_2$}
	}
	\caption{{\sc BinTournament} devuelve el índice de la mejor de dos soluciones aleatorias.}
	\label{alg:bin-tournament}
\end{algorithm}

El uso de esta selección para reemplazar la población dependerá del esquema (generacional o estacionario).

\subsection{Búsqueda local para los algoritmos meméticos}

Proporcionamos la implementación del algoritmo de búsqueda local que usaremos en los algoritmos meméticos. Modifica una solución
saltando al primer mejor vecino explorado hasta consumir un cierto número de evaluaciones o alcanzar un máximo local.

Suponemos accesibles las variables globales $LIMIT=100000$ (límite total de evaluaciones), $EVALS$ (evaluaciones totales hasta el momento, comienza
a 0)
y $limit=400$ (límite de evaluaciones en una búsqueda local).

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Solución de partida $S$.}
	\KwOut{La solución $S$ se modifica (no se devuelve) con varias iteraciones de búsqueda local.}
	$E \gets \{0,\ldots,n-1\}$ \tcp*{Vector con todos los elementos.}
	$evals \gets 0$\;
	$carryon \gets true$\;
	\While{carryon}{
		$carryon \gets false$\;
		$lowest\gets \text{indice del elemento de $S$ que menos contribuye, minimiza $\operatorname{contrib}(S,D,S[lowest])$}$\;
		$min\_contrib \gets \operatorname{contrib}(S,D,lowest)$
		$E \gets \operatorname{shuffle}(E)$ \tcp*{Para explorar los posibles vecinos en orden aleatorio.}
		\For{$e$ \textbf{in} $E$} {
			\If{$e\in S$}{
				continue \tcp*{Si ya está escogido, no lo cuento.}
			}
			$contrib \gets \operatorname{contrib}(S,D,e)-D[e,S[lowest]]$ \tcp*{Contribución a la solución sin el elemento a sustituir.}
			$EVALS \gets EVALS+1$ \tcp*{He evaludado una posible solución.}
			$evals \gets evals+1$\;
			\If{$contrib > min\_contrib$} { 
				$S.fitness \gets S.fitness + contrib - min\_contrib$ \tcp*{Fitness de la nueva solución}
				$carryon \gets true$ \tcp*{Toca saltar, lo que completa la iteración}
				$S[lowest]\gets e$ \tcp*{Saltamos a la nueva solución}
			}
			\If{$carryon==true$ or $EVALS\geq LIMIT$ or $evals\geq limit$} { 
				break  \tcp*{Se cumple alguna de las condiciones de parada}
			}
		}
	}
	\caption{{\sc LocalSearch} modifica una solución con varias iteraciones de búsqueda local con primer mejor.}
	\label{alg:local-search}
\end{algorithm}

\pagebreak

\section{Descripción de los algoritmos}

Distinguimos dos clases de algoritmos genéticos, según el esquema de reemplazamiento.

\subsection{Algoritmo genético generacional (AGG)}

Para seleccionar la nueva población se realizan tantos torneos binarios como el tamaño de la población. Para conservar la mejor solución
 (elitismo), ésta sustituye a la peor en caso de no sobrevivir a los torneos.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{La población $P'$ de padres para la siguiente generación. No se devuelve, se modifica P.}
	$P'\gets\emptyset$\;
	$best\gets\text{índice de la solución de $P$ con mayor fitness}$\;
	$elitism\gets false$ \tcp*{Para contemplar si sobrevive la mejor.}
	\While{$|P'|<|P|$}{
		$i\gets\operatorname{BinTournament}(P)$\;
		$P'\gets P'\cup\{P[i]\}$\;
		\If{$i=best$}{
			$elitism\gets true$ \tcp*{Ha sobrevivido.}
		}
	}
	\If{$elitism=false$}{
		$i\gets\text{índice de la solución de $P'$ con peor fitness}$\;
		$P'[i]\gets P[best]$\;
	}
	$P\gets P'$\;
	\caption{{\sc Replacement} devuelve la población de padres para la siguiente generación.}
	\label{alg:replacement-agg}
\end{algorithm}

Hay que tener en cuenta que comparar si es la mejor solución por índice y no por fitness fuerza a que si hay soluciones repetidas
(ocurrirá tras varias iteraciones del algoritmo, cada vez más), se fuerza a salvar una copia concreta de la solución. Esto le da ventaja
a la mejor solución respecto a las demás, ya que puede salvarse y además copiarse una vez más.
Con esta comparación, se acelera la convergencia del algoritmo pero se reduce la variedad de soluciones, aunque
no en gran medida.

Para cruzar la población (de padres), se calcula el número esperado de cruces, $25\cdot\text{probabilidad de cruce}=18$ (nos quedamos
con un entero). El valor 25 proviene del número de parejas que se forman con la población de 50 cromosomas. Como el operador de
reemplazamiento construye una nueva población de padres aleatorios, podemos simplemente cruzar primero con segundo, tercero y cuarto, etc. (hasta llegar a 18 cruces).
El cruce de dos soluciones puede ser uniforme o posicional, se estudian las dos alternativas.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{En la población $P$, se sustituyen cada pareja de padres por sus hijos.}
	$n2cross=n\_chromosomes\cdot prob_{cross}$ \tcp*{Doble del número esperado de cruces.}
	\For{$i=0,2,4,\dots,n2cross-1$}{
		$child_1\gets \operatorname{Croos}(P[i],P[i+1])$\;
		$child_2\gets \operatorname{Croos}(P[i],P[i+1])$\;
		$P[i]\gets child_1$\;
		$P[i+1]\gets child_2$\;
	}
	\caption{{\sc Cross} cruza los padres de la población y los sustituye por los hijos.}
	\label{alg:cross-generational}
\end{algorithm}

Para la mutación, se calcula el número esperado de mutaciones. En este caso, el número de mutaciones no depende de $n$ y $m$, siempre
es el 10\% del número de cromosomas, 5. Tantas veces como el número esperado de mutaciones, se elige una solución aleatoria, y esta
muta un gen aleatorio como hemos descrito antes. El número de genes coincide con el parámetro $n$ del problema (debemos tener en cuenta
que los parámetros que nos proponen corresponden a la representación binaria).

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{En la población $P$ mutan algunas soluciones, no se devuelve nada.}
	$mutations=n\_chromosomes\cdot n\_genes\cdot prob_{mut}$ \tcp*{Donde $prob_{mut}=0.1\cdot n\_genes$.}
	\For{$i=0,1,\dots,mutations-1$}{
		$j\gets\text{número aleatorio entre $0$ y $|P|-1$}$ \tcp*{Índice de una solución aleatoria.}
		$\operatorname{mutate(P[j])}$ \tcp*{La solución muta un gen aleatorio.}
	}
	\caption{{\sc Mutate} muta algunas soluciones de la población.}
	\label{alg:mutate-generational}
\end{algorithm}

El esquema de reemplazamiento del algoritmo genético generacional es el siguiente.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población) inicializado con soluciones aleatorias.}
	\KwOut{La población $P$ (se modifica, no se devuelve) evoluciona tras varias generaciones.}
	\While{$EVAlS<LIMIT$}{
		$\operatorname{cross}(P)$\;
		$\operatorname{mutate}(P)$\;
		$\operatorname{evaluate}(P)$\;
		$\operatorname{replacement}(P)$\;
	}
	\caption{{\sc AGG}.}
	\label{alg:generational}
\end{algorithm}

En evaluación, se actualiza el fitness de cada solución, que se almacena por razones de eficiencia. Se usa un flag para evitar reevaluar soluciones
que no cambien de una generación a otra. El flag está en ``actualizado'' para nuevas soluciones aleatorias y productos de cruces y
mutaciones. Como la comprobación del límite de evaluaciones no se realiza en mitad de las iteraciones, podemos pasarnos del límite.
Sin embargo, el número máximo de evaluaciones por iteración es de 41 (36 hijos + 5 mutaciones), por lo que como mucho llegaremos a
100040 evaluaciones, lo que no supone mucho ni en tiempo ni en desempeño del algoritmo.

\subsection{Algoritmo genético estacionario (AGE)}

En el esquema estacionario, sólo dos soluciones se cruzan y puden mutar en cada iteración. Los dos padres se eligen con dos
torneos binarios.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{Índices de dos padres.}
	$p_1\gets\operatorname{BinTournament}(P)$\;
	$p_2\gets\operatorname{BinTournament}(P)$\;
	\Return{$p_1,p_2$}\;
	\caption{{\sc Selection} devuelve los índices de dos padres, que selecciona por torneo binario.}
	\label{alg:selection-stationary}
\end{algorithm}

Dichos padres se cruzan para formar dos hijos, por cruce uniforme o basado en posición.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwIn{Los índices de los padres: $p_1$ y $p_2$.}
	\KwOut{Dos nuevas soluciones (hijos).}
	$child_1\gets\operatorname{cross}(P[p_1],P[p_2])$\;
	$child_2\gets\operatorname{cross}(P[p_1],P[p_2])$\;
	\Return{$child_1,child_2$}\;
	\caption{{\sc Cross} devuelve dos soluciones, producto del cruce de los padres.}
	\label{alg:cross-stationary}
\end{algorithm}

Se decide si mutan los hijos (cada uno con probabilidad 0.1, para preservar la esperanza de 0.2 mutaciones por iteración), y posteriormente sustituyen a las dos peores soluciones de la problación (siempre que las superen).
De las 4 soluciones (2 peores + 2 hijos), debemos quedarnos con las 2 mejores. Esto lo conseguimos con la siguiente función.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwIn{Los dos hijos: $child_1$ y $child_2$.}
	\KwOut{Modifica la población $P$ para sustituir las peores soluciones por los hijos (si estos las superan).}
	$w_1,w_2\gets\text{índices de la peor y segunda peor soluciones de $P$ respectivamente}$\;
	\If{$child_1.fitness>P[w_2].fitness$}{
		$P[w_1]\gets P[w_2]$\;
		$P[w_2]\gets child_1$\;
	}
	\ElseIf{$child_1.fitness>P[w_1].fitness$}{
		$P[w_1]\gets child_1$\;
	}
	\If{$child_2.fitness>P[w_1].fitness$}{
		$P[w_1]\gets child_2$\;
	}
	\caption{{\sc Replacement} se queda con las dos mejores de 4 soluciones: $\text{2 peores} + \text{2 hijos}$.}
	\label{alg:replacement-stationary}
\end{algorithm}

El ciclo de evolución queda de la siguiente forma.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población) inicializado con soluciones aleatorias.}
	\KwOut{La población $P$ (se modifica, no se devuelve) evoluciona tras varias iteraciones.}
	Se evalúan todas las soluciones (50 evaluaciones), se incrementa $EVALS$ en 50\;
	\While{$EVAlS<LIMIT$}{
		$p_1,p_2\gets\operatorname{selection}(P)$\;
		$\operatorname{cross}(P,p_1,p_2)$\;
		$child_1$ muta con probabilidad 0.1\;
		$child_2$ muta con probabilidad 0.1\;
		$\operatorname{evaluate}(child_1)$\;
		$\operatorname{evaluate}(child_2)$\;
		$EVALS\gets EVALS+2$\;
		$\operatorname{replacement}(P,child_1,child_2)$\;
	}
	\caption{{\sc AGE}.}
	\label{alg:stationary}
\end{algorithm}

\subsection{Algoritmos meméticos (AM)}

Los algoritmos meméticos combinan el esquema evolutivo generacional (con cruce uniforme) con el algoritmo de búsqueda local. Ya hemos mostrado la implementación
de búsqueda local a nivel de solución. Ahora mostraremos cómo se aplica la búsqueda local a nivel de población, lo que diferencia las
distintas variantes de meméticos.

En la primera versión, AM-(10,1.0), se aplica búsqueda local cada 10 generaciones sobre todos los cromosomas de la población.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{La población $P$ (se modifica, no se devuelve) después de que todas las soluciones mejoren con búsqueda local.}
	\ForEach{$sol$ in $P$}{
		$\operatorname{LocalSearch}(sol)$\;
	}
	\caption{{\sc LocalSearch} de AM-(10,1.0).}
	\label{alg:am-10-1}
\end{algorithm}

En la versión AM-(10,0.1), se aplica búsqueda local a cada cromosoma con probabilidad 0.1 cada 10 generaciones.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{La población $P$ (se modifica, no se devuelve) después de que algunas de las soluciones mejoren con búsqueda local.}
	\ForEach{$sol$ in $P$}{
		Con probabilidad 0.1: $\operatorname{LocalSearch}(sol)$\;
	}
	\caption{{\sc LocalSearch} de AM-(10,0.1).}
	\label{alg:am-10-01}
\end{algorithm}

En la versión AM-(10,0.1mej), se aplica búsqueda local a las 5 mejores soluciones (mejor 10\% de la población).

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{La población $P$ (se modifica, no se devuelve) después de que las 5 mejores soluciones mejoren con búsqueda local.}
	$q\gets\emptyset$ \tcp*{Cola con prioridad donde almacenaré parejas (fitness,índice), se ordenan por mayor fitness.}
	\ForEach{$i=0,\ldots,|P|-1$}{
		$q\gets q\cup\{(P[i].fitness,i)\}$\;
	}
	$k\gets 0.1\cdot n\_chromosomes$ \tcp*{Sacaré los 10\% mejores (5).}
	\For{$j=0,\ldots,k-$1}{
		$\operatorname{LocalSearch}(P[q.top.second])$\;
		$q.pop$\;
	}
	\caption{{\sc LocalSearch} de AM-(10,0.1mej).}
	\label{alg:am-10-01mej}
\end{algorithm}

El cuerpo principal de los algoritmos meméticos es el siguiente, la función LocalSearch (a nivel de población) es lo que diferencia
las distintas alternativas.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población) inicializado con soluciones aleatorias.}
	\KwOut{La población $P$ (se modifica, no se devuelve) evoluciona tras varias iteraciones.}
	Se evalúan todas las soluciones (50 evaluaciones), se incrementa $EVALS$ en 50\;
	$generation\gets 0$\;
	\While{$EVAlS<LIMIT$}{
		$\operatorname{cross}(P)$\;
		$\operatorname{mutate}(P)$\;
		$\operatorname{evaluate}(P)$\;
		$\operatorname{replacement}(P)$\;
		
		$generation\gets generation+1$\;
		
		\If{$generation \operatorname{mod} 10 == 0$}{
			$\operatorname{LocalSearch}(P)$\;
		}
	}
	\caption{{\sc AM}.}
	\label{alg:am}
\end{algorithm}

\pagebreak

\subsection{Búsqueda local}

Procedemos con la descripción del algoritmo de Búsqueda Local que se nos ha presentado en el seminario. 
Este algoritmo utiliza la técnica del Primer Mejor, en la que se van generando soluciones en el entorno de la actual y se
salta a la primera con mejor evaluación. Para la implementación del algoritmo, necesitamos distintos elementos.

El primer elemento, es una función para generar una solución aleatoria de partida. Simplemente se eligen $m$ elementos 
diferentes del conjunto. Por comodidad, también calculamos el complementario.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{El entero $m$.}
	\KwIn{El entero $n$.}
	\KwOut{Una solución válida del MDP obtenida aleatoriamente.}
	\KwOut{El complementario de la solución obtenida.}
	$E \gets \{0,\ldots, n-1\}$ \tcp*{Conjunto con los elementos no seleccionados}
	$S \gets \emptyset$ \tcp*{La solución empieza vacía}
	\While{$|S|<m$}{
		$e \gets$ elemento aleatorio de $E$\;
		$E \gets E\backslash \{e\}$\;
		$S \gets S\cup \{e\}$\;
	}
	\Return{$S$}\;
	\Return{$E$} \tcp*{El complementario}
	\caption{{\sc RandomSol} proporciona una solución válida aleatoria}
	\label{alg:randomsol}
\end{algorithm}

Lo siguiente que necesitamos es un método para generar las soluciones del entorno. Estas soluciones se consiguen sustituyendo
el menor contribuyente de la solución actual por otro candidato. Presentamos el código para obtener el menor contribuyente.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un conjunto de elementos $S$.}
	\KwIn{La matriz de distancias $D$.}
	\KwOut{El elemento de $S$ que minimiza $\operatorname{contrib}(S,S,e)$ con $e\in S$.}
	\KwOut{Su contribución, para la factorización de la función objetivo.}
	$lowest \gets \text{primer elemento de } S$\;
	$min\_contrib \gets \operatorname{contrib}(S,D,lowest)$\;
	\For{$s$ \textbf{in} $S$} {
		$contrib \gets \operatorname{contrib}(S,D,s)$\;
		\If{$contrib < min\_contrib$} { 
			$min\_contrib \gets contrib$\;
			$lowest \gets s$ \tcp*{Si encuentro un candidato con menor contribución, actualizo}
		}
	}
	\Return{$lowest$}\;
	\Return{$min\_contrib$}\;
	\caption{{\sc lowestContrib} obtiene el elemento de $S$ que menos contribuye en la valoración.}
	\label{alg:lowest-contributor}
\end{algorithm}

En el caso de que $S$ se represente como un conjunto, no sabemos cuál será el primer elemento (depende de la implementación del iterador). Pero
esto no es relevante, ya que vale cualquier elemento de $S$.

Finalmente, proporcionamos el algoritmo de Búsqueda Local para actualizar la solución por otra del entorno iterativamente
hasta encontrar un máximo local (una solución mejor que todas las de su entorno) o llegar a un límite de evaluaciones de la función
objetivo: $LIMIT=100000$. Las soluciones del entorno se generan aleatoriamente.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{El entero $m$.}
	\KwIn{La matriz de distancias $D$, $n\times n$.}
	\KwOut{Una solución válida del MDP por el algoritmo de BS que hemos descrito, junto con su evaluación.}
	$S \gets \operatorname{randomSol}(m,n)$ \tcp*{Comenzamos con una solución aleatoria}
	$E \gets \{0,\ldots,n-1\}\backslash S$ \tcp*{$\operatorname{randomSol}$ también devuelve el complementario}
	$fitness \gets \operatorname{fitness}(S)$ \tcp*{Diversidad de la solución}
	$E \gets \operatorname{vector}(E)$ \tcp*{No importa el orden, pero debe poder barajarse}
	$carryon \gets true$\;
	$LIMIT \gets 100000$ \tcp*{Límite de llamadas a la función de evaluación}
	$CALLS \gets 0$\;
	\While{carryon}{
		$carryon \gets false$\;
		$lowest = \operatorname{lowestContributor}(S,D)$\;
		$min\_contrib \gets \operatorname{contrib}(S,D,lowest)$ \tcp*{Se calcula dentro de $\operatorname{lowestContributor}$}
		$S \gets S\backslash\{lowest\}$\;
		$E \gets \operatorname{shuffle}(E)$\;	
		\For{$e$ \textbf{in} $E$} {
			$contrib \gets \operatorname{contrib}(S,D,e)$\;
			$CALLS \gets CALLS +1$ \tcp*{He evaludado una posible solución}
			\If{$contrib > min\_contrib$} { 
				$fitness \gets fitness + contrib - min\_contrib$ \tcp*{Diversidad de la nueva solución}
				$carryon \gets true$ \tcp*{Toca saltar, lo que completa la iteración}
				$S\gets S\cup\{e\}$ \tcp*{Saltamos a la nueva solución}
				$E \gets E\backslash\{e\}$\;
				$E \gets E\cup\{lowest\}$\;
			}
			\If{$carryon==true$ or $CALLS\geq LIMIT$} { 
				\textbf{break}  \tcp*{Se cumple alguna de las condiciones de parada}
			}
		}
	}
	\If{$|S|<m$} { 
		$S\gets S\cup\{lowest\}$ \tcp*{Si salimos porque no encontramos una mejor, recuperamos la solución}
	}
	\Return{$S$}\;
	\Return{$fitness$}\;
	\caption{{\sc LocalSearch}}
	\label{alg:local-search}
\end{algorithm}

Cabe destacar que en este algoritmo se calcula la fitness factorizando. Esto acelera mucho los cálculos, ya que hay que evaluar muchas soluciones diferentes.

\pagebreak

\section{Algoritmo de comparación: Greedy}

Para comparar la eficacia de cada algoritmos, lo compararemos con el algoritmo \textbf{Greedy}. El algoritmo consiste en empezar por el
elemento más lejano al resto e ir añadiendo el elemento que más contribuya hasta completar una solución válida.

Como elemento más lejano al resto se toma el elemento cuya suma de las distancias al resto sea la mayor. Y en cada iteración se introduce el elemento
cuya suma de las distancias a los seleccionados sea mayor. Es decir, utilizamos la definición de \eqref{eq:distance-elem-set}.

Para calcular ambos valores, usamos la siguiente función, que permite obtener el de entre
un conjunto de candidatos más lejano (en el sentido que acabamos de comentar) a los elementos de un conjunto dado.
El código para calcularlo es similar al del algoritmo \ref{alg:lowest-contributor}.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un conjunto de candidatos $C$.}
	\KwIn{Un conjunto de elementos $S$.}
	\KwIn{La matriz de distancias $D$.}
	\KwOut{El candidato más lejano en el sentido de \eqref{eq:distance-elem-set}.}
	$farthest \gets \text{primer elemento de } C$\;
	$max\_contrib \gets \operatorname{contrib}(S,D,farthest)$\;
	\For{$e$ \textbf{in} $C$} {
		$contrib \gets \operatorname{contrib}(S,D,e)$\;
		\If{$contrib > max\_contrib$} { 
			$max\_contrib \gets contrib$\;
			$farthest \gets e$ \tcp*{Si encuentro un candidato con mayor contribución, actualizo}
		}
	}
	\Return{$farthest$}\;
	\caption{{\sc farthest} obtiene el candidato más lejano a los elementos de $S$.}
	\label{alg:farthest-candidate-set}
\end{algorithm}

En el caso de que $C$ se represente como un conjunto, no sabemos cuál será el primer elemento (depende de la implementación del iterador). Pero
esto no es relevante, ya que vale cualquier elemento de $C$.

Ya estamos en condiciones de proporcionar una descripción del algoritmo Greedy.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{La matriz de distancias $D$.}
	\KwIn{El entero $m$.}
	\KwOut{Una solución válida del MDP obtenida como hemos descrito anteriormente, y su diversidad.}
	$C \gets \{0,\ldots, n-1\}$ \tcp*{En principio los $n$ elementos son candidatos}
	$S \gets \emptyset$ \tcp*{La solución empieza vacía}
	$farthest \gets \operatorname{farthest}(C,C,D)$ \tcp*{Elemento más lejano al resto}
	$C \gets C\backslash \{farthest\}$\;
	$S \gets S\cup \{farthest\}$\;
	\While{$|S|<m$}{
		$farthest \gets \operatorname{farthest}(C,S,D)$ \tcp*{Elemento más lejano a los seleccionados}
		$C \gets C\backslash \{farthest\}$\;
		$S \gets S\cup \{farthest\}$\;
	}
	\Return{$S$}\;
	\Return{$\operatorname{fitness}(S)$}\;
	\caption{{\sc Greedy}}
	\label{alg:greedy}
\end{algorithm}

\pagebreak

\section{Desarrollo de la práctica}

La implementación de los algoritmos y la experimentación con los mismos se ha llevado acabo de C++, utilizando la librería STL. 
Para representar la soluciones hemos hecho uso del tipo \texttt{vector}.

La mayoría de operadores (mutación, cruce, búsqueda local) se implementan a nivel de solución y a nivel de población para abstraer
las operaciones y que el código sea más reciclable, generalmente como métodos de clase.

Para medir los tiempos de ejecución se utiliza la función \texttt{clock} de la librería \texttt{time.h}.

A lo largo de la práctica se utilizan acciones aleatorias. Utilizamos la librería \texttt{stdlib.h} para la generación de
enteros (no negativos) pseudoaleatorios con \texttt{rand} y fijamos la semilla con \texttt{srand}. Se barajan vectores con la función
 \texttt{random\_shuffle} de la librería \texttt{algorithm}.
 
Para las acciones que se realizan con cierta probabilidad, es necesario generar flotantes pseudoaleatorios en el intervalos $[0,1]$.
Para esto, se genera un entero no negativo con \texttt{rand} y se divide entre el máximo posible (RAND\_MAX).

Se almacena la matriz de distancias completa (no sólo un triángulo) por comodidad de los cálculos.

Se utiliza optimización de código \texttt{-O2} al compilar.

\subsection{Manual de usuario}

A continuación detallamos instrucciones para lanzar los ejecutables.

Tenemos los siguientes ejecutables:

\begin{itemize}
	\item \textbf{AGG-uniforme:} Implementación del algoritmo genético generacional con cruce uniforme.
	\item \textbf{AGG-posicion:} Implementación del algoritmo genético generacional con cruce basado en posición.
	\item \textbf{AGE-uniforme:} Implementación del algoritmo genético estacionario con cruce uniforme. 
	\item \textbf{AGE-posicion:} Implementación del algoritmo genético estacionario con cruce basado en posición.
	\item \textbf{AM-10-1:} Implementación del algoritmo memético (genético generacional con cruce uniforme combinado con búsqueda local) que aplica búsqueda local a todos los cromosomas cada 10 iteraciones.
	\item \textbf{AM-10-01:} Implementación del algoritmo memético que aplica búsqueda local a cada cromosoma con probabilidad 0.1 cada 10 iteraciones.
	\item \textbf{AM-10-01mej:} Implementación del algoritmo memético que aplica búsqueda local a los ``0.1 $\times$ número de cromosomas'' mejores cromosomas cada 10 iteraciones.
\end{itemize}

Todos ellos devuelven la evaluación de la solución obtenida y el tiempo de ejecución por salida estándar.
Leen el fichero por entrada estándar, así que es conveniente redirigirla.
Todos los archivos reciben la semilla como parámetro.

Además, todos los archivos de búsqueda local reciben la semilla como parámetro. Ejemplo:
\begin{verbatim}
bin/AGG-uniforme 197 < datos/MDG-a_1_n500_m50.txt >> salidas/AGG-uniforme.txt
\end{verbatim}

En la carpeta \textbf{software} se incluye el script usado para lanzar todas las ejecuciones, \texttt{run.sh}. También se incluye
el \texttt{Makefile} que compila los ejecutables.

\pagebreak

\section{Experimentación y análisis}

Toda la experimentación se realiza en mi ordenador portátil personal, que tiene las siguientes especificaciones:
\begin{itemize}
	\item OS: Ubuntu 20.04.2 LTS x86\_64.
	\item RAM: 8GB, DDR4.
	\item CPU: Intel Core i7-6700HQ, 2.60Hz.
\end{itemize}

\subsection{Casos de estudio y resultados}

Tratamos varios casos con distintos parámetros $n$ y $m$. En cada caso se utiliza una semilla diferente, pero se usa la misma para todos los algoritmos.
A continuación presentamos una tabla con los casos estudiados. Para cada caso indicamos los valores de $n$ y $m$ y la semilla
que se utiliza.

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & $n$ & $m$ & Seed\\ \hline
		MDG-a\_10\_n500\_m50 & 500 & 50 & 13\\
		MDG-a\_1\_n500\_m50 & 500 & 50 & 19\\
		MDG-a\_2\_n500\_m50 & 500 & 50 & 25\\
		MDG-a\_3\_n500\_m50 & 500 & 50 & 31\\
		MDG-a\_4\_n500\_m50 & 500 & 50 & 37\\
		MDG-a\_5\_n500\_m50 & 500 & 50 & 43\\
		MDG-a\_6\_n500\_m50 & 500 & 50 & 49\\
		MDG-a\_7\_n500\_m50 & 500 & 50 & 55\\
		MDG-a\_8\_n500\_m50 & 500 & 50 & 61\\
		MDG-a\_9\_n500\_m50 & 500 & 50 & 67\\
		MDG-b\_21\_n2000\_m200 & 2000 & 200 & 73\\
		MDG-b\_22\_n2000\_m200 & 2000 & 200 & 79\\
		MDG-b\_23\_n2000\_m200 & 2000 & 200 & 85\\
		MDG-b\_24\_n2000\_m200 & 2000 & 200 & 91\\
		MDG-b\_25\_n2000\_m200 & 2000 & 200 & 97\\
		MDG-b\_26\_n2000\_m200 & 2000 & 200 & 103\\
		MDG-b\_27\_n2000\_m200 & 2000 & 200 & 109\\
		MDG-b\_28\_n2000\_m200 & 2000 & 200 & 115\\
		MDG-b\_29\_n2000\_m200 & 2000 & 200 & 121\\
		MDG-b\_30\_n2000\_m200 & 2000 & 200 & 127\\
		MDG-c\_10\_n3000\_m400 & 3000 & 400 & 133\\
		MDG-c\_13\_n3000\_m500 & 3000 & 500 & 139\\
		MDG-c\_14\_n3000\_m500 & 3000 & 500 & 145\\
		MDG-c\_15\_n3000\_m500 & 3000 & 500 & 151\\
		MDG-c\_19\_n3000\_m600 & 3000 & 600 & 157\\
		MDG-c\_1\_n3000\_m300 & 3000 & 300 & 163\\
		MDG-c\_20\_n3000\_m600 & 3000 & 600 & 169\\
		MDG-c\_2\_n3000\_m300 & 3000 & 300 & 175\\
		MDG-c\_8\_n3000\_m400 & 3000 & 400 & 181\\
		MDG-c\_9\_n3000\_m400 & 3000 & 400 & 187\\
		\hline
	\end{tabular}
	\caption{Tabla con los parámetros y semillas de cada caso. Ordenando los nombres de los ficheros por orden alfabético
		(el orden en el que los procesa el script), las semillas son números del 13 al 187 saltando de 6 en 6.}
	\label{tab:param-seed}
\end{table}

Ahora mostraremos para cada algoritmo una tabla con los estadísticos (Desviación y Tiempo) que han obtenido en cada
caso.

\pagebreak

\subsubsection*{Greedy}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7610.42 & 2.85 & 0.001375\\
		MDG-a\_2\_n500\_m50 & 7574.39 & 2.54 & 0.001293\\
		MDG-a\_3\_n500\_m50 & 7535.96 & 2.88 & 0.001304\\
		MDG-a\_4\_n500\_m50 & 7551.52 & 2.81 & 0.001281\\
		MDG-a\_5\_n500\_m50 & 7540.14 & 2.77 & 0.001284\\
		MDG-a\_6\_n500\_m50 & 7623.65 & 1.93 & 0.001278\\
		MDG-a\_7\_n500\_m50 & 7594.62 & 2.28 & 0.0014\\
		MDG-a\_8\_n500\_m50 & 7625.94 & 1.61 & 0.001367\\
		MDG-a\_9\_n500\_m50 & 7547.25 & 2.87 & 0.001351\\
		MDG-a\_10\_n500\_m50 & 7642.27 & 1.77 & 0.001893\\
		MDG-b\_21\_n2000\_m200 & 11099332.620328 & 1.77 & 0.319017\\
		MDG-b\_22\_n2000\_m200 & 11149879.733826 & 1.21 & 0.313017\\
		MDG-b\_23\_n2000\_m200 & 11119613.974858 & 1.6 & 0.303374\\
		MDG-b\_24\_n2000\_m200 & 11106996.970212 & 1.63 & 0.311278\\
		MDG-b\_25\_n2000\_m200 & 11114220.292214 & 1.61 & 0.306411\\
		MDG-b\_26\_n2000\_m200 & 11132801.799043 & 1.41 & 0.306542\\
		MDG-b\_27\_n2000\_m200 & 11130608.965587 & 1.55 & 0.310595\\
		MDG-b\_28\_n2000\_m200 & 11110673.520354 & 1.5 & 0.318429\\
		MDG-b\_29\_n2000\_m200 & 11156328.082493 & 1.25 & 0.306362\\
		MDG-b\_30\_n2000\_m200 & 11109767.818822 & 1.65 & 0.296905\\
		MDG-c\_1\_n3000\_m300 & 24617010 & 1.07 & 1.501668\\
		MDG-c\_2\_n3000\_m300 & 24547293 & 1.44 & 1.464132\\
		MDG-c\_8\_n3000\_m400 & 43056071 & 0.88 & 2.546235\\
		MDG-c\_9\_n3000\_m400 & 42958639 & 1.1 & 2.569214\\
		MDG-c\_10\_n3000\_m400 & 42959794 & 1.19 & 2.566065\\
		MDG-c\_13\_n3000\_m500 & 66493045 & 0.78 & 3.67213\\
		MDG-c\_14\_n3000\_m500 & 66449858 & 0.79 & 3.767131\\
		MDG-c\_15\_n3000\_m500 & 66468837 & 0.78 & 3.78725\\
		MDG-c\_19\_n3000\_m600 & 94929882 & 0.74 & 5.183856\\
		MDG-c\_20\_n3000\_m600 & 94979205 & 0.69 & 5.582157\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo Greedy
		en cada caso de estudio.}
	\label{tab:greedy}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		1.63 & 1.19 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

\subsubsection*{Búsqueda local}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7623.23 & 2.69 & 0.001809\\
		MDG-a\_2\_n500\_m50 & 7590.18 & 2.34 & 0.001391\\
		MDG-a\_3\_n500\_m50 & 7544.94 & 2.76 & 0.001204\\
		MDG-a\_4\_n500\_m50 & 7576.44 & 2.49 & 0.0012\\
		MDG-a\_5\_n500\_m50 & 7484.27 & 3.49 & 0.001308\\
		MDG-a\_6\_n500\_m50 & 7570.96 & 2.61 & 0.001297\\
		MDG-a\_7\_n500\_m50 & 7654.98 & 1.5 & 0.001608\\
		MDG-a\_8\_n500\_m50 & 7623.78 & 1.64 & 0.002379\\
		MDG-a\_9\_n500\_m50 & 7612.74 & 2.02 & 0.001494\\
		MDG-a\_10\_n500\_m50 & 7619.52 & 2.07 & 0.001959\\
		MDG-b\_21\_n2000\_m200 & 11181874.0007 & 1.04 & 0.099777\\
		MDG-b\_22\_n2000\_m200 & 11167876.184 & 1.05 & 0.092492\\
		MDG-b\_23\_n2000\_m200 & 11176568.0611 & 1.09 & 0.107634\\
		MDG-b\_24\_n2000\_m200 & 11188223.318 & 0.91 & 0.107425\\
		MDG-b\_25\_n2000\_m200 & 11181859.8196 & 1.01 & 0.090053\\
		MDG-b\_26\_n2000\_m200 & 11193478.832 & 0.88 & 0.122694\\
		MDG-b\_27\_n2000\_m200 & 11211629.6839 & 0.83 & 0.112468\\
		MDG-b\_28\_n2000\_m200 & 11151089.4629 & 1.14 & 0.079449\\
		MDG-b\_29\_n2000\_m200 & 11183039.6644 & 1.01 & 0.09833\\
		MDG-b\_30\_n2000\_m200 & 11159590.8213 & 1.21 & 0.090033\\
		MDG-c\_1\_n3000\_m300 & 24729057 & 0.62 & 0.601221\\
		MDG-c\_2\_n3000\_m300 & 24738675 & 0.67 & 0.584432\\
		MDG-c\_8\_n3000\_m400 & 43200330 & 0.55 & 1.264437\\
		MDG-c\_9\_n3000\_m400 & 43157977 & 0.64 & 1.241837\\
		MDG-c\_10\_n3000\_m400 & 43188306 & 0.66 & 1.195051\\
		MDG-c\_13\_n3000\_m500 & 66636142 & 0.56 & 2.304507\\
		MDG-c\_14\_n3000\_m500 & 66727635 & 0.38 & 2.430114\\
		MDG-c\_15\_n3000\_m500 & 66808383 & 0.28 & 2.78715\\
		MDG-c\_19\_n3000\_m600 & 95244690 & 0.41 & 3.572005\\
		MDG-c\_20\_n3000\_m600 & 95324379 & 0.33 & 3.598978\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo de Búsqueda Local
		con Primer Mejor en cada caso de estudio.}
	\label{tab:bs-primer-mejor}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		1.3 & 0.69 \\
		\hline
	\end{tabular}
\end{table}

\subsubsection*{AGG con cruce uniforme}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7707.95 & 1.61 & 2.090093\\
		MDG-a\_2\_n500\_m50 & 7638.38 & 1.71 & 2.107509\\
		MDG-a\_3\_n500\_m50 & 7606.73 & 1.97 & 2.000252\\
		MDG-a\_4\_n500\_m50 & 7572.09 & 2.55 & 1.9783\\
		MDG-a\_5\_n500\_m50 & 7578.8 & 2.27 & 2.056744\\
		MDG-a\_6\_n500\_m50 & 7595.96 & 2.29 & 2.003538\\
		MDG-a\_7\_n500\_m50 & 7657.02 & 1.48 & 2.028599\\
		MDG-a\_8\_n500\_m50 & 7573.56 & 2.29 & 1.996006\\
		MDG-a\_9\_n500\_m50 & 7624.78 & 1.87 & 2.047315\\
		MDG-a\_10\_n500\_m50 & 7559.2 & 2.84 & 2.024727\\
		MDG-b\_21\_n2000\_m200 & 11121197.565411 & 1.58 & 47.359572\\
		MDG-b\_22\_n2000\_m200 & 11140356.96411 & 1.3 & 46.470377\\
		MDG-b\_23\_n2000\_m200 & 11122989.485668 & 1.57 & 47.038308\\
		MDG-b\_24\_n2000\_m200 & 11093069.977321 & 1.75 & 47.933936\\
		MDG-b\_25\_n2000\_m200 & 11160806.463414 & 1.2 & 46.681582\\
		MDG-b\_26\_n2000\_m200 & 11128960.812991 & 1.45 & 46.708763\\
		MDG-b\_27\_n2000\_m200 & 11151190.815364 & 1.37 & 46.649915\\
		MDG-b\_28\_n2000\_m200 & 11133921.949524 & 1.29 & 44.099666\\
		MDG-b\_29\_n2000\_m200 & 11105148.429167 & 1.7 & 43.791342\\
		MDG-b\_30\_n2000\_m200 & 11115025.068757 & 1.61 & 44.419215\\
		MDG-c\_1\_n3000\_m300 & 24606743 & 1.11 & 142.839721\\
		MDG-c\_2\_n3000\_m300 & 24604945 & 1.21 & 142.000313\\
		MDG-c\_8\_n3000\_m400 & 43018354 & 0.96 & 201.906448\\
		MDG-c\_9\_n3000\_m400 & 43010797 & 0.98 & 199.613779\\
		MDG-c\_10\_n3000\_m400 & 42986441 & 1.13 & 203.129084\\
		MDG-c\_13\_n3000\_m500 & 66338876 & 1.01 & 244.070216\\
		MDG-c\_14\_n3000\_m500 & 66332815 & 0.97 & 242.688824\\
		MDG-c\_15\_n3000\_m500 & 66450927 & 0.81 & 248.337499\\
		MDG-c\_19\_n3000\_m600 & 94857517 & 0.81 & 293.797158\\
		MDG-c\_20\_n3000\_m600 & 94808873 & 0.87 & 303.61342\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo AGG con cruce uniforme
		en cada caso de estudio.}
	\label{tab:agg-uniforme}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		 1.52 & 90.12 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

\subsubsection*{AGG con cruce basado en posición}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7524.33 & 3.95 & 1.930193\\
		MDG-a\_2\_n500\_m50 & 7568.98 & 2.61 & 1.939586\\
		MDG-a\_3\_n500\_m50 & 7541.52 & 2.81 & 1.945953\\
		MDG-a\_4\_n500\_m50 & 7521.62 & 3.2 & 1.923407\\
		MDG-a\_5\_n500\_m50 & 7539.26 & 2.78 & 1.952541\\
		MDG-a\_6\_n500\_m50 & 7538.96 & 3.02 & 1.938942\\
		MDG-a\_7\_n500\_m50 & 7450.6 & 4.13 & 1.937036\\
		MDG-a\_8\_n500\_m50 & 7564.71 & 2.4 & 1.939857\\
		MDG-a\_9\_n500\_m50 & 7603.57 & 2.14 & 1.930254\\
		MDG-a\_10\_n500\_m50 & 7544.26 & 3.03 & 2.016837\\
		MDG-b\_21\_n2000\_m200 & 10992775.091951 & 2.72 & 27.771752\\
		MDG-b\_22\_n2000\_m200 & 10976004.218225 & 2.75 & 27.515051\\
		MDG-b\_23\_n2000\_m200 & 11010381.091843 & 2.56 & 27.593846\\
		MDG-b\_24\_n2000\_m200 & 11004690.027815 & 2.53 & 27.324046\\
		MDG-b\_25\_n2000\_m200 & 11050334.301811 & 2.18 & 27.377645\\
		MDG-b\_26\_n2000\_m200 & 11009755.0324 & 2.5 & 27.681516\\
		MDG-b\_27\_n2000\_m200 & 10973671.631925 & 2.94 & 27.388455\\
		MDG-b\_28\_n2000\_m200 & 11007899.484688 & 2.41 & 27.441754\\
		MDG-b\_29\_n2000\_m200 & 10965254.29057 & 2.94 & 27.687189\\
		MDG-b\_30\_n2000\_m200 & 10969766.811796 & 2.89 & 27.704564\\
		MDG-c\_1\_n3000\_m300 & 24234790 & 2.61 & 81.964096\\
		MDG-c\_2\_n3000\_m300 & 24291889 & 2.46 & 81.279382\\
		MDG-c\_8\_n3000\_m400 & 42565620 & 2.01 & 122.55461\\
		MDG-c\_9\_n3000\_m400 & 42575671 & 1.98 & 124.047167\\
		MDG-c\_10\_n3000\_m400 & 42429806 & 2.41 & 125.035444\\
		MDG-c\_13\_n3000\_m500 & 65814139 & 1.79 & 157.365497\\
		MDG-c\_14\_n3000\_m500 & 65837578 & 1.71 & 158.397447\\
		MDG-c\_15\_n3000\_m500 & 65882485 & 1.66 & 157.807931\\
		MDG-c\_19\_n3000\_m600 & 94069575 & 1.64 & 193.966365\\
		MDG-c\_20\_n3000\_m600 & 94140624 & 1.57 & 192.747059\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo AGG con cruce basado en posición
		en cada caso de estudio.}
	\label{tab:agg-posicion}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		2.54 & 56.34 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

\subsubsection*{AGE con cruce uniforme}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7699.87 & 1.71 & 1.935585\\
		MDG-a\_2\_n500\_m50 & 7577.32 & 2.5 & 1.79422\\
		MDG-a\_3\_n500\_m50 & 7539.43 & 2.83 & 1.799771\\
		MDG-a\_4\_n500\_m50 & 7527.6 & 3.12 & 1.755444\\
		MDG-a\_5\_n500\_m50 & 7492.01 & 3.39 & 1.743837\\
		MDG-a\_6\_n500\_m50 & 7604.02 & 2.18 & 1.792661\\
		MDG-a\_7\_n500\_m50 & 7509.91 & 3.37 & 1.791742\\
		MDG-a\_8\_n500\_m50 & 7564.46 & 2.41 & 1.74758\\
		MDG-a\_9\_n500\_m50 & 7567.89 & 2.6 & 1.818509\\
		MDG-a\_10\_n500\_m50 & 7579.83 & 2.58 & 1.940848\\
		MDG-b\_21\_n2000\_m200 & 11096803.204221 & 1.8 & 28.572898\\
		MDG-b\_22\_n2000\_m200 & 11066582.864213 & 1.95 & 30.746676\\
		MDG-b\_23\_n2000\_m200 & 11103929.892324 & 1.73 & 28.877216\\
		MDG-b\_24\_n2000\_m200 & 11108833.598636 & 1.61 & 29.766053\\
		MDG-b\_25\_n2000\_m200 & 11089928.650404 & 1.82 & 30.116922\\
		MDG-b\_26\_n2000\_m200 & 11072601.605505 & 1.95 & 28.99646\\
		MDG-b\_27\_n2000\_m200 & 11098217.011779 & 1.84 & 31.245306\\
		MDG-b\_28\_n2000\_m200 & 11091400.95864 & 1.67 & 31.786776\\
		MDG-b\_29\_n2000\_m200 & 11056917.76965 & 2.13 & 29.736697\\
		MDG-b\_30\_n2000\_m200 & 11098912.065773 & 1.75 & 31.97064\\
		MDG-c\_1\_n3000\_m300 & 24515388 & 1.48 & 98.19262\\
		MDG-c\_2\_n3000\_m300 & 24514080 & 1.57 & 94.704585\\
		MDG-c\_8\_n3000\_m400 & 42758112 & 1.56 & 136.57157\\
		MDG-c\_9\_n3000\_m400 & 42837534 & 1.38 & 134.870618\\
		MDG-c\_10\_n3000\_m400 & 42870141 & 1.39 & 139.704011\\
		MDG-c\_13\_n3000\_m500 & 66172152 & 1.26 & 180.704192\\
		MDG-c\_14\_n3000\_m500 & 66320235 & 0.98 & 170.5091\\
		MDG-c\_15\_n3000\_m500 & 66331255 & 0.99 & 175.780283\\
		MDG-c\_19\_n3000\_m600 & 94735806 & 0.94 & 214.486399\\
		MDG-c\_20\_n3000\_m600 & 94753449 & 0.93 & 220.617744\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo AGE con cruce uniforme
		en cada caso de estudio.}
	\label{tab:age-uniforme}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		1.91 & 62.87 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

\subsubsection*{AGE con cruce basado en posición}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7499.7 & 4.27 & 1.925836\\
		MDG-a\_2\_n500\_m50 & 7507.96 & 3.39 & 1.943304\\
		MDG-a\_3\_n500\_m50 & 7537.63 & 2.86 & 1.957983\\
		MDG-a\_4\_n500\_m50 & 7646.03 & 1.6 & 1.926846\\
		MDG-a\_5\_n500\_m50 & 7577.33 & 2.29 & 1.942608\\
		MDG-a\_6\_n500\_m50 & 7533.03 & 3.1 & 1.934613\\
		MDG-a\_7\_n500\_m50 & 7627.8 & 1.85 & 1.925517\\
		MDG-a\_8\_n500\_m50 & 7621.37 & 1.67 & 1.929454\\
		MDG-a\_9\_n500\_m50 & 7581.98 & 2.42 & 1.937019\\
		MDG-a\_10\_n500\_m50 & 7591.91 & 2.42 & 1.988036\\
		MDG-b\_21\_n2000\_m200 & 10971888.149454 & 2.9 & 28.643575\\
		MDG-b\_22\_n2000\_m200 & 11027565.453894 & 2.3 & 28.229621\\
		MDG-b\_23\_n2000\_m200 & 10984557.930365 & 2.79 & 28.259755\\
		MDG-b\_24\_n2000\_m200 & 11019573.82926 & 2.4 & 28.206778\\
		MDG-b\_25\_n2000\_m200 & 11031909.811213 & 2.34 & 28.188983\\
		MDG-b\_26\_n2000\_m200 & 10972375.024121 & 2.83 & 28.235294\\
		MDG-b\_27\_n2000\_m200 & 11019671.669981 & 2.53 & 29.779949\\
		MDG-b\_28\_n2000\_m200 & 11003349.24807 & 2.45 & 28.305121\\
		MDG-b\_29\_n2000\_m200 & 10984303.49364 & 2.77 & 28.312105\\
		MDG-b\_30\_n2000\_m200 & 11018900.201837 & 2.46 & 28.268545\\
		MDG-c\_1\_n3000\_m300 & 24257830 & 2.52 & 79.378184\\
		MDG-c\_2\_n3000\_m300 & 24288993 & 2.47 & 80.020735\\
		MDG-c\_8\_n3000\_m400 & 42566989 & 2 & 122.195934\\
		MDG-c\_9\_n3000\_m400 & 42606289 & 1.91 & 123.499277\\
		MDG-c\_10\_n3000\_m400 & 42579055 & 2.06 & 123.454948\\
		MDG-c\_13\_n3000\_m500 & 65940834 & 1.6 & 162.591331\\
		MDG-c\_14\_n3000\_m500 & 65888399 & 1.63 & 160.209596\\
		MDG-c\_15\_n3000\_m500 & 65949859 & 1.56 & 159.929673\\
		MDG-c\_19\_n3000\_m600 & 94208266 & 1.49 & 198.198681\\
		MDG-c\_20\_n3000\_m600 & 94167554 & 1.54 & 198.774549\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo AGE con cruce basado en posición
		en cada caso de estudio.}
	\label{tab:age-posicion}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		2.35 & 57.07 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

\subsubsection*{AM-(10,1.0)}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7700.82 & 1.7 & 0.185877\\
		MDG-a\_2\_n500\_m50 & 7721.71 & 0.64 & 0.163316\\
		MDG-a\_3\_n500\_m50 & 7705.94 & 0.69 & 0.19582\\
		MDG-a\_4\_n500\_m50 & 7645.81 & 1.6 & 0.203958\\
		MDG-a\_5\_n500\_m50 & 7643.15 & 1.45 & 0.210678\\
		MDG-a\_6\_n500\_m50 & 7664.54 & 1.4 & 0.186335\\
		MDG-a\_7\_n500\_m50 & 7700.58 & 0.92 & 0.180075\\
		MDG-a\_8\_n500\_m50 & 7692.35 & 0.76 & 0.202284\\
		MDG-a\_9\_n500\_m50 & 7623.02 & 1.89 & 0.174959\\
		MDG-a\_10\_n500\_m50 & 7711.32 & 0.89 & 0.165259\\
		MDG-b\_21\_n2000\_m200 & 11098034.367619 & 1.79 & 12.714229\\
		MDG-b\_22\_n2000\_m200 & 11114872.596709 & 1.52 & 13.74357\\
		MDG-b\_23\_n2000\_m200 & 11046514.713112 & 2.24 & 13.221175\\
		MDG-b\_24\_n2000\_m200 & 11085811.030799 & 1.82 & 12.426276\\
		MDG-b\_25\_n2000\_m200 & 11108364.164213 & 1.66 & 13.379022\\
		MDG-b\_26\_n2000\_m200 & 11101324.660648 & 1.69 & 12.462323\\
		MDG-b\_27\_n2000\_m200 & 11108922.583065 & 1.74 & 12.367685\\
		MDG-b\_28\_n2000\_m200 & 11114670.65925 & 1.46 & 12.96751\\
		MDG-b\_29\_n2000\_m200 & 11163653.99827 & 1.18 & 12.191321\\
		MDG-b\_30\_n2000\_m200 & 11092297.742468 & 1.81 & 11.631424\\
		MDG-c\_1\_n3000\_m300 & 24501042 & 1.54 & 41.494163\\
		MDG-c\_2\_n3000\_m300 & 24455245 & 1.81 & 39.206223\\
		MDG-c\_8\_n3000\_m400 & 42827259 & 1.4 & 52.130071\\
		MDG-c\_9\_n3000\_m400 & 42743253 & 1.6 & 50.978821\\
		MDG-c\_10\_n3000\_m400 & 42808199 & 1.54 & 51.95662\\
		MDG-c\_13\_n3000\_m500 & 66183870 & 1.24 & 70.166402\\
		MDG-c\_14\_n3000\_m500 & 66120270 & 1.28 & 67.915979\\
		MDG-c\_15\_n3000\_m500 & 66236107 & 1.13 & 65.384416\\
		MDG-c\_19\_n3000\_m600 & 94745444 & 0.93 & 79.415658\\
		MDG-c\_20\_n3000\_m600 & 94389441 & 1.31 & 89.668006\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo AM-(10,1.0).}
	\label{tab:am-10-1}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		1.42 & 24.58 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

\subsubsection*{AM-(10,0.1)}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7665.34 & 2.15 & 0.444765\\
		MDG-a\_2\_n500\_m50 & 7638.93 & 1.71 & 0.424028\\
		MDG-a\_3\_n500\_m50 & 7659.83 & 1.28 & 0.427798\\
		MDG-a\_4\_n500\_m50 & 7594.19 & 2.27 & 0.454077\\
		MDG-a\_5\_n500\_m50 & 7644.02 & 1.43 & 0.423357\\
		MDG-a\_6\_n500\_m50 & 7602.98 & 2.2 & 0.43389\\
		MDG-a\_7\_n500\_m50 & 7622.97 & 1.91 & 0.425276\\
		MDG-a\_8\_n500\_m50 & 7646.34 & 1.35 & 0.409405\\
		MDG-a\_9\_n500\_m50 & 7644.58 & 1.62 & 0.408827\\
		MDG-a\_10\_n500\_m50 & 7623.36 & 2.02 & 0.415836\\
		MDG-b\_21\_n2000\_m200 & 11154224.651148 & 1.29 & 24.167352\\
		MDG-b\_22\_n2000\_m200 & 11195682.50995 & 0.81 & 25.845168\\
		MDG-b\_23\_n2000\_m200 & 11193129.056159 & 0.95 & 23.585301\\
		MDG-b\_24\_n2000\_m200 & 11154194.151774 & 1.21 & 27.342935\\
		MDG-b\_25\_n2000\_m200 & 11181857.898937 & 1.01 & 23.255834\\
		MDG-b\_26\_n2000\_m200 & 11185064.252571 & 0.95 & 24.836796\\
		MDG-b\_27\_n2000\_m200 & 11186293.835698 & 1.06 & 23.695422\\
		MDG-b\_28\_n2000\_m200 & 11136103.80939 & 1.27 & 21.437087\\
		MDG-b\_29\_n2000\_m200 & 11164170.189057 & 1.18 & 23.421367\\
		MDG-b\_30\_n2000\_m200 & 11154631.751513 & 1.26 & 24.846379\\
		MDG-c\_1\_n3000\_m300 & 24728126 & 0.63 & 84.572393\\
		MDG-c\_2\_n3000\_m300 & 24697000 & 0.84 & 72.995771\\
		MDG-c\_8\_n3000\_m400 & 43165013 & 0.63 & 100.799762\\
		MDG-c\_9\_n3000\_m400 & 43149724 & 0.66 & 105.070718\\
		MDG-c\_10\_n3000\_m400 & 43187178 & 0.66 & 100.059467\\
		MDG-c\_13\_n3000\_m500 & 66773925 & 0.36 & 122.149366\\
		MDG-c\_14\_n3000\_m500 & 66647248 & 0.5 & 119.359096\\
		MDG-c\_15\_n3000\_m500 & 66732655 & 0.39 & 116.756599\\
		MDG-c\_19\_n3000\_m600 & 95201709 & 0.45 & 140.959524\\
		MDG-c\_20\_n3000\_m600 & 95187705 & 0.48 & 141.718517\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo AM-(10,0.1).}
	\label{tab:am-10-01}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		1.15 & 45.04 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

\subsubsection*{AM-(10,0.1mej)}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7637.16 & 2.51 & 0.414972\\
		MDG-a\_2\_n500\_m50 & 7724.21 & 0.61 & 0.41606\\
		MDG-a\_3\_n500\_m50 & 7650.23 & 1.41 & 0.411984\\
		MDG-a\_4\_n500\_m50 & 7619.15 & 1.94 & 0.431361\\
		MDG-a\_5\_n500\_m50 & 7683.11 & 0.93 & 0.415595\\
		MDG-a\_6\_n500\_m50 & 7606.02 & 2.16 & 0.406575\\
		MDG-a\_7\_n500\_m50 & 7671.13 & 1.29 & 0.407201\\
		MDG-a\_8\_n500\_m50 & 7640.97 & 1.42 & 0.417129\\
		MDG-a\_9\_n500\_m50 & 7623.97 & 1.88 & 0.392046\\
		MDG-a\_10\_n500\_m50 & 7609.15 & 2.2 & 0.387585\\
		MDG-b\_21\_n2000\_m200 & 11132452.586865 & 1.48 & 19.528066\\
		MDG-b\_22\_n2000\_m200 & 11189058.525244 & 0.87 & 23.840448\\
		MDG-b\_23\_n2000\_m200 & 11199499.507476 & 0.89 & 25.008253\\
		MDG-b\_24\_n2000\_m200 & 11153274.975023 & 1.22 & 25.542597\\
		MDG-b\_25\_n2000\_m200 & 11197661.105297 & 0.87 & 25.065803\\
		MDG-b\_26\_n2000\_m200 & 11175094.576497 & 1.04 & 22.660221\\
		MDG-b\_27\_n2000\_m200 & 11214002.699731 & 0.81 & 24.63223\\
		MDG-b\_28\_n2000\_m200 & 11190418.039251 & 0.79 & 23.46206\\
		MDG-b\_29\_n2000\_m200 & 11181245.238434 & 1.03 & 20.418433\\
		MDG-b\_30\_n2000\_m200 & 11165943.182085 & 1.15 & 21.691616\\
		MDG-c\_1\_n3000\_m300 & 24680269 & 0.82 & 68.57299\\
		MDG-c\_2\_n3000\_m300 & 24667185 & 0.96 & 74.06677\\
		MDG-c\_8\_n3000\_m400 & 43190089 & 0.57 & 86.488724\\
		MDG-c\_9\_n3000\_m400 & 43125997 & 0.72 & 98.001809\\
		MDG-c\_10\_n3000\_m400 & 43136622 & 0.78 & 88.114333\\
		MDG-c\_13\_n3000\_m500 & 66704966 & 0.46 & 112.764369\\
		MDG-c\_14\_n3000\_m500 & 66664685 & 0.47 & 110.111094\\
		MDG-c\_15\_n3000\_m500 & 66655997 & 0.5 & 109.479115\\
		MDG-c\_19\_n3000\_m600 & 95292197 & 0.36 & 130.071368\\
		MDG-c\_20\_n3000\_m600 & 95132559 & 0.53 & 121.509782\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo AM-(10,0.1mej).}
	\label{tab:am-10-01mej}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		1.09 & 41.17 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

Comparamos los estadísticos medios obtenidos estos algoritmos entre sí y con los obtenidos por los algoritmos
de búsqueda local (con primer mejor) y greedy de la práctica anterior.

\begin{table}[H]
	\centering
	\begin{tabular}{|ccc|}
		\hline
		Algoritmo & Desv & Tiempo (s)\\ \hline
		Greedy & 1.63 & 1.19 \\
		BL & 1.3 & 0.69 \\
		AGG-uniforme & 1.52 & 90.12 \\
		AGG-posicion & 2.54 & 56.34 \\
		AGE-uniforme & 1.91 & 62.87 \\
		AGE-posicion & 2.35 & 57.07 \\
		AM-(10,1.0) & 1.42 & 24.58 \\
		AM-(10,0.1) & 1.15 & 45.04 \\
		AM-(10,0.1mej) & 1.09 & 41.17 \\
		\hline
	\end{tabular}
	\caption{Comparativa de los estadísticos medios obtenidos por los distintos algoritmos.}
	\label{tab:comparativa}
\end{table}

\subsection{Análisis de resultados}

A la vista de la Tabla \ref{tab:comparativa}, intuimos que todos son algoritmos decentes para la resolución
de este problema, aunque hay diferencias entre ellos.

Sin duda, los tiempos de los algoritmos que sólo manejan una solución (búsqueda local y greedy) en lugar de
una población de soluciones son mucho más rápidos. El tiempo de cómputo de estos algoritmos tiene un orden
de magnitud bastante inferior a los algoritmos basados en poblaciones. En cuanto a fitness, los algoritmos de
la práctica 1 obtienen mejores resultados (en general) que los genéticos, pero se ven superados por los meméticos, que
obtienen los mejores resultados entre las alternativas que consideramos.

\subsubsection*{A grandes rasgos: algoritmos genéticos frente a meméticos}

Respecto a la fitness conseguida, la ninguno de los \textbf{algoritmos genéticos} logra superar a la búsqueda local, y sólo
el AGG-uniforme supera (por poco) a greedy. Esto posiblemente se deba a la falta de explotación en estos algoritmos, ya que
no buscan explícitamente soluciones mejores, sino esperan que se generen por medio de cruces y mutaciones y se
mantengan por la simulación que hacemos de selección natural.

El problema de los algoritmos genéticos es que cuando la mejor solución es replicada en muchos de los cromosomas,
algo que acaba pasando debido al comportamiento del algoritmo y a lo que llamamos ``convergencia del algoritmo'',
es muy difícil que el algoritmo encuentre nuevas soluciones. Esto se debe a que el operador de cruce de dos
soluciones idénticas genera hijos idénticos a los padres. Por tanto, es posible que rápidamente toda la población
se vea ``invadida'' por una o varias soluciones mejores que el resto, y esto lleve a una pérdida de diversidad
 (me refiero a diversidad genética, variedad entre soluciones) significativa. Por tanto, es posible que estos algoritmos
 converjan (encuentren una solución buena) rápidamente y después se pasen un gran número de iteraciones trabajando con
 soluciones muy similares hasta que una mutación o cruce fortuito mejore la fitness de la población, dando lugar
 a un gran número de evaluaciones desperdiciadas.

Para justificar esta hipótesis, resaltamos que la función que calcula los índices de la peor y segunda peor solución de la población en
el esquema estacionario (se invoca en el Algoritmo \ref{alg:replacement-stationary}) acaba devolviendo 0 y 1 a partir
de un número de iteraciones, y rara vez vuelve a devolver valores distintos. Esto quiere decir que encontrar soluciones
mejores es muy difícil para el algoritmo a partir de cierto punto, y se limita a agotar las evaluaciones restantes
con la esperanza de que alguna mutación o cruce origine una solución mejor.

Podríamos pensar que nuestra implementación del reemplazamiento elitista en AGG puede ser causante de este problema
(ver comentarios tras Algoritmo \ref{alg:replacement-agg}), pero esto no explica el problema en el caso de AGE, que
de hecho obtiene soluciones peores en media (ligeramente mejores para el cruce basado en posición, pero peores
para el cruce uniforme). Por tanto nuestra implementación del elitismo como mucho acentúa ligeramente este problema,
que es intrínseco a los algoritmos genéticos.

Para solventar esto, añadimos un componente de explotación como es la búsqueda local, dando lugar a los \textbf{algoritmos
meméticos} (implementados sobre el esquema generacional con cruce uniforme, el AGG que mejores resultados obtiene).
De esta forma, una parte de las evaluaciones se dedica a la exploración (genéticos) y otra a la explotación (búsqueda local). Este
equilibrio los convierte en los más adecuados para el problema entre las alternativas consideradas, ya que consiguen las mejores
fitness con la excepción del AM-(10,1.0), que es ligeramente superado por la búsqueda local.

Además, estos algoritmos consiguen un
efecto que combate el problema de la pérdida de la convergencia demasiado rápida en los algoritmos genéticos que hemos comentado
anteriormente. Aplicar la búsqueda local a algunas soluciones separa los miembros de la población unos de otros y da lugar a un
conjunto más variado de soluciones. Por ejemplos, si el algoritmo encuentra una buena solución que acaba copiándose multiples veces
y desbancando al resto, aplicar búsqueda local a algunas de las copias de esa solución provocarán que el conjunto de soluciones sea
más variado, con lo que podemos esperar cruces de soluciones más distintas y que alguno de ellos dé lugar a una solución mejor. Esta mejora
se nota menos en AM-(10,1.0), ya que aplica búsqueda local a todos los cromosomas y no sólo a algunos, de hecho esta variante de memético
consigue los peores resultados entre este tipo de algoritmo. El hecho de que la búsqueda local se realice con primer mejor y explorando
los entornos en orden aleatorio, consigue que soluciones iguales se transformen en soluciones distintas, debido a que la aleatoriedad de
exploración del entorno provoca que no se salte siempre al mismo vecino (al contrario que en la búsqueda local con mejor), esta
 diversificación ocurre también aunque se aplique búsqueda local a todas las soluciones y no sólo a algunas, luego también mejora 
  AM-(10,1.0). Ésto sin mencionar que la alternaiva del primer mejor consume muchísimas menos evaluaciones que la búsqueda local con mejor,
  lo que comprobamos como trabajo voluntario en la anterior práctica.
  
En resumen, los algoritmos genéticos carecen de explotación y pueden tener el problema de que se pierda la diversidad demasiado pronto,
y la introducción de la búsqueda local combate ambos problemas.

Respecto al tiempo, los algoritmos meméticos tardan mucho menos, ya que en la búsqueda local se dedica mucho más porcentaje del
tiempo de cómputo a evaluar soluciones. Además, estas evaluaciones son mucho más rápidas al calcularse la fitness de forma
factorizada.
  
\subsubsection*{Cruce uniforme frente a cruce basado en posición}

El operador de cruce uniforme proporciona mejores resultados, lo que puede deberse a que palia esa pérdida de diversidad genética que
hemos comentado. A pesar de que parecen muy similares (los dos respetan las decisiones tomadas por ambos padres), existe una diferencia
que hace mejor al cruce uniforme.

Primero, ambos cruces eligen y descartan los elementos en los que ambos padres estén de acuerdo. Después se rellena la solución de
forma aleatoria en ambos casos, con la siguiente diferencia: la probabilidad de que un elemento sólo seleccionado por uno de los padres
sea seleccionado por el hijo es siempre de \\ $\dfrac{\text{número de huecos por cubrir}}{\text{número de elementos seleccionados por sólo un padre}}$ en el cruce basado en posición, mientras que en el cruce uniforme esta probabilidad depende de la aportación del elemento.
En cruce uniforme se introduce cada uno de los elementos con probabilidad 0.5, y a partir de ahí se elimina o se añade el que más aporta
dependiendo de si faltan o sobran elementos. De esta forma, algunos hijos llevan un componente de explotación que recuerda al greedy
 (cuando faltan elementos y se añaden los
que más aportan), mientras que otros hijos se empeoran a propósito para no quedarnos sin variedad en las soluciones (cuando sobran
 elementos y se eliminan los que más aportan). Este comportamiento sugiere que los hijos procedentes de cruces uniformes serán más
variados que los basados en posición, y además habrá algunos hijos (en los que se añadan elementos de fuera) que tendrán cierta
componente de explotación similar a la del greedy, lo que podría solventar parcialmente los problemas de los algoritmos genéticos que
comentamos con anterioridad.

Como consecuencia usamos el cruce uniforme (y el esquema generacional) para los algoritmos meméticos.

Respecto al tiempo, el algoritmo de reparación puede requerir varias búsquedas del elemento que más aporta, que son bastante costosas,
sobre todo cuando vienen de fuera de la solución. Esto provoca que sea más lento, se aprecia más en el esquema generacional.

\subsubsection*{AGG frente a AGE}

No hay una gran diferencia en los resultados obtendios por ambos esquemas de reemplazamiento. El esquema generacional ha resultado
algo más efectivo en media debido a su mejor desempeño con el cruce uniforme.
Respecto a tiempos, el esquema generacional es algo más lento cuando se utiliza el cruce uniforme. 

\subsubsection*{Variantes de meméticos}

Además de añadir una componente de explotación de la que carecen los algoritmos genéticos. Hemos explicado cómo la introducción de
la búsqueda local (sobre todo con primer mejor) aumenta la diversidad entre los cromosomas, es más notable en las variantes en las que sólo
se aplica a algunos de los cromosomas. Como consecuencia, los algoritmos meméticos proporcionan (en en media) los mejores resultados

Dentro de los los meméticos, AM-(10,0.1) y AM-(10,0.1mej) ofrecen un mejor desempeño debido a esa mayor diversidad genética en las soluciones y a que
no compensa invertir demasiadas itereaciones en mejorar todos los cromosomas, ya que cierto número de soluciones no sobreviven cada
generación. 

Dentro de sólo aplicar la búsqueda local a algunas soluciones, obtiene ligeramente mejores resultados (en media) la alternativa que la aplica
a las mejores (a las 10\% mejores), probablemente debido a que aprovechan mejor la explotación. Mejoran aun más las soluciones con más
fitness, lo que al cabo de varias generaciones se traduce en una mayor mejora de la población. Puesto que la búsqueda local sólo
se realiza hasta consumir 400 evaluaciones por cromosoma, las mejores más altas tienen más posibilidades de alcanzar una mayor fitness.

Respecto al tiempo, AM-(10,1.0) es el memético más rápido con diferencia, ya que dedica 10 veces más que las otras variantes a hacer
búsqueda local, que es una forma mucho más rápida de consumir evaluaciones por la cantidad que hace y por hacerlas factorizadas.

\end{document}
