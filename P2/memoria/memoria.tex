\documentclass{article}

\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry} 

\usepackage[utf8]{inputenc}   % otra alternativa para los caracteres acentuados y la "Ã±"
\usepackage[           spanish % para poder usar el espaÃ±ol
                      ,es-tabla % para los captions de las tablas
                       ]{babel}   
\decimalpoint %para usar el punto decimal en vez de coma para los nÃºmeros con decimales

%\usepackage{beton}
%\usepackage[T1]{fontenc}

\usepackage{parskip}
\usepackage{xcolor}

\usepackage{caption}

\usepackage{enumerate} % paquete para poder personalizar fÃ¡cilmente la apariencia de las listas enumerativas

\usepackage{graphicx} % figuras
\usepackage{subfigure} % subfiguras

\usepackage{amsfonts}
\usepackage{amsmath}

\usepackage{listings}
\lstset
{ %Formatting for code in appendix
    language=python,
    basicstyle=\footnotesize,
    stepnumber=1,
    showstringspaces=false,
    tabsize=1,
    breaklines=true,
    breakatwhitespace=false,
}

\definecolor{gris}{RGB}{220,220,220}
	
\usepackage{float} % para controlar la situaciÃ³n de los entornos flotantes

\restylefloat{figure}
\restylefloat{table} 
\setlength{\parindent}{0mm}


\usepackage[bookmarks=true,
            bookmarksnumbered=false, % true means bookmarks in 
                                     % left window are numbered
            bookmarksopen=false,     % true means only level 1
                                     % are displayed.
            colorlinks=true,
            allcolors=blue,
            urlcolor=blue]{hyperref}
\definecolor{webblue}{rgb}{0, 0, 0.5}  % less intense blue

\usepackage[ruled,vlined]{algorithm2e}
\SetKwInOut{Parameter}{parameter}


\title{\Huge Metaheurísticas: Práctica 2 \\ Técnicas de Búsqueda basadas en Poblaciones \\ para el Problema de la Máxima Diversidad \vspace{10mm}}

\author{\huge David Cabezas Berrido \vspace{10mm} \\
	\huge 20079906D \vspace{10mm} \\  
  \huge Grupo 2: Viernes \vspace{10mm} \\ 
  \huge dxabezas@correo.ugr.es \vspace{10mm}}

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage

\section{Descripción y formulación del problema}

Nos enfrentamos al \textbf{Problema de la Máxima Diversidad} (\textbf{Maximum Diversity Problem, MDP}). El problema consiste en seleccionar
un subconjunto $m$ elementos de un conjunto de $n>m$ elementos de forma que se \textbf{maximice} la \emph{diversidad} entre los
 elementos escogidos.
 
 Disponemos de una matriz $D=(d_{ij})$ de dimensión $n\times n$ que contiene las distancias entre los elementos, la entrada $(i,j)$ contiene el
 valor $d_{ij}$, que corresponde a la distancia entre el elemento $i$-ésimo y el $j$-ésimo. Obviamente, la matriz $D$ es simétrica y con
 diagonal nula.
 
 Existen distintas formas de medir la diversidad, que originan distintas variantes del problema. En nuestro caso, la diversidad será la suma
 de las distancias entre cada par de elementos seleccionados.

De manera formal, se puede formular el problema de la siguiente forma:

\begin{description}
	\item Maximizar 
	\begin{equation} \label{eq:objetivo}
		f(x)=\sum_{i=1}^{n-1}\sum_{j=i+1}^n d_{ij} x_i x_j
	\end{equation}
	\item sujeto a 
	\begin{align*}
		\sum_{i=1}^n x_i &= m \\
		x_i&= \{0,1\}, \quad\forall i=1,\ldots, n.
	\end{align*}
\end{description}

Una solución al problema es un vector binario $x$ que indica qué elementos son seleccionados, seleccionamos el elemento $i$-ésimo si $x_i=1$.

Sin embargo, esta formulación es poco eficiente y para la mayoría de algoritmos proporcionaremos otra equivalente pero más eficiente.

El problema es \textbf{NP-completo} y el tamaño del espacio de soluciones es $\dbinom{n}{m}$, de modo que es conveniente recurrir al uso de metaheurísticas
para atacarlo.

\pagebreak

\section{Aplicación de los algoritmos}

Los algoritmos para resolver este problema tendrán como entradas la matriz $D$ ($n\times n$) y el valor $m$. La salida será un contenedor
(vector, conjunto, \ldots) con los índices de los elementos seleccionados, y no un vector binario como el que utilizamos para la formulación.
 En nuestro caso utilizaremos vectores de enteros para representar soluciones.

\textbf{Nota:} Al contrario de lo recomendado, mantenemos la representación entera (vector de enteros con los elementos seleccionados) en lugar de cambiar a la binaria para las soluciones.
Esto conlleva la traducción de los operadores a la nueva representación. Sin embargo, aunque la descripción detallada de los operadores es
algo más compleja, entender su funcionamiento es bastante más fácil con la representación entera. 

La evaluación de la calidad de una solución se hará
sumando la contribución de cada uno de los elementos, y dividiremos la evaluación en dos funciones. En lugar de calcular la función evaluación como en
\eqref{eq:objetivo}, lo haremos así:
\begin{equation} \label{eq:objetivo-fact}
f(x)=\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^m d(i,j)=\frac{1}{2}\sum_{i=1}^{m}\operatorname{contrib}(i)
\end{equation}
La diferencia es que contamos la distancia entre cada dos elementos $i,j$ dos veces, distancia del elemento $i$-ésimo al $j$-ésimo y del $j$-ésimo al
$i$-ésimo. Esto es obviamente más lento que con $j>i$ en la sumatoria, pero nos permite factorizar la evaluación de la solución como suma de las
 contribuciones de los elementos, lo cuál será útil para reaprovechar cálculos al evaluar soluciones para la Búsqueda Local.
 Además, representar la solución como un vector de $m$ índices y no un vector binario de longitud $n$ presenta una clara ventaja: las sumatorias van hasta
 $m$ en lugar de $n$. No tenemos que computar distancias para luego multiplicarlas por cero como sugería la formulación en \eqref{eq:objetivo}.

Presentamos el pseudocódigo de la función para calcular la contribución de un elemento $x_i$.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de índices $S$.}
	\KwIn{La matriz de distancias $D$.}
	\KwIn{Un entero $e$ correspondiente al índice del elemento.}
	\KwOut{La contribución del elemento $e$, como se describe en \eqref{eq:objetivo-fact}.}
	$contrib \gets 0$\;
	\For{$s$ \textbf{in} $S$} {
		$contrib \gets contrib + D[e,s]$ \tcp*{Sumo las distancias del elemento $e$ a cada elemento de $S$}
	}
	\Return{$contrib$}\;
	\caption{{\sc Contrib} calcula la contribución de un elemento en una solución.}
	\label{alg:contrib}
\end{algorithm}

Nótese que el elemento $e$ no tiene que pertenecer al conjunto $S$. Esto obviamente no ocurrirá cuando se vaya a evaluar una solución
al completo invocando esta función con la que describiremos a continuación. Pero, de esta forma, permite conocer cómo influirá en la evaluación el añadir
 un nuevo elemento sin necesidad de añadirlo realmente. 
 
 Ahora presentamos el pseudocódigo de la función para evaluar una solución completa.
 
 \begin{algorithm}[H]
 	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
 	\KwIn{Un vector de índices $S$.}
 	\KwIn{La matriz de distancias $D$.}
 	\KwOut{El valor de la función objetivo sobre la solución compuesta por $S$, como se describe en \eqref{eq:objetivo-fact}.}
 	$fitness \gets 0$\;
 	\For{$e$ \textbf{in} $S$} {
 		$fitness \gets fitness + \operatorname{contrib}(S,D,e)$ \tcp*{Sumo la contribución de cada elemento de la solución}
 	}
 	\Return{$fitness/2$} \tcp*{Hemos contado cada distancia dos veces}
 	\caption{{\sc Fitness} calcula la evaluación de una solución.}
 	\label{alg:eval}
 \end{algorithm}

Podemos definir la distancia de un elemento $e$ a un conjunto $S$ como:

\begin{equation} \label{eq:distance-elem-set}
	d(e,S)=\sum_{s\in S} d(e,s)
\end{equation}

Esta expresión nos será de utilidad para la implementación de los algoritmos.

Gracias a la existencia del Algoritmo \ref{alg:contrib}, podemos obtener esta expresión como $\operatorname{contrib}(S,D,e)$.

En esta práctica, implementamos cuatro variantes de algoritmos genéticos (dos generacionales y dos estacionarios) y tres variantes
de meméticos. Compararemos estos algoritmos entre sí y con los algoritmos Greedy y Búsqueda Local con Primer Mejor de la práctica anterior.

Para los pseudocódigos que siguen, suponemos la matriz de distancias $D$ y los parámetros $n$ y $m$ accesibles.
El conjunto de todos los elementos es el $\{0,\ldots,n-1\}$, para cuando nos refiramos a elementos de fuera de un subconjunto de ellos.

Inicializamos la población con soluciones aleatorias, usamos la siguiente función.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwOut{Una solución válida del MDP obtenida aleatoriamente.}
	$E \gets \{0,\ldots, n-1\}$ \tcp*{Vector con todos los elementos.}
	$\operatorname{shuffle}(E)$\;
	$S \gets \emptyset$ \tcp*{La solución empieza vacía.}
	\While{$|S|<m$}{
		$S \gets S\cup \{E[|S|]\}$ \tcp*{Seleccionamos los $m$ primeros elementos de $E$, que son aleatorios.}
	}
	\Return{$S$}\;
	\caption{{\sc RandomSol} proporciona una solución válida aleatoria}
	\label{alg:randomsol}
\end{algorithm}

\subsection{Operadores de los algoritmos genéticos}

Usaremos dos operadores de cruce distintos. El primero es el \textbf{cruce uniforme}, que dados dos padres mantiene los elementos
seleccionados por ambos (intersección) y por ninguno. Los elementos que sólo son seleccionados por uno de los padres se introducen
con un 0.5 de probabilidad, pudiendo dar lugar a soluciones con más de $m$ elementos seleccionados. Es por ello que se aplica un
\textbf{operador de reparación} posteriormente, que elimina (cuando sobran elementos) o añade (cuando faltan) siempre el elemento
que más contribuye (dentro o fuera de la solución, según haya que eliminar o añadir).

Cuando escribimos operaciones de conjuntos sobre vectores entendemos que no es relevante el orden
de los elementos. Con la unión entre un vector y un elemento, podemos añadir el elemento al final, por ejemplo.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de índices $S$.}
	\KwOut{El vector $S$ reparado (no lo devuelve, modifica el existente).}
	\While{$|S|>m$}{
		$g\gets\text{Elemento de $S$ que maximiza $\operatorname{contrib}(S,D,g)$}$\;
		$S\gets S\backslash\{g\}$\;
	}
	\While{$|S|<m$}{
		$g\gets\text{Elemento de fuera de $S$ que maximiza $\operatorname{contrib}(S,D,g)$}$\;
		$S\gets S\cup\{g\}$\;
	}
	\caption{{\sc Repair} repara un vector solución que puede no contener $m$ elementos (puede ser no válida).}
	\label{alg:reparacion}
\end{algorithm}

A continuación, proporcionamos el pseudocódigo del algoritmo de cruce uniforme.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Dos vectores de índices $S_1,S_2$.}
	\KwOut{Un vector solución $S$ (hijo).}
	$S\gets\emptyset$\;
	\ForEach{$e$ in $0,\ldots,n-1$}{
		\If{$e\in S_1$ and $e\in S_2$}{
			$S\gets S\cup\{e\}$\;
		}
		\ElseIf{$e\notin S_1$ and $e\notin S_2$}{
			No se incluye el elemento (no se hace nada).
		}
		\Else{
			Con probabilidad 0.5: $S\gets S\cup\{e\}$\;
		}
	}
	$\operatorname{repair}(S)$ \tcp*{La solución puede no ser factible.}
	\Return{$S$}
	\caption{{\sc UniformCross} genera un hijo cruzando dos padres.}
	\label{alg:uniform-cross}
\end{algorithm}

El otro operador de cruce que consideramos es el cruce basado en posición. Este operador respeta los seleccionados y descartados
por ambos padres, y completa con un subconjunto aleatorio de los elementos que sólo están seleccionados por uno de los padres hasta
obtener un vector con $m$ elementos seleccionados.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Dos vectores de índices $S_1,S_2$.}
	\KwOut{Un vector solución $S$ (hijo).}
	$S\gets\emptyset$\;
	$W\gets\emptyset$ \tcp*{Candidatos a completar la solución.}
	\ForEach{$e$ in $0,\ldots,n-1$}{
		\If{$e\in S_1$ and $e\in S_2$}{
			$S\gets S\cup\{e\}$\;
		}
		\ElseIf{$e\notin S_1$ and $e\notin S_2$}{
			No se incluye el elemento (no se hace nada).
		}
		\Else{
			$W\gets W\cup\{e\}$\;
		}
	}
	$W \gets \operatorname{shuffle}(W)$\;
	\While{$|S|<m$}{
		$e\gets W[0]$ \tcp*{Primer elemento de $W$, es aleatorio.}
		$S\gets S\cup\{e\}$\;
		$W\gets W\backslash\{e\}$\;
	}
	\Return{$S$}
	\caption{{\sc PositionCross} genera un hijo cruzando dos padres.}
	\label{alg:position-cross}
\end{algorithm}

Con la implementación que hemos hecho, ambos operadores sólo generan un hijo, por lo que llamaremos a estos operador dos veces cada vez que crucemos dos padres. Sería más eficiente generar dos hijos en cada ejecución para aprovechar parte de los cálculos.

Necesitamos también un operador de mutación. Éste saca un elemento aleatorio de una solución y mete un elemento aleatorio de fuera.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector solución $S$.}
	\KwOut{La solución $S$ modificada, la modifica en lugar de devolverla.}
	$e_{out}\gets\text{numero aleatorio entre $0$ y $m-1$}$ \tcp*{Posición del elemento a eliminar.}
	$e_{in}\gets\text{elemento aleatorio (número aleatorio entre $0$ y $n-1$)}$\;
	\While{$e_{in}\in S$}{
		$e_{in}\gets\text{elemento aleatorio}$ \tcp*{Forzamos que sea de fuera.}
	}
	$S[e_{out}]\gets e_{in}$\tcp*{Sustituimos el elemento a eliminar por el nuevo.}
	\caption{{\sc Mutate} modifica una solución cambiando un elemento.}
	\label{alg:mutate}
\end{algorithm}

Por último, necesitamos un operador de selección para elegir a los padres en cada iteración. Se hace uno de torneos binarios, donde se elige el mejor de dos soluciones aleatorias.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{El índice de la mejor solución entre dos elegidas aleatoriamente.}
	$i_1\gets\text{número aleatorio entre 0 y $|P|$}$\;
	$i_2\gets\text{número aleatorio entre 0 y $|P|$}$\;
	$sol_1\gets P[i_1]$\;
	$sol_2\gets P[i_2]$\;
	\tcc{$sol.fitness$ almacena el resultado de $\operatorname{fitness}(sol)$ por razones de eficiencia.}
	\If{$sol_1.fitness > sol_2.fitness$}{
		\Return{$i_1$}
	}
	\Else{
		\Return{$i_2$}
	}
	\caption{{\sc BinTournament} devuelve el índice de la mejor de dos soluciones aleatorias.}
	\label{alg:bin-tournament}
\end{algorithm}

El uso de esta selección para reemplazar la población dependerá del esquema (generacional o estacionario).

\subsection{Búsqueda local para los algoritmos meméticos}

Proporcionamos la implementación del algoritmo de búsqueda local que usaremos en los algoritmos meméticos. Modifica una solución
saltando al primer mejor vecino explorado hasta consumir un cierto número de evaluaciones o alcanzar un máximo local.

Suponemos accesibles las variables globales $LIMIT=100000$ (límite total de evaluaciones), $EVALS$ (evaluaciones totales hasta el momento, comienza
a 0)
y $limit=400$ (límite de evaluaciones en una búsqueda local).

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Solución de partida $S$.}
	\KwOut{La solución $S$ se modifica (no se devuelve) con varias iteraciones de búsqueda local.}
	$E \gets \{0,\ldots,n-1\}$ \tcp*{Vector con todos los elementos.}
	$evals \gets 0$\;
	$carryon \gets true$\;
	\While{carryon}{
		$carryon \gets false$\;
		$lowest\gets \text{indice del elemento de $S$ que menos contribuye, minimiza $\operatorname{contrib}(S,D,S[lowest])$}$\;
		%$min\_contrib \gets \operatorname{contrib}(S,D,lowest)$
		$E \gets \operatorname{shuffle}(E)$ \tcp*{Para explorar los posibles vecinos en orden aleatorio.}
		\For{$e$ \textbf{in} $E$} {
			\If{$e\in S$}{
				continue \tcp*{Si ya está escogido, no lo cuento.}
			}
			$contrib \gets \operatorname{contrib}(S,D,e)-D[e,S[lowest]]$ \tcp*{Contribución a la solución sin el elemento a sustituir.}
			$EVALS \gets EVALS+1$ \tcp*{He evaludado una posible solución.}
			$evals \gets evals+1$\;
			\If{$contrib > min\_contrib$} { 
				$S.fitness \gets S.fitness + contrib - min\_contrib$ \tcp*{Fitness de la nueva solución}
				$carryon \gets true$ \tcp*{Toca saltar, lo que completa la iteración}
				$S[lowest]\gets e$ \tcp*{Saltamos a la nueva solución}
			}
			\If{$carryon==true$ or $EVALS\geq LIMIT$ or $evals\geq limit$} { 
				break  \tcp*{Se cumple alguna de las condiciones de parada}
			}
		}
	}
	\caption{{\sc LocalSearch} modifica una solución con varias iteraciones de búsqueda local con primer mejor.}
	\label{alg:local-search}
\end{algorithm}

\pagebreak

\section{Descripción de los algoritmos}

Distinguimos dos clases de algoritmos genéticos, según el esquema de reemplazamiento.

\subsection{Algoritmo genético generacional}

Para seleccionar la nueva población se realizan tantos torneos binarios como el tamaño de la población. Para conservar la mejor solución
 (elitismo), ésta sustituye a la peor en caso de no sobrevivir a los torneos.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{La población $P'$ de padres para la siguiente generación. No se devuelve, se modifica P.}
	$P'\gets\emptyset$\;
	$best\gets\text{índice de la solución de $P$ con mayor fitness}$\;
	$elitism\gets false$ \tcp*{Para contemplar si sobrevive la mejor.}
	\While{$|P'|<|P|$}{
		$i\gets\operatorname{BinTournament}(P)$\;
		$P'\gets P'\cup\{P[i]\}$\;
		\If{$i=best$}{
			$elitism\gets true$ \tcp*{Ha sobrevivido.}
		}
	}
	\If{$elitism=false$}{
		$i\gets\text{índice de la solución de $P'$ con peor fitness}$\;
		$P'[i]\gets P[best]$\;
	}
	$P\gets P'$\;
	\caption{{\sc Replacement} devuelve la población de padres para la siguiente generación.}
	\label{alg:replacement}
\end{algorithm}

Hay que tener en cuenta que comparar si es la mejor solución por índice y no por fitness fuerza a que si hay soluciones repetidas
(ocurrirá tras varias iteraciones del algoritmo, cada vez más), se fuerza a salvar una copia concreta de la solución. Esto le da ventaja
a la mejor solución respecto a las demás, ya que puede salvarse y además copiarse una vez más.
Con esta comparación, se acelera la convergencia del algoritmo pero se reduce la variedad de soluciones, aunque
no en gran medida.

Para cruzar la población (de padres), se calcula el número esperado de cruces, $25\cdot\text{probabilidad de cruce}=18$ (nos quedamos
con un entero). El valor 25 proviene del número de parejas que se forman con la población de 50 cromosomas. Como el operador de
reemplazamiento construye una nueva población de padres aleatorios, podemos simplemente cruzar primero con segundo, tercero y cuarto, etc. (hasta llegar a 18 cruces).
El cruce de dos soluciones puede ser uniforme o posicional, se estudian las dos alternativas.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{En la población $P$, se sustituyen cada pareja de padres por sus hijos.}
	$n2cross=n\_chromosomes\cdot prob_{cross}$ \tcp*{Doble del número esperado de cruces.}
	\For{$i=0,2,4,\dots,n2cross-1$}{
		$child_1\gets \operatorname{Croos}(P[i],P[i+1])$\;
		$child_2\gets \operatorname{Croos}(P[i],P[i+1])$\;
		$P[i]\gets child_1$\;
		$P[i+1]\gets child_2$\;
	}
	\caption{{\sc Cross} cruza los padres de la población y los sustituye por los hijos.}
	\label{alg:cross-generational}
\end{algorithm}

Para la mutación, se calcula el número esperado de mutaciones. En este caso, el número de mutaciones no depende de $n$ y $m$, siempre
es el 10\% del número de cromosomas, 5. Tantas veces como el número esperado de mutaciones, se elige una solución aleatoria, y esta
muta un gen aleatorio como hemos descrito antes. El número de genes coincide con el parámetro $n$ del problema (debemos tener en cuenta
que los parámetros que nos proponen corresponden a la representación binaria).

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{En la población $P$ mutan algunas soluciones, no se devuelve nada.}
	$mutations=n\_chromosomes\cdot n\_genes\cdot prob_{mut}$ \tcp*{Donde $prob_{mut}=0.1\cdot n\_genes$.}
	\For{$i=0,1,\dots,mutations-1$}{
		$j\gets\text{número aleatorio entre $0$ y $|P|-1$}$ \tcp*{Índice de una solución aleatoria.}
		$\operatorname{mutate(P[j])}$ \tcp*{La solución muta un gen aleatorio.}
	}
	\caption{{\sc Mutate} muta algunas soluciones de la población.}
	\label{alg:mutate-generational}
\end{algorithm}

El esquema de reemplazamiento del algoritmo genético generacional es el siguiente.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población) inicializado con soluciones aleatorias.}
	\KwOut{La población $P$ (se modifica, no se devuelve) evoluciona tras varias generaciones.}
	\While{$EVAlS<LIMIT$}{
		$\operatorname{cross}(P)$\;
		$\operatorname{mutate}(P)$\;
		$\operatorname{evaluate}(P)$\;
		$\operatorname{replacement}(P)$\;
	}
	\caption{{\sc AGG}.}
	\label{alg:generational}
\end{algorithm}

En evaluación, se actualiza el fitness de cada solución, que se almacena por razones de eficiencia. Se usa un flag para evitar reevaluar soluciones
que no cambien de una generación a otra. El flag está en ``actualizado'' para nuevas soluciones aleatorias y productos de cruces y
mutaciones. Como la comprobación del límite de evaluaciones no se realiza en mitad de las iteraciones, podemos pasarnos del límite.
Sin embargo, el número máximo de evaluaciones por iteración es de 41 (36 hijos + 5 mutaciones), por lo que como mucho llegaremos a
100040 evaluaciones, lo que no supone mucho ni en tiempo ni en desempeño del algoritmo.

\subsection{Algoritmo genético estacionario}

En el esquema estacionario, sólo dos soluciones se cruzan y puden mutar en cada iteración. Los dos padres se eligen con dos
torneos binarios.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{Índices de dos padres.}
	$p_1\gets\operatorname{BinTournament}(P)$\;
	$p_2\gets\operatorname{BinTournament}(P)$\;
	\Return{$p_1,p_2$}\;
	\caption{{\sc Selection} devuelve los índices de dos padres, que selecciona por torneo binario.}
	\label{alg:selection-stationary}
\end{algorithm}

Dichos padres se cruzan para formar dos hijos, por cruce uniforme o basado en posición.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwIn{Los índices de los padres: $p_1$ y $p_2$.}
	\KwOut{Dos nuevas soluciones (hijos).}
	$child_1\gets\operatorname{cross}(P[p_1],P[p_2])$\;
	$child_2\gets\operatorname{cross}(P[p_1],P[p_2])$\;
	\Return{$child_1,child_2$}\;
	\caption{{\sc Cross} devuelve dos soluciones, producto del cruce de los padres.}
	\label{alg:cross-stationary}
\end{algorithm}

Se decide si mutan los hijos (cada uno con probabilidad 0.1, para preservar la esperanza de 0.2 mutaciones por iteración), y posteriormente sustituyen a las dos peores soluciones de la problación (siempre que las superen).
De las 4 soluciones (2 peores + 2 hijos), debemos quedarnos con las 2 mejores. Esto lo conseguimos con la siguiente función.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwIn{Los dos hijos: $child_1$ y $child_2$.}
	\KwOut{Modifica la población $P$ para sustituir las peores soluciones por los hijos (si estos las superan).}
	$w_1,w_2\gets\text{índices de la peor y segunda peor soluciones de $P$ respectivamente}$\;
	\If{$child_1.fitness>P[w_2].fitness$}{
		$P[w_1]\gets P[w_2]$\;
		$P[w_2]\gets child_1$\;
	}
	\ElseIf{$child_1.fitness>P[w_1].fitness$}{
		$P[w_1]\gets child_1$\;
	}
	\If{$child_2.fitness>P[w_1].fitness$}{
		$P[w_1]\gets child_2$\;
	}
	\caption{{\sc Replacement} se queda con las dos mejores de 4 soluciones: $\text{2 peores} + \text{2 hijos}$.}
	\label{alg:replacement-stationary}
\end{algorithm}

El ciclo de evolución queda de la siguiente forma.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población) inicializado con soluciones aleatorias.}
	\KwOut{La población $P$ (se modifica, no se devuelve) evoluciona tras varias iteraciones.}
	Se evalúan todas las soluciones (50 evaluaciones), se incrementa $EVALS$ en 50\;
	\While{$EVAlS<LIMIT$}{
		$p_1,p_2\gets\operatorname{selection}(P)$\;
		$\operatorname{cross}(P,p_1,p_2)$\;
		$child_1$ muta con probabilidad 0.1\;
		$child_2$ muta con probabilidad 0.1\;
		$\operatorname{evaluate}(child_1)$\;
		$\operatorname{evaluate}(child_2)$\;
		$EVALS\gets EVALS+2$\;
		$\operatorname{replacement}(P,child_1,child_2)$\;
	}
	\caption{{\sc AGE}.}
	\label{alg:stationary}
\end{algorithm}

\subsection{Algoritmos meméticos}

Los algoritmos meméticos combinan el esquema evolutivo generacional con el algoritmo de búsqueda local. Ya hemos mostrado la implementación
de búsqueda local a nivel de solución. Ahora mostraremos cómo se aplica la búsqueda local a nivel de población, lo que diferencia las
distintas variantes de meméticos.

En la primera versión, AM-(10,1.0), se aplica búsqueda local cada 10 generaciones sobre todos los cromosomas de la población.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{La población $P$ (se modifica, no se devuelve) después de que todas las soluciones mejoren con búsqueda local.}
	\ForEach{$sol$ in $P$}{
		$\operatorname{LocalSearch}(sol)$\;
	}
	\caption{{\sc LocalSearch} de AM-(10,1.0).}
	\label{alg:am-10-1}
\end{algorithm}

En la versión AM-(10,0.1), se aplica búsqueda local a cada cromosoma con probabilidad 0.1 cada 10 generaciones.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{La población $P$ (se modifica, no se devuelve) después de que algunas de las soluciones mejoren con búsqueda local.}
	\ForEach{$sol$ in $P$}{
		Con probabilidad 0.1: $\operatorname{LocalSearch}(sol)$\;
	}
	\caption{{\sc LocalSearch} de AM-(10,0.1).}
	\label{alg:am-10-01}
\end{algorithm}

En la versión AM-(10,0.1mej), se aplica búsqueda local a las 5 mejores soluciones (mejor 10\% de la población).

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población).}
	\KwOut{La población $P$ (se modifica, no se devuelve) después de que las 5 mejores soluciones mejoren con búsqueda local.}
	$q\gets\emptyset$ \tcp*{Cola con prioridad donde almacenaré parejas (fitness,índice), se ordenan por mayor fitness.}
	\ForEach{$i=0,\ldots,|P|-1$}{
		$q\gets q\cup\{(P[i].fitness,i)\}$\;
	}
	$k\gets 0.1\cdot n\_chromosomes$ \tcp*{Sacaré los 10\% mejores (5).}
	\For{$j=0,\ldots,k-$1}{
		$\operatorname{LocalSearch}(P[q.top.second])$\;
		$q.pop$\;
	}
	\caption{{\sc LocalSearch} de AM-(10,0.1mej).}
	\label{alg:am-10-01mej}
\end{algorithm}

El cuerpo principal de los algoritmos meméticos es el siguiente, la función LocalSearch (a nivel de población) es lo que diferencia
las distintas alternativas.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de soluciones $P$ (población) inicializado con soluciones aleatorias.}
	\KwOut{La población $P$ (se modifica, no se devuelve) evoluciona tras varias iteraciones.}
	Se evalúan todas las soluciones (50 evaluaciones), se incrementa $EVALS$ en 50\;
	$generation\gets 0$\;
	\While{$EVAlS<LIMIT$}{
		$\operatorname{cross}(P)$\;
		$\operatorname{mutate}(P)$\;
		$\operatorname{evaluate}(P)$\;
		$\operatorname{replacement}(P)$\;
		
		$generation\gets generation+1$\;
		
		\If{$generation \operatorname{mod} 10 == 0$}{
			$\operatorname{LocalSearch}(P)$\;
		}
	}
	\caption{{\sc AM}.}
	\label{alg:am}
\end{algorithm}

\pagebreak

\section{Desarrollo de la práctica}

La implementación de los algoritmos y la experimentación con los mismos se ha llevado acabo de C++, utilizando la librería STL. 
Para representar la soluciones hemos hecho uso del tipo \texttt{vector}.

La mayoría de operadores (mutación, cruce, búsqueda local) se implementan a nivel de solución y a nivel de población para abstraer
las operaciones y que el código sea más reciclable, generalmente como métodos de clase.

Para medir los tiempos de ejecución se utiliza la función \texttt{clock} de la librería \texttt{time.h}.

A lo largo de la práctica se utilizan acciones aleatorias. Utilizamos la librería \texttt{stdlib.h} para la generación de
enteros (no negativos) pseudoaleatorios con \texttt{rand} y fijamos la semilla con \texttt{srand}. Se barajan vectores con la función
 \texttt{random\_shuffle} de la librería \texttt{algorithm}.
 
Para las acciones que se realizan con cierta probabilidad, es necesario generar flotantes pseudoaleatorios en el intervalos $[0,1]$.
Para esto, se genera un entero no negativo con \texttt{rand} y se divide entre el máximo posible (RAND\_MAX).

Se almacena la matriz de distancias completa (no sólo un triángulo) por comodidad de los cálculos.

Se utiliza optimización de código \texttt{-O2} al compilar.

\end{document}

\subsection{Manual de usuario}

A continuación detallamos instrucciones para lanzar los ejecutables.

Tenemos los siguientes ejecutables:

\begin{itemize}
	\item \textbf{Greedy:} Implementación del algoritmo Greedy.
	\item \textbf{LocalSearch:} Implementación del algoritmo de Búsqueda Local (Primer Mejor).
	\item \textbf{LocalSearch2:} Implementación del algoritmo de Búsqueda Local (Mejor).
	\item \textbf{LocalSearch2nolim:} Implementación del algoritmo de Búsqueda Local (Mejor) sin límite de evaluaciones.
\end{itemize}

Todos ellos devuelven la evaluación de la solución obtenida y el tiempo de ejecución por salida estándar.
Leen el fichero por entrada estándar, así que es conveniente redirigirla.

Ejemplo:
\begin{verbatim}
	bin/greedy < datos/MDG-a_1_n500_m50.txt >> salidas/greedy.txt
\end{verbatim}

Los programas correspondientes a la búsqueda local también devuelven el número de llamadas a la función de evaluación, para
comparar cómo de cerca se quedan del límite.

Tenemos dos ejecutables más: \textbf{LocalSearchEvol} y \textbf{LocalSearch2Evol}, que son versiones equivalentes a
\textbf{LocalSearch} y \textbf{LocalSearch2}, pero con la diferencia de que devuelven una lista con la fitness de la solución
en cada iteración. Los usamos para estudiar la evolución de la solución a lo largo del proceso y obtener gráficas de convergencia.

Además, todos los archivos de búsqueda local reciben la semilla como parámetro. Ejemplo:
\begin{verbatim}
bin/localSearch 197 < datos/MDG-a_1_n500_m50.txt >> salidas/localSearch.txt
\end{verbatim}

En la carpeta \textbf{software} se incluye el script usado para lanzar todas las ejecuciones, \texttt{run.sh}. También se incluye
el \texttt{Makefile} que compila los ejecutables.

\pagebreak

\section{Experimentación y análisis}

Toda la experimentación se realiza en mi ordenador portátil personal, que tiene las siguientes especificaciones:
\begin{itemize}
	\item OS: Ubuntu 20.04.2 LTS x86\_64.
	\item RAM: 8GB, DDR4.
	\item CPU: Intel Core i7-6700HQ, 2.60Hz.
\end{itemize}

\subsection{Casos de estudio y resultados}

Tratamos varios casos con distintos parámetros $n$ y $m$. En cada caso se utiliza una semilla diferente para Búsqueda Local.
A continuación presentamos una tabla con los casos estudiados. Para cada caso indicamos los valores de $n$ y $m$ y la semilla
que se utiliza para la búsqueda local.

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & $n$ & $m$ & Seed\\ \hline
		MDG-a\_10\_n500\_m50 & 500 & 50 & 13\\
		MDG-a\_1\_n500\_m50 & 500 & 50 & 19\\
		MDG-a\_2\_n500\_m50 & 500 & 50 & 25\\
		MDG-a\_3\_n500\_m50 & 500 & 50 & 31\\
		MDG-a\_4\_n500\_m50 & 500 & 50 & 37\\
		MDG-a\_5\_n500\_m50 & 500 & 50 & 43\\
		MDG-a\_6\_n500\_m50 & 500 & 50 & 49\\
		MDG-a\_7\_n500\_m50 & 500 & 50 & 55\\
		MDG-a\_8\_n500\_m50 & 500 & 50 & 61\\
		MDG-a\_9\_n500\_m50 & 500 & 50 & 67\\
		MDG-b\_21\_n2000\_m200 & 2000 & 200 & 73\\
		MDG-b\_22\_n2000\_m200 & 2000 & 200 & 79\\
		MDG-b\_23\_n2000\_m200 & 2000 & 200 & 85\\
		MDG-b\_24\_n2000\_m200 & 2000 & 200 & 91\\
		MDG-b\_25\_n2000\_m200 & 2000 & 200 & 97\\
		MDG-b\_26\_n2000\_m200 & 2000 & 200 & 103\\
		MDG-b\_27\_n2000\_m200 & 2000 & 200 & 109\\
		MDG-b\_28\_n2000\_m200 & 2000 & 200 & 115\\
		MDG-b\_29\_n2000\_m200 & 2000 & 200 & 121\\
		MDG-b\_30\_n2000\_m200 & 2000 & 200 & 127\\
		MDG-c\_10\_n3000\_m400 & 3000 & 400 & 133\\
		MDG-c\_13\_n3000\_m500 & 3000 & 500 & 139\\
		MDG-c\_14\_n3000\_m500 & 3000 & 500 & 145\\
		MDG-c\_15\_n3000\_m500 & 3000 & 500 & 151\\
		MDG-c\_19\_n3000\_m600 & 3000 & 600 & 157\\
		MDG-c\_1\_n3000\_m300 & 3000 & 300 & 163\\
		MDG-c\_20\_n3000\_m600 & 3000 & 600 & 169\\
		MDG-c\_2\_n3000\_m300 & 3000 & 300 & 175\\
		MDG-c\_8\_n3000\_m400 & 3000 & 400 & 181\\
		MDG-c\_9\_n3000\_m400 & 3000 & 400 & 187\\
		\hline
	\end{tabular}
\caption{Tabla con los parámetros y semillas de cada caso. Ordenando los nombres de los ficheros por orden alfabético
(el orden en el que los procesa el script), las semillas son números del 13 al 187 saltando de 6 en 6.}
\label{tab:param-seed}
\end{table}

Ahora mostraremos para cada algoritmo una tabla con los estadísticos (Desviación y Tiempo) que han obtenido en cada
caso.

\pagebreak

Comenzamos con el algoritmo \textbf{Greedy}.

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7610.42 & 2.85 & 0.001375\\
		MDG-a\_2\_n500\_m50 & 7574.39 & 2.54 & 0.001293\\
		MDG-a\_3\_n500\_m50 & 7535.96 & 2.88 & 0.001304\\
		MDG-a\_4\_n500\_m50 & 7551.52 & 2.81 & 0.001281\\
		MDG-a\_5\_n500\_m50 & 7540.14 & 2.77 & 0.001284\\
		MDG-a\_6\_n500\_m50 & 7623.65 & 1.93 & 0.001278\\
		MDG-a\_7\_n500\_m50 & 7594.62 & 2.28 & 0.0014\\
		MDG-a\_8\_n500\_m50 & 7625.94 & 1.61 & 0.001367\\
		MDG-a\_9\_n500\_m50 & 7547.25 & 2.87 & 0.001351\\
		MDG-a\_10\_n500\_m50 & 7642.27 & 1.77 & 0.001893\\
		MDG-b\_21\_n2000\_m200 & 11099332.620328 & 1.77 & 0.319017\\
		MDG-b\_22\_n2000\_m200 & 11149879.733826 & 1.21 & 0.313017\\
		MDG-b\_23\_n2000\_m200 & 11119613.974858 & 1.6 & 0.303374\\
		MDG-b\_24\_n2000\_m200 & 11106996.970212 & 1.63 & 0.311278\\
		MDG-b\_25\_n2000\_m200 & 11114220.292214 & 1.61 & 0.306411\\
		MDG-b\_26\_n2000\_m200 & 11132801.799043 & 1.41 & 0.306542\\
		MDG-b\_27\_n2000\_m200 & 11130608.965587 & 1.55 & 0.310595\\
		MDG-b\_28\_n2000\_m200 & 11110673.520354 & 1.5 & 0.318429\\
		MDG-b\_29\_n2000\_m200 & 11156328.082493 & 1.25 & 0.306362\\
		MDG-b\_30\_n2000\_m200 & 11109767.818822 & 1.65 & 0.296905\\
		MDG-c\_1\_n3000\_m300 & 24617010 & 1.07 & 1.501668\\
		MDG-c\_2\_n3000\_m300 & 24547293 & 1.44 & 1.464132\\
		MDG-c\_8\_n3000\_m400 & 43056071 & 0.88 & 2.546235\\
		MDG-c\_9\_n3000\_m400 & 42958639 & 1.1 & 2.569214\\
		MDG-c\_10\_n3000\_m400 & 42959794 & 1.19 & 2.566065\\
		MDG-c\_13\_n3000\_m500 & 66493045 & 0.78 & 3.67213\\
		MDG-c\_14\_n3000\_m500 & 66449858 & 0.79 & 3.767131\\
		MDG-c\_15\_n3000\_m500 & 66468837 & 0.78 & 3.78725\\
		MDG-c\_19\_n3000\_m600 & 94929882 & 0.74 & 5.183856\\
		MDG-c\_20\_n3000\_m600 & 94979205 & 0.69 & 5.582157\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo Greedy
		en cada caso de estudio.}
	\label{tab:greedy}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		1.63 & 1.19 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

Ahora pasamos al algoritmo de \textbf{Búsqueda Local}.

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7623.23 & 2.69 & 0.001809\\
		MDG-a\_2\_n500\_m50 & 7590.18 & 2.34 & 0.001391\\
		MDG-a\_3\_n500\_m50 & 7544.94 & 2.76 & 0.001204\\
		MDG-a\_4\_n500\_m50 & 7576.44 & 2.49 & 0.0012\\
		MDG-a\_5\_n500\_m50 & 7484.27 & 3.49 & 0.001308\\
		MDG-a\_6\_n500\_m50 & 7570.96 & 2.61 & 0.001297\\
		MDG-a\_7\_n500\_m50 & 7654.98 & 1.5 & 0.001608\\
		MDG-a\_8\_n500\_m50 & 7623.78 & 1.64 & 0.002379\\
		MDG-a\_9\_n500\_m50 & 7612.74 & 2.02 & 0.001494\\
		MDG-a\_10\_n500\_m50 & 7619.52 & 2.07 & 0.001959\\
		MDG-b\_21\_n2000\_m200 & 11181874.0007 & 1.04 & 0.099777\\
		MDG-b\_22\_n2000\_m200 & 11167876.184 & 1.05 & 0.092492\\
		MDG-b\_23\_n2000\_m200 & 11176568.0611 & 1.09 & 0.107634\\
		MDG-b\_24\_n2000\_m200 & 11188223.318 & 0.91 & 0.107425\\
		MDG-b\_25\_n2000\_m200 & 11181859.8196 & 1.01 & 0.090053\\
		MDG-b\_26\_n2000\_m200 & 11193478.832 & 0.88 & 0.122694\\
		MDG-b\_27\_n2000\_m200 & 11211629.6839 & 0.83 & 0.112468\\
		MDG-b\_28\_n2000\_m200 & 11151089.4629 & 1.14 & 0.079449\\
		MDG-b\_29\_n2000\_m200 & 11183039.6644 & 1.01 & 0.09833\\
		MDG-b\_30\_n2000\_m200 & 11159590.8213 & 1.21 & 0.090033\\
		MDG-c\_1\_n3000\_m300 & 24729057 & 0.62 & 0.601221\\
		MDG-c\_2\_n3000\_m300 & 24738675 & 0.67 & 0.584432\\
		MDG-c\_8\_n3000\_m400 & 43200330 & 0.55 & 1.264437\\
		MDG-c\_9\_n3000\_m400 & 43157977 & 0.64 & 1.241837\\
		MDG-c\_10\_n3000\_m400 & 43188306 & 0.66 & 1.195051\\
		MDG-c\_13\_n3000\_m500 & 66636142 & 0.56 & 2.304507\\
		MDG-c\_14\_n3000\_m500 & 66727635 & 0.38 & 2.430114\\
		MDG-c\_15\_n3000\_m500 & 66808383 & 0.28 & 2.78715\\
		MDG-c\_19\_n3000\_m600 & 95244690 & 0.41 & 3.572005\\
		MDG-c\_20\_n3000\_m600 & 95324379 & 0.33 & 3.598978\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo de Búsqueda Local
		con Primer Mejor en cada caso de estudio.}
	\label{tab:bs-primer-mejor}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		1.3 & 0.69 \\
		\hline
	\end{tabular}
\end{table}

Comparamos los estadísticos medios obtenidos por ambos algoritmos.

\begin{table}[H]
	\centering
	\begin{tabular}{|ccc|}
		\hline
		Algoritmo & Desv & Tiempo (s)\\ \hline
		Greedy & 1.63 & 1.19 \\
		BL & 1.3 & 0.69 \\
		\hline
	\end{tabular}
	\caption{Comparativa de los estadísticos medios obtenidos por el algoritmo Greedy y por el de Búsqueda Local.}
	\label{tab:comparativa}
\end{table}

\pagebreak

\subsection{Análisis de resultados}

A la vista de la Tabla \ref{tab:comparativa}, intuimos que ambos algoritmos son adecuados para el problema.
El algoritmo Greedy, en media, alcanza el 98.37\% de la diversidad de la mejor solución posible. Mientras que la Búsqueda Local
 alcanza el 98.7\%.
 
 La BL resulta ser algo más efectiva, debido a que explora el espacio de soluciones con una mayor profundidad que Greedy.
 
 En las Tablas \ref{tab:greedy} y \ref{tab:bs-primer-mejor}, observamos que la desviación es menor en los casos con mayores 
 valores de $n$ y $m$. En general, es algo superior a 2 en los 10 ejemplos del grupo MDG-a, algo inferior a 2 para Greedy y
 cercana a 1 para BL en los 10 ejemplos del grupo MDG-b y algo inferior a 1 (entorno a 0.8 para Greedy y 0.55 para BL) en los 10
  ejemplos del grupo MDG-c. En la gran mayoría de casos, mejor la Búsqueda Local.
  
  Además, observamos que la mejora de la Búsqueda Local respecto a Greedy se acentúa en ejemplos con mayor número de elementos,
  al menos en términos
  relativos. Ya que una mejora del 0.25\% en la desviación cuando los algoritmos rondan desviaciones del 0.65 es bastante
   significativo, más que mejorar en 0.5\% cuando rondan desviaciones de 1.5 ó 2. Parece que cuanto mayor es el espacio de
   búsqueda, la mayor profundidad de exploración de BL cobra más relevancia.
   
  En cuanto al tiempo, nos sorprende la rapidez de la Búsqueda Local, que de media tarda un poco más de la mitad que Greedy.
  
  La mayor parte del tiempo de cómputo en el algoritmo Greedy se invierte en iterar sobre los elementos no seleccionados
   (prácticamente $n$) para encontrar el más lejano a los seleccionados. En cambio, en la Búsqueda Local sólo se itera hasta
   encontrar un candidato mejor que el peor de los seleccionados, aunque se evalúan soluciones completas.
   En el algoritmo Greedy se evalúa la solución completa al final.
   
   Otra fracción muy importante del tiempo de cómputo de Búsqueda Local se invierte también en barajar el vector de candidatos,
   que son $n-m$, para explorar los entornos de las soluciones de forma aleatoria. Hay que barajar por cada actualización de la
   solución.
   
   El motivo por que el la Búsqueda Local sea mucho más rápida es la factorización de la función de evaluación. Aunque técnicamente
   estemos evaluando nuevas soluciones completas, ya conocemos la contribución de todos los candidatos menos el posible nuevo
   seleccionado. Esto hace que el cálculo sea equivalente al de probar un nuevo candidato de Greedy.
   
   De todos modos, podemos considerar que ambos algoritmos son rápidos. Los tiempos de ejecución no han supuesto ningún impedimento
   en el desarrollo de la práctica, han sido prácticamente despreciables.
   
   A continuación incluiremos gráficas de convergencia para analizar la evolución de las soluciones de BL a medida que el algoritmo
   avanza.
   
\pagebreak
   

En general, observamos que la mejora es mayor en las primeras iteraciones, lo que les da a las gráficas una característica forma
creciente y cóncava.

En el eje de abscisas de cada gráfica podemos apreciar el número de actualizaciones que han tenido lugar durante el desarollo del
 algoritmo.
Es del orden de unas 100 para los ejemplos de MDG-a, 500-600 para los de MDG-b y entre 800 y 1000 para los de MDG-c. Hay que 
tener en cuenta que la estrategia del Primer Mejor da lugar a una gran cantidad de actualizaciones, con pequeña mejoría de
una actualización a la siguiente.

En los ejes de ordenadas se observa la mejora de diversidad que consigue el algoritmo partiendo de la solución aleatoria. Esta mejora ronda el 
20-25\% para los ejemplos del grupo MDG-a, es entorno al 12\% para los ejemplos del grupo MDG-b, y de ligeramente menos del 10\%
para los del grupo MDG-c. Esto le resta importancia al hecho de que los algoritmos hayan conseguido desviaciones más bajas en los
ejemplos grandes, pues una solución aleatoria también presenta menos desviación en los ejemplos grandes que en los pequeños.

\pagebreak

\section{Trabajo voluntario}

\subsection{Comparación Búsqueda Local: Mejor vs Primer Mejor}

En el seminario se nos ha aconsejado la estrategia del Primer Mejor para la Búsqueda Local, que consiste en actualizar una
solución cuando se encuentra una mejor en su entorno. La comparamos con la estrategia del Mejor, que explora todo el entorno
de cada solución y salta a la mejor solución del entorno.

A priori, tenemos una ventaja y dos inconvenientes. Por una parte, saltar a la mejor solución posible del entorno hace que el
valor de la función de evaluación crezca más rápido, lo que conlleva tener que realizar menos actualizaciones y menos barajamientos
del vector de no seleccionados.

Por otra parte, exploramos una menor porción del espacio de soluciones y corremos un alto riesgo de atascarnos en el máximo local
más cercano. También tenemos que evaluar todos los posibles candidatos para cada actualización.

Para este algoritmo, utilizamos la misma semilla en cada caso de estudio que usábamos en el algoritmo de BL con Primer Mejor.

Coste y estadísticos obtenidos en cada caso por este algoritmo.

\begin{table}[H]
	
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7605.85 & 2.91 & 0.001692\\
		MDG-a\_2\_n500\_m50 & 7650.91 & 1.55 & 0.001909\\
		MDG-a\_3\_n500\_m50 & 7627.05 & 1.71 & 0.001872\\
		MDG-a\_4\_n500\_m50 & 7628.28 & 1.83 & 0.00212\\
		MDG-a\_5\_n500\_m50 & 7443.78 & 4.02 & 0.001392\\
		MDG-a\_6\_n500\_m50 & 7519.01 & 3.28 & 0.001522\\
		MDG-a\_7\_n500\_m50 & 7602.72 & 2.17 & 0.002021\\
		MDG-a\_8\_n500\_m50 & 7527.51 & 2.88 & 0.001499\\
		MDG-a\_9\_n500\_m50 & 7605.79 & 2.11 & 0.001788\\
		MDG-a\_10\_n500\_m50 & 7625.84 & 1.99 & 0.001925\\
		MDG-b\_21\_n2000\_m200 & 10704537.121824 & 5.27 & 0.167474\\
		MDG-b\_22\_n2000\_m200 & 10729825.979899 & 4.93 & 0.157267\\
		MDG-b\_23\_n2000\_m200 & 10747061.106059 & 4.89 & 0.158778\\
		MDG-b\_24\_n2000\_m200 & 10697650.091284 & 5.25 & 0.154234\\
		MDG-b\_25\_n2000\_m200 & 10722432.780205 & 5.08 & 0.151428\\
		MDG-b\_26\_n2000\_m200 & 10712851.622844 & 5.13 & 0.151654\\
		MDG-b\_27\_n2000\_m200 & 10697966.587231 & 5.38 & 0.159407\\
		MDG-b\_28\_n2000\_m200 & 10704037.524274 & 5.11 & 0.16044\\
		MDG-b\_29\_n2000\_m200 & 10696542.050433 & 5.32 & 0.156025\\
		MDG-b\_30\_n2000\_m200 & 10687418.268475 & 5.39 & 0.16345\\
		MDG-c\_1\_n3000\_m300 & 23280092 & 6.45 & 0.391262\\
		MDG-c\_2\_n3000\_m300 & 23190732 & 6.88 & 0.384945\\
		MDG-c\_8\_n3000\_m400 & 40935884 & 5.76 & 0.504655\\
		MDG-c\_9\_n3000\_m400 & 40828623 & 6.01 & 0.509323\\
		MDG-c\_10\_n3000\_m400 & 40765886 & 6.23 & 0.501521\\
		MDG-c\_13\_n3000\_m500 & 63608646 & 5.08 & 0.607681\\
		MDG-c\_14\_n3000\_m500 & 63545017 & 5.13 & 0.604924\\
		MDG-c\_15\_n3000\_m500 & 63532837 & 5.16 & 0.583044\\
		MDG-c\_19\_n3000\_m600 & 91101174 & 4.74 & 0.712232\\
		MDG-c\_20\_n3000\_m600 & 91289378 & 4.55 & 0.718865\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo de Búsqueda Local
		con Mejor en cada caso de estudio.}
	\label{tab:bs-mejor}
\end{table}

%Media de los estadísticos:
%\begin{table}[H]
%	\centering
%	\begin{tabular}{|cc|}
%		\hline
%		Desv & Tiempo (s)\\ \hline
%		4.41 & 0.24 \\
%		\hline
%	\end{tabular}
%\end{table}

Comparativa de los estadísticos medios con la estrategia del Primer Mejor:

\begin{table}[H]
	\centering
	\begin{tabular}{|ccc|}
		\hline
		Estrategia & Desv & Tiempo (s)\\ \hline
		Mejor & 4.41 & 0.24 \\
		Primer Mejor & 1.3 & 0.69 \\
		\hline
	\end{tabular}
	\caption{Comparativa de estrategias de Búsqueda Local.}
	\label{tab:comparativa-bs}
\end{table}

Observamos en las dos tablas anteriores que la estrategia del Mejor da lugar a una desviación mucho mayor que la del Primer Mejor,
probablemente porque se quede atascado en el máximo local más cercano. Además, a diferencia de Primer Mejor y Greedy, este algoritmo
obtiene mayor desviación en los ejemplos grandes, donde las soluciones aleatorias ya eran mejores. Por tanto la eficacia de este
algoritmo es bastante baja en comparación con los que hemos visto antes, posiblemente debido a una exploración en menor profundidad
del espacio de búsqueda cuyos inconvenientes se acentúan al ser este mayor.

Incorporamos ahora gráficas de convergencia de este algoritmo.


En los ejemplos del grupo MDG-a, la forma de las gráficas es similar a las que proporcionaba la estrategia del Primer Mejor, y 
la mejor también es similar. También es similar la mejora que consigue (eje de ordenadas) con respecto a la solución aleatoria.

En cambio, en los ejemplos de los grupos MDG-b y MDG-c, el crecimiento del valor de la función exponencial es prácticamente lineal,
sobre todo en los ejemplos más grandes. Además, en el eje de ordenadas observamos que la mejora que consigue este algoritmo en 
estos ejemplos respecto a la solución aleatoria es mucho menor, en los ejemplos grandes no llega al 2\% de la diversidad.

En el eje de abscisas, observamos que el número de actualizaciones del algoritmo BL con primer mejor es de entorno a 50,
independientemente del tamaño del problema. Esto podría significar que el algoritmo para antes de tiempo y no llega a explorar
el espacio de soluciones todo lo que podría, así que obtenemos una tabla con las llamadas a la función de evaluación de cada
estrategia.

La estrategia del Primer Mejor es capaz de parar en mitad de una iteración si se llega al límite de llamadas, mientras que la 
estrategia del Mejor la he diseñado para que se detenga al final de la iteración. Por este motivo, el algoritmo del Mejor puede
exceder el límite de llamadas, pero nunca en más de $n$, De modo que no tiene mucha importancia de cara a los tiempos de ejecución
y al comportamiento del algoritmo.

\begin{table}[H]
	\centering
	\begin{tabular}{|ccc|}
		\hline
		Caso & Primer Mejor & Mejor\\ \hline
		MDG-a\_10\_n500\_m50 & 4933 & 22500\\
		MDG-a\_1\_n500\_m50 & 3533 & 19800\\
		MDG-a\_2\_n500\_m50 & 2664 & 22050\\
		MDG-a\_3\_n500\_m50 & 1522 & 22050\\
		MDG-a\_4\_n500\_m50 & 1843 & 24300\\
		MDG-a\_5\_n500\_m50 & 1869 & 16200\\
		MDG-a\_6\_n500\_m50 & 2330 & 16650\\
		MDG-a\_7\_n500\_m50 & 2776 & 22950\\
		MDG-a\_8\_n500\_m50 & 3439 & 17100\\
		MDG-a\_9\_n500\_m50 & 2246 & 20700\\
		MDG-b\_21\_n2000\_m200 & 29153 & 100800\\
		MDG-b\_22\_n2000\_m200 & 23745 & 100800\\
		MDG-b\_23\_n2000\_m200 & 28631 & 100800\\
		MDG-b\_24\_n2000\_m200 & 30061 & 100800\\
		MDG-b\_25\_n2000\_m200 & 22374 & 100800\\
		MDG-b\_26\_n2000\_m200 & 40168 & 100800\\
		MDG-b\_27\_n2000\_m200 & 31362 & 100800\\
		MDG-b\_28\_n2000\_m200 & 15585 & 100800\\
		MDG-b\_29\_n2000\_m200 & 25351 & 100800\\
		MDG-b\_30\_n2000\_m200 & 19936 & 100800\\
		MDG-c\_10\_n3000\_m400 & 34032 & 101400\\
		MDG-c\_13\_n3000\_m500 & 27872 & 100000\\
		MDG-c\_14\_n3000\_m500 & 47459 & 100000\\
		MDG-c\_15\_n3000\_m500 & 79989 & 100000\\
		MDG-c\_19\_n3000\_m600 & 34607 & 100800\\
		MDG-c\_1\_n3000\_m300 & 58816 & 102600\\
		MDG-c\_20\_n3000\_m600 & 44010 & 100800\\
		MDG-c\_2\_n3000\_m300 & 63615 & 102600\\
		MDG-c\_8\_n3000\_m400 & 60814 & 101400\\
		MDG-c\_9\_n3000\_m400 & 51098 & 101400\\
		\hline
	\end{tabular}
	\caption{Número de llamadas a la función de evaluación por las estrategias Mejor y Primer Mejor para cada ejemplo.}
	\label{tab:calls}
\end{table}

Efectivamente, comprobamos que la estrategia del Primer Mejor siempre alcanza un máximo local. En cambio, la del Mejor
invierte demasiadas evaluaciones en cada iteración de los ejemplos grandes, lo que provoca que pare antes de alcanzar uno.

Por el contrario, el número de barajamientos de los candidatos que realiza la estrategia del Mejor es mucho menor, ya que
actualiza la solución menos veces. Este algoritmo invierte prácticamente todo su tiempo de ejecución en llamadas a la función
de evaluación.

Tras observar esto, es probable que al quizar o aumentar el límite de llamadas a la función de evaluación, el la estrategia del 
Mejor se asemeje en eficacia a la del Primer Mejor. No obstante, en los ejemplos del grupo MDG-a, donde ambos algoritmos se
 ejecutan al completo, la desviación que logra
la estrategia del Primer Mejor es ligeramente menor. Además, la mejor que realiza el algoritmo Primer Mejor respecto al tiempo que
tarda sugiere que la estrategia Mejor necesitaría más tiempo para alcanzar soluciones de la misma calidad.

Finalmente, hay que tener en cuenta que en otros problemas donde no sea posible la factorización de la función de evaluación,
la estrategia del Mejor sería mucho más lenta que la del Primer Mejor. Debido a que la mayoría de su tiempo se dedida a evaluar
esta función.

Por tanto, concluimos que la estrategia del Mejor no parece ser tan mala como muestra la Tabla \ref{tab:comparativa-bs}, pero
es más conveniente actualizar más a menudo la solución en lugar de realizar exhaustivas búsquedas por el entorno de cada solución,
sobre todo si no se pudiese factorizar la función de evaluación.

Para corroborar nuestras conclusiones, y como los ejemplos que estudiamos no son demasiado grandes, probamos a lanzar la BL
con Mejor eliminando el límite de llamadas a la función de evaluación. Obtenemos los siquientes resultados.

\begin{table}[H]
	\centering
	\begin{tabular}{|lrrr|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7605.85 & 2.91 & 0.001625\\
		MDG-a\_2\_n500\_m50 & 7650.91 & 1.55 & 0.001816\\
		MDG-a\_3\_n500\_m50 & 7627.05 & 1.71 & 0.001806\\
		MDG-a\_4\_n500\_m50 & 7628.28 & 1.83 & 0.001896\\
		MDG-a\_5\_n500\_m50 & 7443.78 & 4.02 & 0.001291\\
		MDG-a\_6\_n500\_m50 & 7519.01 & 3.28 & 0.001317\\
		MDG-a\_7\_n500\_m50 & 7602.72 & 2.17 & 0.001892\\
		MDG-a\_8\_n500\_m50 & 7527.51 & 2.88 & 0.001354\\
		MDG-a\_9\_n500\_m50 & 7605.79 & 2.11 & 0.001631\\
		MDG-a\_10\_n500\_m50 & 7625.84 & 1.99 & 0.001932\\
		MDG-b\_21\_n2000\_m200 & 11180058.750775 & 1.06 & 0.677438\\
		MDG-b\_22\_n2000\_m200 & 11155314.466742 & 1.16 & 0.555748\\
		MDG-b\_23\_n2000\_m200 & 11108124.604139 & 1.7 & 0.496808\\
		MDG-b\_24\_n2000\_m200 & 11153820.029699 & 1.21 & 0.542795\\
		MDG-b\_25\_n2000\_m200 & 11171185.53995 & 1.11 & 0.597482\\
		MDG-b\_26\_n2000\_m200 & 11188729.123865 & 0.92 & 0.634261\\
		MDG-b\_27\_n2000\_m200 & 11114584.701586 & 1.69 & 0.499422\\
		MDG-b\_28\_n2000\_m200 & 11179532.969364 & 0.89 & 0.610616\\
		MDG-b\_29\_n2000\_m200 & 11149615.9197 & 1.31 & 0.62679\\
		MDG-b\_30\_n2000\_m200 & 11157311.470229 & 1.23 & 0.588087\\
		MDG-c\_1\_n3000\_m300 & 24736454 & 0.59 & 3.828034\\
		MDG-c\_2\_n3000\_m300 & 24675066 & 0.92 & 3.003777\\
		MDG-c\_8\_n3000\_m400 & 43243999 & 0.44 & 5.740351\\
		MDG-c\_9\_n3000\_m400 & 43163449 & 0.63 & 6.146966\\
		MDG-c\_10\_n3000\_m400 & 42989641 & 1.12 & 4.425393\\
		MDG-c\_13\_n3000\_m500 & 66766340 & 0.37 & 8.536604\\
		MDG-c\_14\_n3000\_m500 & 66628488 & 0.52 & 7.471225\\
		MDG-c\_15\_n3000\_m500 & 66715761 & 0.41 & 7.363534\\
		MDG-c\_19\_n3000\_m600 & 95226472 & 0.43 & 9.204225\\
		MDG-c\_20\_n3000\_m600 & 95271298 & 0.39 & 9.370968\\
		\hline
	\end{tabular}
	\caption{Resultados y estadísticos obtenidos por el algoritmo de BL con Mejor eliminando el límite de llamadas.}
\label{tab:ls2-nolim}
\end{table}

Las desviaciones son bastante similares a las obtenidas con la estrategia del Primer Mejor, en cambio los tiempos son mucho mayores.

La desviación media es de 1.42\%, y el tiempo medio de 2.36 segundos. Aunque la desviación sea buena (mejor que Greedy, aunque
ligeramente peor que la estrategia del Primer Mejor), el tiempo medio de ejecución es bastante mayor, más del triple que el de la
estrategia Primer Mejor.

\end{document}
