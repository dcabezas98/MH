\documentclass{article}

\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry} 

\usepackage[utf8]{inputenc}   % otra alternativa para los caracteres acentuados y la "Ã±"
\usepackage[           spanish % para poder usar el espaÃ±ol
                      ,es-tabla % para los captions de las tablas
                       ]{babel}   
\decimalpoint %para usar el punto decimal en vez de coma para los nÃºmeros con decimales

%\usepackage{beton}
%\usepackage[T1]{fontenc}

\usepackage{parskip}
\usepackage{xcolor}

\usepackage{caption}

\usepackage{enumerate} % paquete para poder personalizar fÃ¡cilmente la apariencia de las listas enumerativas

\usepackage{graphicx} % figuras
\usepackage{subfigure} % subfiguras

\usepackage{amsfonts}
\usepackage{amsmath}

\usepackage{listings}
\lstset
{ %Formatting for code in appendix
    language=python,
    basicstyle=\footnotesize,
    stepnumber=1,
    showstringspaces=false,
    tabsize=1,
    breaklines=true,
    breakatwhitespace=false,
}

\definecolor{gris}{RGB}{220,220,220}
	
\usepackage{float} % para controlar la situaciÃ³n de los entornos flotantes

\restylefloat{figure}
\restylefloat{table} 
\setlength{\parindent}{0mm}


\usepackage[bookmarks=true,
            bookmarksnumbered=false, % true means bookmarks in 
                                     % left window are numbered
            bookmarksopen=false,     % true means only level 1
                                     % are displayed.
            colorlinks=true,
            allcolors=blue,
            urlcolor=blue]{hyperref}
\definecolor{webblue}{rgb}{0, 0, 0.5}  % less intense blue

\usepackage[ruled,vlined]{algorithm2e}
\SetKwInOut{Parameter}{parameter}


\title{\Huge Metaheurísticas: Práctica 3 \\ Búsquedas por Trayectorias \\ para el Problema de la Máxima Diversidad \vspace{10mm}}

\author{\huge David Cabezas Berrido \vspace{10mm} \\
	\huge 20079906D \vspace{10mm} \\  
  \huge Grupo 2: Viernes \vspace{10mm} \\ 
  \huge dxabezas@correo.ugr.es \vspace{10mm}}

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage

\section{Descripción y formulación del problema}

Nos enfrentamos al \textbf{Problema de la Máxima Diversidad} (\textbf{Maximum Diversity Problem, MDP}). El problema consiste en seleccionar
un subconjunto $m$ elementos de un conjunto de $n>m$ elementos de forma que se \textbf{maximice} la \emph{diversidad} entre los
 elementos escogidos.
 
 Disponemos de una matriz $D=(d_{ij})$ de dimensión $n\times n$ que contiene las distancias entre los elementos, la entrada $(i,j)$ contiene el
 valor $d_{ij}$, que corresponde a la distancia entre el elemento $i$-ésimo y el $j$-ésimo. Obviamente, la matriz $D$ es simétrica y con
 diagonal nula.
 
 Existen distintas formas de medir la diversidad, que originan distintas variantes del problema. En nuestro caso, la diversidad será la suma
 de las distancias entre cada par de elementos seleccionados.

De manera formal, se puede formular el problema de la siguiente forma:

\begin{description}
	\item Maximizar 
	\begin{equation} \label{eq:objetivo}
		f(x)=\sum_{i=1}^{n-1}\sum_{j=i+1}^n d_{ij} x_i x_j
	\end{equation}
	\item sujeto a 
	\begin{align*}
		\sum_{i=1}^n x_i &= m \\
		x_i&= \{0,1\}, \quad\forall i=1,\ldots, n.
	\end{align*}
\end{description}

Una solución al problema es un vector binario $x$ que indica qué elementos son seleccionados, seleccionamos el elemento $i$-ésimo si $x_i=1$.

Sin embargo, esta formulación es poco eficiente y para la mayoría de algoritmos proporcionaremos otra equivalente pero más eficiente.

El problema es \textbf{NP-completo} y el tamaño del espacio de soluciones es $\dbinom{n}{m}$, de modo que es conveniente recurrir al uso de metaheurísticas
para atacarlo.

\pagebreak

\section{Aplicación de los algoritmos}

Los algoritmos para resolver este problema tendrán como entradas la matriz $D$ ($n\times n$) y el valor $m$. La salida será un contenedor
(vector, conjunto, \ldots) con los índices de los elementos seleccionados, y no un vector binario como el que utilizamos para la formulación.
 En nuestro caso (algoritmos implementados en esta práctica) utilizaremos vectores de enteros para representar soluciones.

La evaluación de la calidad de una solución se hará
sumando la contribución de cada uno de los elementos, y dividiremos la evaluación en dos funciones. En lugar de calcular la función evaluación como en
\eqref{eq:objetivo}, lo haremos así:
\begin{equation} \label{eq:objetivo-fact}
f(x)=\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^m d(i,j)=\frac{1}{2}\sum_{i=1}^{m}\operatorname{contrib}(i)
\end{equation}
La diferencia es que contamos la distancia entre cada dos elementos $i,j$ dos veces, distancia del elemento $i$-ésimo al $j$-ésimo y del $j$-ésimo al
$i$-ésimo. Esto es obviamente más lento que con $j>i$ en la sumatoria, pero nos permite factorizar la evaluación de la solución como suma de las
 contribuciones de los elementos, lo cuál será útil para reaprovechar cálculos al evaluar soluciones para la Búsqueda Local.
 Además, representar la solución como un vector de $m$ índices y no un vector binario de longitud $n$ presenta una clara ventaja: las sumatorias van hasta
 $m$ en lugar de $n$. No tenemos que computar distancias para luego multiplicarlas por cero como sugería la formulación en \eqref{eq:objetivo}.

Presentamos el pseudocódigo de la función para calcular la contribución de un elemento $x_i$.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un vector de índices $S$.}
	\KwIn{La matriz de distancias $D$.}
	\KwIn{Un entero $e$ correspondiente al índice del elemento.}
	\KwOut{La contribución del elemento $e$, como se describe en \eqref{eq:objetivo-fact}.}
	$contrib \gets 0$\;
	\For{$s$ \textbf{in} $S$} {
		$contrib \gets contrib + D[e,s]$ \tcp*{Sumo las distancias del elemento $e$ a cada elemento de $S$}
	}
	\Return{$contrib$}\;
	\caption{{\sc Contrib} calcula la contribución de un elemento en una solución.}
	\label{alg:contrib}
\end{algorithm}

Nótese que el elemento $e$ no tiene que pertenecer al conjunto $S$. Esto obviamente no ocurrirá cuando se vaya a evaluar una solución
al completo invocando esta función con la que describiremos a continuación. Pero, de esta forma, permite conocer cómo influirá en la evaluación el añadir
 un nuevo elemento sin necesidad de añadirlo realmente. 
 
 Ahora presentamos el pseudocódigo de la función para evaluar una solución completa.
 
 \begin{algorithm}[H]
 	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
 	\KwIn{Un vector de índices $S$.}
 	\KwIn{La matriz de distancias $D$.}
 	\KwOut{El valor de la función objetivo sobre la solución compuesta por $S$, como se describe en \eqref{eq:objetivo-fact}.}
 	$fitness \gets 0$\;
 	\For{$e$ \textbf{in} $S$} {
 		$fitness \gets fitness + \operatorname{contrib}(S,D,e)$ \tcp*{Sumo la contribución de cada elemento de la solución}
 	}
 	\Return{$fitness/2$} \tcp*{Hemos contado cada distancia dos veces}
 	\caption{{\sc Fitness} calcula la evaluación de una solución.}
 	\label{alg:eval}
 \end{algorithm}

Podemos definir la distancia de un elemento $e$ a un conjunto $S$ como:

\begin{equation} \label{eq:distance-elem-set}
	d(e,S)=\sum_{s\in S} d(e,s)
\end{equation}

Esta expresión nos será de utilidad para la implementación de los algoritmos.

Gracias a la existencia del Algoritmo \ref{alg:contrib}, podemos obtener esta expresión como $\operatorname{contrib}(S,D,e)$.

Para los pseudocódigos que siguen, suponemos la matriz de distancias $D$ y los parámetros $n$ y $m$ accesibles. El
conjunto de todos los elementos es el $\{0,\ldots , n-1\}$, para cuando nos refiramos a elementos de fuera de un
 subconjunto
de ellos.

En esta práctica implementaremos 4 algoritmos basados en trayectorias, y los compararemos entre sí y con la búsqueda local y el greedy de la práctica 1.
Adicionalmente, compararemos para el Enfriamiento Simulado el esquema de Cauchy Modificado con el enfriamiento proporcional, también en la
hibridación con ILS.

Todos los algoritmos de esta práctica parten de soluciones aleatorias. La siguiente función permite construir
las soluciones aleatorias que utilizaremos como partida.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwOut{Una solución válida del MDP obtenida aleatoriamente.}
	$E \gets \{0,\ldots, n-1\}$ \tcp*{Vector con todos los elementos.}
	$\operatorname{shuffle}(E)$\;
	$S \gets \emptyset$ \tcp*{La solución empieza vacía.}
	\While{$|S|<m$}{
		$S \gets S\cup \{E[|S|]\}$ \tcp*{Seleccionamos los $m$ primeros elementos de $E$, que son aleatorios.}
	}
	\Return{$S$}\;
	\caption{{\sc RandomSol} proporciona una solución válida aleatoria}
	\label{alg:randomsol}
\end{algorithm}

La mayoría de algoritmos implementados en esta práctica hacen uso de la búsqueda local (con primer mejor). El siguiente algoritmo
implementa esta búsqueda. Supondremos declaradas las variables globales $LIMIT$, que valdrá 100000 o 10000 dependiendo
de si el problema es de trayectoria simple o múltiple; y $EVALS$, las evaluaciones hasta el momento, esta variable
comienza a 0 y sólo es reseteada en los problemas de trayectorias múltiples (donde $LIMIT$ vale 10000), y se resetea
10 veces para que el total de evaluaciones siempre sea 100000.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Solución de partida $S$.}
	\KwOut{La solución $S$ se modifica (no se devuelve) con varias iteraciones de búsqueda local.}
	$E \gets \{0,\ldots,n-1\}$ \tcp*{Vector con todos los elementos.}
	$carryon \gets true$\;
	\While{carryon}{
		$carryon \gets false$\;
		$lowest\gets \text{indice del elemento de $S$ que menos contribuye, minimiza $\operatorname{contrib}(S,D,S[lowest])$}$\;
		$min\_contrib \gets \operatorname{contrib}(S,D,lowest)$
		$E \gets \operatorname{shuffle}(E)$ \tcp*{Para explorar los posibles vecinos en orden aleatorio.}
		\For{$e$ \textbf{in} $E$} {
			\If{$e\in S$}{
				continue \tcp*{Si ya está escogido, no lo cuento.}
			}
			$contrib \gets \operatorname{contrib}(S,D,e)-D[e,S[lowest]]$ \tcp*{Contribución a la solución sin el elemento a sustituir.}
			$EVALS \gets EVALS+1$ \tcp*{He evaludado una posible solución.}
			\If{$contrib > min\_contrib$} { 
				$S.fitness \gets S.fitness + contrib - min\_contrib$ \tcp*{Fitness de la nueva solución}
				$carryon \gets true$ \tcp*{Toca saltar, lo que completa la iteración}
				$S[lowest]\gets e$ \tcp*{Saltamos a la nueva solución}
			}
			\If{$carryon==true$ or $EVALS\geq LIMIT$} { 
				break  \tcp*{Se cumple alguna de las condiciones de parada}
			}
		}
	}
	\caption{{\sc LocalSearch} modifica una solución con varias iteraciones de búsqueda local con primer mejor.}
	\label{alg:local-search}
\end{algorithm}

\pagebreak

\section{Descripción de los algoritmos}

\subsection{Enfriamiento Simulado}

Para implementar el algoritmo de Enfriamiento Simulado, hemos separado los operadores de generación de vecino y
salto. 

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Solución de partida $S$.}
	\KwOut{Índice del elemento a eliminar.}
	\KwOut{Elemento a añadir.}
	\KwOut{Diferencia de fitness entre el vecino y la solución $S$.}
	$index\_out\gets\text{entero aleatorio entre 0 y $|S|-1$}$\;
	$elem\_in\gets\text{elemento aleatorio entre 0 y $n-1$}$\;
	\While{$elem\_in\in S$}{
		$elem\_in\gets\text{elemento aleatorio entre 0 y $n-1$}$\;
	}
	$contrib\_in\gets\operatorname{contrib}(S,D,elem\_in)-D[elem\_in,S[index\_out]]$\tcp*{Contribución del nuevo elemento, no hay que contar su distancia al que vamos a quitar.}
	$contrib\_out\gets\operatorname{contrib}(S,D,S[index\_out])$\;
	$delta\gets contrib\_in-contrib\_out$\;
	$EVALS\gets EVALS+1$\;
	\Return{$elem\_in$}\;
	\Return{$index\_out$}\;
	\Return{$delta$}\;
	\caption{{\sc MUTATE} genera un vecino aleatorio en un entorno de la solución y calcula la diferencia de fitness.}
	\label{alg:mutate-es}
\end{algorithm}

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Solución de partida $S$.}
	\KwIn{Índice del elemento a eliminar: $index\_out$.}
	\KwIn{Elemento a añadir: $elem\_in$.}
	\KwIn{Diferencia de fitness entre el vecino y la solución $S$: $delta$.}
	\KwOut{Nueva solución (no devuelve nada, modifica $S$).}
	$S[index\_out]\gets elem\_in$\;
	$S.fitness\gets S.fitness+delta$\;	
	\caption{{\sc JUMP} desplaza la solución al vecino indicado.}
	\label{alg:jump-es}
\end{algorithm}

En este caso, el número de evaluaciones no se se resetea, y el límite se fija en 100000.
El cuerpo del algoritmo queda de la siguiente forma.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwOut{Una solución factible obtenida por enfriamiento simulado con Cauchy Modificado.}
	$exitos\gets 1$ \tcp*{Para que entre la primera vez en el bucle}
	$max\_vecinos\gets 10n$\;
	$\max\_exitos\gets 0.1*max\_vecinos$\;
	$best\_fitness\gets 0$\;
	$M\gets LIMIT/max\_vecinos$\;
	$S\gets \operatorname{randomSol}$\;
	$\operatorname{evaluate}(S)$ \tcp*{Asigna $S.fitness\gets\operatorname{fitness}(S)$.}
	$EVALS\gets EVALS+1$\;
	$mu\gets 0.3$\;
	$phi\gets 0.3$\;
	$T\gets -mu\cdot S.fitness/\log phi$ \tcp*{Temperatura inicial}
	$T_f\gets 10^{-3}$\;
	\While{$T<T_f$}{
		$T_f\gets T_f/10$ \tcp*{La temperatura final debe ser menor que la inicial}
	}
	$beta\gets (T-T_f)/(M\cdot T\cdot T_f)$\;
	\While{$exitos>0$ and $EVALS<LIMIT$}{
		$exitos\gets 0$\;
		$vecinos\gets 0$\;
		\While{$vecinos < max\_vecinos$ and $exitos<max\_exitos$}{
			$index\_out, elem\_in, delta \gets \operatorname{mutate}(S)$\;
			$vecinos\gets vecinos+1$\;
			$x\gets\text{número aleatorio en una uniforme $[0,1]$}$\;
			\If{$delta>0$ or $x\leq \exp(delta/T)$}{
				$\operatorname{jump}(S,index\_out, elem\_in, delta)$\;
				$exitos\gets exitos+1$\;
				\If{$S.fitness>best\_fitness$}{
					$best\_sol\gets S$ \tcp*{En realidad sólo guardo la fitness, no la solución}
					$best\_fitness \gets S.fitness$\;
				}
			}
		}
		$T\gets T/(1+beta\cdot T)$ \tcp*{Enfriamiento}
	}
	\Return{$best\_sol$}\;
	\caption{{\sc EnfriamientoSimulado}}
	\label{alg:es}
\end{algorithm}

También incorporamos una comparación con el esquema de enfriamiento proporcional. La única diferencia es que el enfriamiento pasa a ser
$T\gets 0.9\cdot T$, y sobran $M$ y $beta$.

\subsection{Búsqueda Multiarranque Básica}

Este algoritmo se limita a ejecutar 10 búsquedas locales, cada una con 10000 evaluaciones ($LIMIT=10000$ y $EVALS$ se resetea a 0 para
cada búsqueda), al final nos quedamos con la mejor de las 10 soluciones alcanzadas.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwOut{Una solución factible obtenida por Búsqueda Multiarranque Básica.}
	$best\_fitness\gets 0$\;
	\For{$i=0,\ldots,9$}{
		$EVALS\gets 0$\;
		$S\gets \operatorname{randomSol}$\;
		$\operatorname{evaluate}(S)$ \tcp*{Asigna $S.fitness\gets\operatorname{fitness}(S)$.}
		$EVALS\gets EVALS+1$\;
		$\operatorname{localSearch}(S)$\;		
		\If{$S.fitness>best\_fitness$}{
			$best\_sol\gets S$ \tcp*{En realidad sólo guardo la fitness, no la solución}
			$best\_fitness \gets S.fitness$\;
		}
	}
	\Return{$best\_sol$}\;
	\caption{{\sc BMB}}
	\label{alg:bmb}
\end{algorithm}

\subsection{Búsqueda Local Reiterada}

Para este algoritmo, necesitamos el siguiente operador de mutación. Se eliminan aleatoriamente $t$ elementos de $S$ (los $t$ primeros
tras barajar) y se sustituyen por $t$ elementos de fuera elegidos aleatoriamente.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Solución de partida $S$.}
	\KwIn{Número de elementos a modificar: $t$.}
	\KwOut{Modifica (no devuelve) $t$ elementos aleatorios de $S$.}
	$E\gets\{0,\ldots,n-1\}$\;
	$\operatorname{shuffle}(S)$\;
	$\operatorname{shuffle}(E)$\;
	$new\gets\emptyset$\;
	$j\gets 0$\;
	\While{$|new|<t$}{
		\If{$E[j]\notin S$}{
			$new\gets new\cup\{E[j]\}$\;
		}
		$j\gets j+1$\;
	}
	\For{$j=0,\ldots,|new|-1$}{
		$S[j]\gets new[j]$\;
	}
	$\operatorname{evaluate}(S)$\;
	$EVALS\gets EVALS+1$\;
	\caption{{\sc MUTATE} modifica la solución cambiando el 10\% de los elementos seleccionados por elementos aleatorios
		de fuera.}
	\label{alg:mutate-ils}
\end{algorithm}

El algoritmo ILS es similar al anterior, la diferencia es que cada solución parte de una mutación aleatoria de la mejor encontrada.
El límite de ejecucioes es 10000, y se resetea el número de evaluaciones 10 veces.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwOut{Una solución factible obtenida por Búsqueda Local Reiterada.}
	$t\gets 0.1\cdot m$\;
	$best\_sol\gets \operatorname{randomSol}$\;
	$\operatorname{evaluate}(best\_sol)$\;
	$best\_fitness\gets 0$\;
	\For{$i=0,\ldots,9$}{
		$EVALS\gets 0$\;
		$S\gets best\_sol$\;
		$\operatorname{mutate}(S,t)$\;
		$\operatorname{localSearch}(S)$\;		
		\If{$S.fitness>best\_fitness$}{
			$best\_sol\gets S$ \;
			$best\_fitness \gets S.fitness$\;
		}
	}
	\Return{$best\_sol$}\;
	\caption{{\sc ILS}}
	\label{alg:ils}
\end{algorithm}

Esta implementación realiza $100001$ iteraciones en lugar de $100000$, e igual le ocurre a la siguiente variante. Aunque esto no
es relevante para el comportamiento del algoritmo.

\subsection{Híbridación ILS-ES}

Este algoritmo es idéntico al anterior, con la diferencia de que utiliza Enfriamiento Simulado en lugar de Búsqueda Local.
Para ello, necesitamos una variante del Algoritmo \ref{alg:es} que modifique una solución de entrada en lugar de generar una
nueva.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Una solución factible de partida: $S$.}
	\KwOut{La solución $S$ modificada con varias iteraciones de Enfriamiento Simulado con Cauchy Modificado.}
	$exitos\gets 1$ \tcp*{Para que entre la primera vez en el bucle}
	$max\_vecinos\gets 10n$\;
	$\max\_exitos\gets 0.1*max\_vecinos$\;
	$M\gets LIMIT/max\_vecinos$\;
	$EVALS\gets EVALS+1$\;
	$mu\gets 0.3$\;
	$phi\gets 0.3$\;
	$T\gets -mu\cdot S.fitness/\log phi$ \tcp*{Temperatura inicial}
	$T_f\gets 10^{-3}$\;
	\While{$T<T_f$}{
		$T_f\gets T_f/10$ \tcp*{La temperatura final debe ser menor que la inicial}
	}
	$beta\gets (T-T_f)/(M\cdot T\cdot T_f)$\;
	\While{$exitos>0$ and $EVALS<LIMIT$}{
		$exitos\gets 0$\;
		$vecinos\gets 0$\;
		\While{$vecinos < max\_vecinos$ and $exitos<max\_exitos$}{
			$index\_out, elem\_in, delta \gets \operatorname{mutate}(S)$\;
			$vecinos\gets vecinos+1$\;
			$x\gets\text{número aleatorio en una uniforme $[0,1]$}$\;
			\If{$delta>0$ or $x\leq \exp(delta/T)$}{
				$\operatorname{jump}(S,index\_out, elem\_in, delta)$\;
				$exitos\gets exitos+1$\;
			}
		}
		$T\gets T/(1+beta\cdot T)$ \tcp*{Enfriamiento}
	}
	\Return{$best\_sol$}\;
	\caption{{\sc EnfriamientoSimulado}}
	\label{alg:es-ils}
\end{algorithm}

Con esta nueva implementación, el cuerpo del algoritmo ILS-ES es exactamente igual al de ILS (Algoritmo \ref{alg:ils}) pero
cambiando localSearch$(S)$ por enfriamientoSimulado$(S)$.

Hay que tener cuidado, ya que hemos usado un nombre confuso para algunas funciones. El operador Mutate llamado por el Enfriamiento
Simulado busca un vecino y calcula el cambio de fitness, corresponde al Algoritmo \ref{alg:mutate-es}. Sin embargo, el operador
Mutate invocado por ILS corresponde al Algoritmo \ref{alg:mutate-ils}.

También incluimos la comparación con el modelo de enfriamiento proporcional. Como el número de enfriamientos va a ser es mucho menor,
en lugar de 0.9 usamos 0.5: $T\gets 0.5\cdot T$. Esto quizá enfríe demasiado rápido.

\subsection{Búsqueda Local}

Procedemos con la descripción del algoritmo de Búsqueda Local que se nos ha presentado en el seminario. 
Este algoritmo utiliza la técnica del Primer Mejor, en la que se van generando soluciones en el entorno de la actual y se
salta a la primera con mejor evaluación. Para la implementación del algoritmo, necesitamos distintos elementos.

Este algoritmo se implementó en la práctica 1, y utiliza conjuntos de enteros en lugar de vectores para representar
las soluciones.

El primer elemento, es una función para generar una solución aleatoria de partida. Simplemente se eligen $m$ elementos 
diferentes del conjunto. Por comodidad, también calculamos el complementario.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{El entero $m$.}
	\KwIn{El entero $n$.}
	\KwOut{Una solución válida del MDP obtenida aleatoriamente.}
	\KwOut{El complementario de la solución obtenida.}
	$E \gets \{0,\ldots, n-1\}$ \tcp*{Conjunto con los elementos no seleccionados}
	$S \gets \emptyset$ \tcp*{La solución empieza vacía}
	\While{$|S|<m$}{
		$e \gets$ elemento aleatorio de $E$\;
		$E \gets E\backslash \{e\}$\;
		$S \gets S\cup \{e\}$\;
	}
	\Return{$S$}\;
	\Return{$E$} \tcp*{El complementario}
	\caption{{\sc RandomSol} proporciona una solución válida aleatoria}
	\label{alg:randomsol-ls}
\end{algorithm}

Lo siguiente que necesitamos es un método para generar las soluciones del entorno. Estas soluciones se consiguen sustituyendo
el menor contribuyente de la solución actual por otro candidato. Presentamos el código para obtener el menor contribuyente.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un conjunto de elementos $S$.}
	\KwIn{La matriz de distancias $D$.}
	\KwOut{El elemento de $S$ que minimiza $\operatorname{contrib}(S,S,e)$ con $e\in S$.}
	\KwOut{Su contribución, para la factorización de la función objetivo.}
	$lowest \gets \text{primer elemento de } S$\;
	$min\_contrib \gets \operatorname{contrib}(S,D,lowest)$\;
	\For{$s$ \textbf{in} $S$} {
		$contrib \gets \operatorname{contrib}(S,D,s)$\;
		\If{$contrib < min\_contrib$} { 
			$min\_contrib \gets contrib$\;
			$lowest \gets s$ \tcp*{Si encuentro un candidato con menor contribución, actualizo}
		}
	}
	\Return{$lowest$}\;
	\Return{$min\_contrib$}\;
	\caption{{\sc lowestContrib} obtiene el elemento de $S$ que menos contribuye en la valoración.}
	\label{alg:lowest-contributor-ls}
\end{algorithm}

En el caso de que $S$ se represente como un conjunto, no sabemos cuál será el primer elemento (depende de la implementación del iterador). Pero
esto no es relevante, ya que vale cualquier elemento de $S$.

Finalmente, proporcionamos el algoritmo de Búsqueda Local para actualizar la solución por otra del entorno iterativamente
hasta encontrar un máximo local (una solución mejor que todas las de su entorno) o llegar a un límite de evaluaciones de la función
objetivo: $LIMIT=100000$. Las soluciones del entorno se generan aleatoriamente.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{El entero $m$.}
	\KwIn{La matriz de distancias $D$, $n\times n$.}
	\KwOut{Una solución válida del MDP por el algoritmo de BS que hemos descrito, junto con su evaluación.}
	$S \gets \operatorname{randomSol}(m,n)$ \tcp*{Comenzamos con una solución aleatoria}
	$E \gets \{0,\ldots,n-1\}\backslash S$ \tcp*{$\operatorname{randomSol}$ también devuelve el complementario}
	$fitness \gets \operatorname{fitness}(S)$ \tcp*{Diversidad de la solución}
	$E \gets \operatorname{vector}(E)$ \tcp*{No importa el orden, pero debe poder barajarse}
	$carryon \gets true$\;
	$LIMIT \gets 100000$ \tcp*{Límite de llamadas a la función de evaluación}
	$CALLS \gets 0$\;
	\While{carryon}{
		$carryon \gets false$\;
		$lowest = \operatorname{lowestContributor}(S,D)$\;
		$min\_contrib \gets \operatorname{contrib}(S,D,lowest)$ \tcp*{Se calcula dentro de $\operatorname{lowestContributor}$}
		$S \gets S\backslash\{lowest\}$\;
		$E \gets \operatorname{shuffle}(E)$\;	
		\For{$e$ \textbf{in} $E$} {
			$contrib \gets \operatorname{contrib}(S,D,e)$\;
			$CALLS \gets CALLS +1$ \tcp*{He evaludado una posible solución}
			\If{$contrib > min\_contrib$} { 
				$fitness \gets fitness + contrib - min\_contrib$ \tcp*{Diversidad de la nueva solución}
				$carryon \gets true$ \tcp*{Toca saltar, lo que completa la iteración}
				$S\gets S\cup\{e\}$ \tcp*{Saltamos a la nueva solución}
				$E \gets E\backslash\{e\}$\;
				$E \gets E\cup\{lowest\}$\;
			}
			\If{$carryon==true$ or $CALLS\geq LIMIT$} { 
				\textbf{break}  \tcp*{Se cumple alguna de las condiciones de parada}
			}
		}
	}
	\If{$|S|<m$} { 
		$S\gets S\cup\{lowest\}$ \tcp*{Si salimos porque no encontramos una mejor, recuperamos la solución}
	}
	\Return{$S$}\;
	\Return{$fitness$}\;
	\caption{{\sc LocalSearch}}
	\label{alg:local-searchls}
\end{algorithm}

Cabe destacar que en este algoritmo se calcula la fitness factorizando. Esto acelera mucho los cálculos, ya que hay que evaluar muchas soluciones diferentes.

\pagebreak

\section{Algoritmo de comparación: Greedy}

Para comparar la eficacia de cada algoritmos, lo compararemos con el algoritmo \textbf{Greedy}. El algoritmo consiste en empezar por el
elemento más lejano al resto e ir añadiendo el elemento que más contribuya hasta completar una solución válida.

Este algoritmo también se implementó en la primera práctica y utiliza un conjunto de enteros.

Como elemento más lejano al resto se toma el elemento cuya suma de las distancias al resto sea la mayor. Y en cada iteración se introduce el elemento
cuya suma de las distancias a los seleccionados sea mayor. Es decir, utilizamos la definición de \eqref{eq:distance-elem-set}.

Para calcular ambos valores, usamos la siguiente función, que permite obtener el de entre
un conjunto de candidatos más lejano (en el sentido que acabamos de comentar) a los elementos de un conjunto dado.
El código para calcularlo es similar al del algoritmo \ref{alg:lowest-contributor}.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{Un conjunto de candidatos $C$.}
	\KwIn{Un conjunto de elementos $S$.}
	\KwIn{La matriz de distancias $D$.}
	\KwOut{El candidato más lejano en el sentido de \eqref{eq:distance-elem-set}.}
	$farthest \gets \text{primer elemento de } C$\;
	$max\_contrib \gets \operatorname{contrib}(S,D,farthest)$\;
	\For{$e$ \textbf{in} $C$} {
		$contrib \gets \operatorname{contrib}(S,D,e)$\;
		\If{$contrib > max\_contrib$} { 
			$max\_contrib \gets contrib$\;
			$farthest \gets e$ \tcp*{Si encuentro un candidato con mayor contribución, actualizo}
		}
	}
	\Return{$farthest$}\;
	\caption{{\sc farthest} obtiene el candidato más lejano a los elementos de $S$.}
	\label{alg:farthest-candidate-set}
\end{algorithm}

En el caso de que $C$ se represente como un conjunto, no sabemos cuál será el primer elemento (depende de la implementación del iterador). Pero
esto no es relevante, ya que vale cualquier elemento de $C$.

Ya estamos en condiciones de proporcionar una descripción del algoritmo Greedy.

\begin{algorithm}[H]
	\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
	\KwIn{La matriz de distancias $D$.}
	\KwIn{El entero $m$.}
	\KwOut{Una solución válida del MDP obtenida como hemos descrito anteriormente, y su diversidad.}
	$C \gets \{0,\ldots, n-1\}$ \tcp*{En principio los $n$ elementos son candidatos}
	$S \gets \emptyset$ \tcp*{La solución empieza vacía}
	$farthest \gets \operatorname{farthest}(C,C,D)$ \tcp*{Elemento más lejano al resto}
	$C \gets C\backslash \{farthest\}$\;
	$S \gets S\cup \{farthest\}$\;
	\While{$|S|<m$}{
		$farthest \gets \operatorname{farthest}(C,S,D)$ \tcp*{Elemento más lejano a los seleccionados}
		$C \gets C\backslash \{farthest\}$\;
		$S \gets S\cup \{farthest\}$\;
	}
	\Return{$S$}\;
	\Return{$\operatorname{fitness}(S)$}\;
	\caption{{\sc Greedy}}
	\label{alg:greedy}
\end{algorithm}

\pagebreak

\section{Desarrollo de la práctica}

La implementación de los algoritmos y la experimentación con los mismos se ha llevado acabo de C++, utilizando la librería STL. 
Para representar la soluciones hemos hecho uso del tipo \texttt{vector}.

La mayoría de operadores (mutación, generación de vecino, salto, búsqueda local) se implementan como métodos de una 
clase Solucion.

En el enfriamiento simulado, se utilizan las funciones exponencial y logaritmo neperiano de la biblioteca \texttt{math.h}.

Para medir los tiempos de ejecución se utiliza la función \texttt{clock} de la librería \texttt{time.h}.

A lo largo de la práctica se utilizan acciones aleatorias. Utilizamos la librería \texttt{stdlib.h} para la generación de
enteros (no negativos) pseudoaleatorios con \texttt{rand} y fijamos la semilla con \texttt{srand}. Se barajan vectores con la función
 \texttt{random\_shuffle} de la librería \texttt{algorithm}.
 
Para las acciones que se realizan con cierta probabilidad, es necesario generar flotantes pseudoaleatorios en el intervalos $[0,1]$.
Para esto, se genera un entero no negativo con \texttt{rand} y se divide entre el máximo posible (RAND\_MAX).

Se almacena la matriz de distancias completa (no sólo un triángulo) por comodidad de los cálculos.

Se utiliza optimización de código \texttt{-O2} al compilar.

\subsection{Manual de usuario}

A continuación detallamos instrucciones para lanzar los ejecutables.

Tenemos los siguientes ejecutables:

\begin{itemize}
\item \textbf{ES:} Enfriamiento Simulado con Cauchy Modificado.
\item \textbf{ES-proporcional:} Enfriamiento Simulado con enfriamiento proporcional.
\item \textbf{BMB:} Búsqueda Multiarranque Básica.
\item \textbf{ILS:} Búsqueda Local Reiterada.
\item \textbf{ILS-ES:} Hibridación de ILS y Enfriamiento Simulado con Cauchy Modificado.
\item \textbf{ILS-ES-proporcional:} Hibridación de ILS y Enfriamiento Simulado con enfriamiento proporcional. 
\end{itemize}

Todos ellos devuelven la evaluación de la solución obtenida y el tiempo de ejecución por salida estándar.
Leen el fichero por entrada estándar, así que es conveniente redirigirla.
Todos los archivos reciben la semilla como parámetro.

Además, todos los archivos de búsqueda local reciben la semilla como parámetro. Ejemplo:
\begin{verbatim}
bin/ES 197 < datos/MDG-a_1_n500_m50.txt >> salidas/ES.txt
\end{verbatim}

En la carpeta \textbf{software} se incluye el script usado para lanzar todas las ejecuciones, \texttt{run.sh}. También se incluye
el \texttt{Makefile} que compila los ejecutables.

\pagebreak

\section{Experimentación y análisis}

Toda la experimentación se realiza en mi ordenador portátil personal, que tiene las siguientes especificaciones:
\begin{itemize}
	\item OS: Ubuntu 20.04.2 LTS x86\_64.
	\item RAM: 8GB, DDR4.
	\item CPU: Intel Core i7-6700HQ, 2.60Hz.
\end{itemize}

\subsection{Casos de estudio y resultados}

Tratamos varios casos con distintos parámetros $n$ y $m$. En cada caso se utiliza una semilla diferente, pero se usa la misma para todos los algoritmos.
A continuación presentamos una tabla con los casos estudiados. Para cada caso indicamos los valores de $n$ y $m$ y la semilla
que se utiliza.

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & $n$ & $m$ & Seed\\ \hline
		MDG-a\_10\_n500\_m50 & 500 & 50 & 13\\
		MDG-a\_1\_n500\_m50 & 500 & 50 & 19\\
		MDG-a\_2\_n500\_m50 & 500 & 50 & 25\\
		MDG-a\_3\_n500\_m50 & 500 & 50 & 31\\
		MDG-a\_4\_n500\_m50 & 500 & 50 & 37\\
		MDG-a\_5\_n500\_m50 & 500 & 50 & 43\\
		MDG-a\_6\_n500\_m50 & 500 & 50 & 49\\
		MDG-a\_7\_n500\_m50 & 500 & 50 & 55\\
		MDG-a\_8\_n500\_m50 & 500 & 50 & 61\\
		MDG-a\_9\_n500\_m50 & 500 & 50 & 67\\
		MDG-b\_21\_n2000\_m200 & 2000 & 200 & 73\\
		MDG-b\_22\_n2000\_m200 & 2000 & 200 & 79\\
		MDG-b\_23\_n2000\_m200 & 2000 & 200 & 85\\
		MDG-b\_24\_n2000\_m200 & 2000 & 200 & 91\\
		MDG-b\_25\_n2000\_m200 & 2000 & 200 & 97\\
		MDG-b\_26\_n2000\_m200 & 2000 & 200 & 103\\
		MDG-b\_27\_n2000\_m200 & 2000 & 200 & 109\\
		MDG-b\_28\_n2000\_m200 & 2000 & 200 & 115\\
		MDG-b\_29\_n2000\_m200 & 2000 & 200 & 121\\
		MDG-b\_30\_n2000\_m200 & 2000 & 200 & 127\\
		MDG-c\_10\_n3000\_m400 & 3000 & 400 & 133\\
		MDG-c\_13\_n3000\_m500 & 3000 & 500 & 139\\
		MDG-c\_14\_n3000\_m500 & 3000 & 500 & 145\\
		MDG-c\_15\_n3000\_m500 & 3000 & 500 & 151\\
		MDG-c\_19\_n3000\_m600 & 3000 & 600 & 157\\
		MDG-c\_1\_n3000\_m300 & 3000 & 300 & 163\\
		MDG-c\_20\_n3000\_m600 & 3000 & 600 & 169\\
		MDG-c\_2\_n3000\_m300 & 3000 & 300 & 175\\
		MDG-c\_8\_n3000\_m400 & 3000 & 400 & 181\\
		MDG-c\_9\_n3000\_m400 & 3000 & 400 & 187\\
		\hline
	\end{tabular}
	\caption{Tabla con los parámetros y semillas de cada caso. Ordenando los nombres de los ficheros por orden alfabético
		(el orden en el que los procesa el script), las semillas son números del 13 al 187 saltando de 6 en 6.}
	\label{tab:param-seed}
\end{table}

Ahora mostraremos para cada algoritmo una tabla con los estadísticos (Desviación y Tiempo) que han obtenido en cada
caso.

\pagebreak

\subsubsection*{Greedy}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7610.42 & 2.85 & 0.001375\\
		MDG-a\_2\_n500\_m50 & 7574.39 & 2.54 & 0.001293\\
		MDG-a\_3\_n500\_m50 & 7535.96 & 2.88 & 0.001304\\
		MDG-a\_4\_n500\_m50 & 7551.52 & 2.81 & 0.001281\\
		MDG-a\_5\_n500\_m50 & 7540.14 & 2.77 & 0.001284\\
		MDG-a\_6\_n500\_m50 & 7623.65 & 1.93 & 0.001278\\
		MDG-a\_7\_n500\_m50 & 7594.62 & 2.28 & 0.0014\\
		MDG-a\_8\_n500\_m50 & 7625.94 & 1.61 & 0.001367\\
		MDG-a\_9\_n500\_m50 & 7547.25 & 2.87 & 0.001351\\
		MDG-a\_10\_n500\_m50 & 7642.27 & 1.77 & 0.001893\\
		MDG-b\_21\_n2000\_m200 & 11099332.620328 & 1.77 & 0.319017\\
		MDG-b\_22\_n2000\_m200 & 11149879.733826 & 1.21 & 0.313017\\
		MDG-b\_23\_n2000\_m200 & 11119613.974858 & 1.6 & 0.303374\\
		MDG-b\_24\_n2000\_m200 & 11106996.970212 & 1.63 & 0.311278\\
		MDG-b\_25\_n2000\_m200 & 11114220.292214 & 1.61 & 0.306411\\
		MDG-b\_26\_n2000\_m200 & 11132801.799043 & 1.41 & 0.306542\\
		MDG-b\_27\_n2000\_m200 & 11130608.965587 & 1.55 & 0.310595\\
		MDG-b\_28\_n2000\_m200 & 11110673.520354 & 1.5 & 0.318429\\
		MDG-b\_29\_n2000\_m200 & 11156328.082493 & 1.25 & 0.306362\\
		MDG-b\_30\_n2000\_m200 & 11109767.818822 & 1.65 & 0.296905\\
		MDG-c\_1\_n3000\_m300 & 24617010 & 1.07 & 1.501668\\
		MDG-c\_2\_n3000\_m300 & 24547293 & 1.44 & 1.464132\\
		MDG-c\_8\_n3000\_m400 & 43056071 & 0.88 & 2.546235\\
		MDG-c\_9\_n3000\_m400 & 42958639 & 1.1 & 2.569214\\
		MDG-c\_10\_n3000\_m400 & 42959794 & 1.19 & 2.566065\\
		MDG-c\_13\_n3000\_m500 & 66493045 & 0.78 & 3.67213\\
		MDG-c\_14\_n3000\_m500 & 66449858 & 0.79 & 3.767131\\
		MDG-c\_15\_n3000\_m500 & 66468837 & 0.78 & 3.78725\\
		MDG-c\_19\_n3000\_m600 & 94929882 & 0.74 & 5.183856\\
		MDG-c\_20\_n3000\_m600 & 94979205 & 0.69 & 5.582157\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo Greedy
		en cada caso de estudio.}
	\label{tab:greedy}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		1.63 & 1.19 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

\subsubsection*{Búsqueda Local}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7623.23 & 2.69 & 0.001809\\
		MDG-a\_2\_n500\_m50 & 7590.18 & 2.34 & 0.001391\\
		MDG-a\_3\_n500\_m50 & 7544.94 & 2.76 & 0.001204\\
		MDG-a\_4\_n500\_m50 & 7576.44 & 2.49 & 0.0012\\
		MDG-a\_5\_n500\_m50 & 7484.27 & 3.49 & 0.001308\\
		MDG-a\_6\_n500\_m50 & 7570.96 & 2.61 & 0.001297\\
		MDG-a\_7\_n500\_m50 & 7654.98 & 1.5 & 0.001608\\
		MDG-a\_8\_n500\_m50 & 7623.78 & 1.64 & 0.002379\\
		MDG-a\_9\_n500\_m50 & 7612.74 & 2.02 & 0.001494\\
		MDG-a\_10\_n500\_m50 & 7619.52 & 2.07 & 0.001959\\
		MDG-b\_21\_n2000\_m200 & 11181874.0007 & 1.04 & 0.099777\\
		MDG-b\_22\_n2000\_m200 & 11167876.184 & 1.05 & 0.092492\\
		MDG-b\_23\_n2000\_m200 & 11176568.0611 & 1.09 & 0.107634\\
		MDG-b\_24\_n2000\_m200 & 11188223.318 & 0.91 & 0.107425\\
		MDG-b\_25\_n2000\_m200 & 11181859.8196 & 1.01 & 0.090053\\
		MDG-b\_26\_n2000\_m200 & 11193478.832 & 0.88 & 0.122694\\
		MDG-b\_27\_n2000\_m200 & 11211629.6839 & 0.83 & 0.112468\\
		MDG-b\_28\_n2000\_m200 & 11151089.4629 & 1.14 & 0.079449\\
		MDG-b\_29\_n2000\_m200 & 11183039.6644 & 1.01 & 0.09833\\
		MDG-b\_30\_n2000\_m200 & 11159590.8213 & 1.21 & 0.090033\\
		MDG-c\_1\_n3000\_m300 & 24729057 & 0.62 & 0.601221\\
		MDG-c\_2\_n3000\_m300 & 24738675 & 0.67 & 0.584432\\
		MDG-c\_8\_n3000\_m400 & 43200330 & 0.55 & 1.264437\\
		MDG-c\_9\_n3000\_m400 & 43157977 & 0.64 & 1.241837\\
		MDG-c\_10\_n3000\_m400 & 43188306 & 0.66 & 1.195051\\
		MDG-c\_13\_n3000\_m500 & 66636142 & 0.56 & 2.304507\\
		MDG-c\_14\_n3000\_m500 & 66727635 & 0.38 & 2.430114\\
		MDG-c\_15\_n3000\_m500 & 66808383 & 0.28 & 2.78715\\
		MDG-c\_19\_n3000\_m600 & 95244690 & 0.41 & 3.572005\\
		MDG-c\_20\_n3000\_m600 & 95324379 & 0.33 & 3.598978\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo de Búsqueda Local
		con Primer Mejor en cada caso de estudio.}
	\label{tab:ls-primer-mejor}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		1.3 & 0.69 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

\subsubsection*{Enfriamiento Simulado (Cauchy Modificado)}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7670.07 & 2.09 & 0.006072\\
		MDG-a\_2\_n500\_m50 & 7605.52 & 2.14 & 0.00734\\
		MDG-a\_3\_n500\_m50 & 7640.15 & 1.54 & 0.004435\\
		MDG-a\_4\_n500\_m50 & 7506.45 & 3.39 & 0.002631\\
		MDG-a\_5\_n500\_m50 & 7595.3 & 2.06 & 0.007672\\
		MDG-a\_6\_n500\_m50 & 7513.32 & 3.35 & 0.002595\\
		MDG-a\_7\_n500\_m50 & 7531.44 & 3.09 & 0.00346\\
		MDG-a\_8\_n500\_m50 & 7609.81 & 1.82 & 0.007511\\
		MDG-a\_9\_n500\_m50 & 7654.97 & 1.48 & 0.006011\\
		MDG-a\_10\_n500\_m50 & 7707.51 & 0.94 & 0.012247\\
		MDG-b\_21\_n2000\_m200 & 11155738.985299 & 1.28 & 0.186285\\
		MDG-b\_22\_n2000\_m200 & 11164122.435074 & 1.09 & 0.184283\\
		MDG-b\_23\_n2000\_m200 & 11177722.312113 & 1.08 & 0.180047\\
		MDG-b\_24\_n2000\_m200 & 11124330.872795 & 1.48 & 0.175191\\
		MDG-b\_25\_n2000\_m200 & 11181796.14402 & 1.01 & 0.175225\\
		MDG-b\_26\_n2000\_m200 & 11157826.838857 & 1.19 & 0.176321\\
		MDG-b\_27\_n2000\_m200 & 11165835.734422 & 1.24 & 0.177808\\
		MDG-b\_28\_n2000\_m200 & 11119034.565327 & 1.43 & 0.174686\\
		MDG-b\_29\_n2000\_m200 & 11163768.720372 & 1.18 & 0.175868\\
		MDG-b\_30\_n2000\_m200 & 11148372.956175 & 1.31 & 0.174758\\
		MDG-c\_1\_n3000\_m300 & 24637456 & 0.99 & 0.418843\\
		MDG-c\_2\_n3000\_m300 & 24595823 & 1.24 & 0.416247\\
		MDG-c\_8\_n3000\_m400 & 43042008 & 0.91 & 0.515977\\
		MDG-c\_9\_n3000\_m400 & 43044732 & 0.91 & 0.51509\\
		MDG-c\_10\_n3000\_m400 & 43031426 & 1.02 & 0.514451\\
		MDG-c\_13\_n3000\_m500 & 66556889 & 0.68 & 0.602169\\
		MDG-c\_14\_n3000\_m500 & 66646003 & 0.5 & 0.598817\\
		MDG-c\_15\_n3000\_m500 & 66693908 & 0.45 & 0.605126\\
		MDG-c\_19\_n3000\_m600 & 95013094 & 0.65 & 0.672743\\
		MDG-c\_20\_n3000\_m600 & 94941193 & 0.73 & 0.664133\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo de Enfriamiento Simulado con Cauchy modificado en cada caso de estudio.}
	\label{tab:es}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		 1.41 & 0.25 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

\subsubsection*{Enfriamiento Simulado (Proporcional)}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7822.51 & 0.14 & 0.017657\\
		MDG-a\_2\_n500\_m50 & 7622.47 & 1.92 & 0.017737\\
		MDG-a\_3\_n500\_m50 & 7687.45 & 0.93 & 0.018346\\
		MDG-a\_4\_n500\_m50 & 7721.95 & 0.62 & 0.018346\\
		MDG-a\_5\_n500\_m50 & 7691.9 & 0.82 & 0.017978\\
		MDG-a\_6\_n500\_m50 & 7725.73 & 0.62 & 0.017659\\
		MDG-a\_7\_n500\_m50 & 7666.35 & 1.36 & 0.018872\\
		MDG-a\_8\_n500\_m50 & 7654.96 & 1.24 & 0.018646\\
		MDG-a\_9\_n500\_m50 & 7700.72 & 0.89 & 0.018478\\
		MDG-a\_10\_n500\_m50 & 7747.54 & 0.42 & 0.01974\\
		MDG-b\_21\_n2000\_m200 & 10162614.655392 & 10.06 & 0.209395\\
		MDG-b\_22\_n2000\_m200 & 10173535.392627 & 9.86 & 0.210087\\
		MDG-b\_23\_n2000\_m200 & 10155768.757838 & 10.13 & 0.210103\\
		MDG-b\_24\_n2000\_m200 & 10153786.637714 & 10.07 & 0.209786\\
		MDG-b\_25\_n2000\_m200 & 10205945.840977 & 9.65 & 0.209136\\
		MDG-b\_26\_n2000\_m200 & 10186840.609219 & 9.79 & 0.209538\\
		MDG-b\_27\_n2000\_m200 & 10178369.828872 & 9.97 & 0.210577\\
		MDG-b\_28\_n2000\_m200 & 10165757.250428 & 9.88 & 0.209549\\
		MDG-b\_29\_n2000\_m200 & 10166804.326253 & 10.01 & 0.20924\\
		MDG-b\_30\_n2000\_m200 & 10167455.620431 & 9.99 & 0.210194\\
		MDG-c\_1\_n3000\_m300 & 22710993 & 8.73 & 0.367478\\
		MDG-c\_2\_n3000\_m300 & 22674638 & 8.96 & 0.365672\\
		MDG-c\_8\_n3000\_m400 & 40198770 & 7.46 & 0.44825\\
		MDG-c\_9\_n3000\_m400 & 40192167 & 7.47 & 0.448765\\
		MDG-c\_10\_n3000\_m400 & 40208739 & 7.52 & 0.459702\\
		MDG-c\_13\_n3000\_m500 & 62739982 & 6.38 & 0.524618\\
		MDG-c\_14\_n3000\_m500 & 62722779 & 6.36 & 0.521154\\
		MDG-c\_15\_n3000\_m500 & 62827242 & 6.22 & 0.519484\\
		MDG-c\_19\_n3000\_m600 & 90250861 & 5.63 & 0.576816\\
		MDG-c\_20\_n3000\_m600 & 90300816 & 5.59 & 0.576425\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo de Enfriamiento Simulado Proporcional en cada caso de estudio.}
	\label{tab:es-proporcional}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		5.96 & 0.24 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

\subsubsection*{Búsqueda Multiarranque Básica}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7728.33 & 1.35 & 0.012555\\
		MDG-a\_2\_n500\_m50 & 7660.38 & 1.43 & 0.012736\\
		MDG-a\_3\_n500\_m50 & 7685.73 & 0.95 & 0.012163\\
		MDG-a\_4\_n500\_m50 & 7670.73 & 1.28 & 0.013113\\
		MDG-a\_5\_n500\_m50 & 7697.13 & 0.75 & 0.01369\\
		MDG-a\_6\_n500\_m50 & 7672.51 & 1.3 & 0.012915\\
		MDG-a\_7\_n500\_m50 & 7671.47 & 1.29 & 0.012711\\
		MDG-a\_8\_n500\_m50 & 7638.95 & 1.44 & 0.012538\\
		MDG-a\_9\_n500\_m50 & 7671.42 & 1.27 & 0.013783\\
		MDG-a\_10\_n500\_m50 & 7691.73 & 1.14 & 0.015372\\
		MDG-b\_21\_n2000\_m200 & 11191731.408656 & 0.96 & 0.548181\\
		MDG-b\_22\_n2000\_m200 & 11173811.056111 & 1 & 0.545127\\
		MDG-b\_23\_n2000\_m200 & 11188292.385945 & 0.99 & 0.536318\\
		MDG-b\_24\_n2000\_m200 & 11171816.301443 & 1.05 & 0.547428\\
		MDG-b\_25\_n2000\_m200 & 11187435.832728 & 0.96 & 0.545627\\
		MDG-b\_26\_n2000\_m200 & 11183285.709461 & 0.97 & 0.539269\\
		MDG-b\_27\_n2000\_m200 & 11187635.60774 & 1.04 & 0.527482\\
		MDG-b\_28\_n2000\_m200 & 11159849.337533 & 1.06 & 0.521256\\
		MDG-b\_29\_n2000\_m200 & 11165563.257994 & 1.17 & 0.519606\\
		MDG-b\_30\_n2000\_m200 & 11175655.345143 & 1.07 & 0.526765\\
		MDG-c\_1\_n3000\_m300 & 24669394 & 0.86 & 2.025703\\
		MDG-c\_2\_n3000\_m300 & 24640413 & 1.06 & 2.012946\\
		MDG-c\_8\_n3000\_m400 & 43103744 & 0.77 & 4.708329\\
		MDG-c\_9\_n3000\_m400 & 43115518 & 0.74 & 4.693528\\
		MDG-c\_10\_n3000\_m400 & 43106298 & 0.85 & 4.674107\\
		MDG-c\_13\_n3000\_m500 & 66572923 & 0.66 & 8.603123\\
		MDG-c\_14\_n3000\_m500 & 66605573 & 0.56 & 8.606731\\
		MDG-c\_15\_n3000\_m500 & 66616585 & 0.56 & 8.536043\\
		MDG-c\_19\_n3000\_m600 & 95117057 & 0.54 & 13.523184\\
		MDG-c\_20\_n3000\_m600 & 95136282 & 0.53 & 13.541991\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo de Búsqueda Multiarranque Básica en cada caso de estudio.}
	\label{tab:bmb}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		0.99 & 2.55 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

\subsubsection*{Búsqueda Local Reiterada}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7709.93 & 1.58 & 0.005458\\
		MDG-a\_2\_n500\_m50 & 7724.48 & 0.61 & 0.005492\\
		MDG-a\_3\_n500\_m50 & 7700.95 & 0.75 & 0.005432\\
		MDG-a\_4\_n500\_m50 & 7698.72 & 0.92 & 0.004801\\
		MDG-a\_5\_n500\_m50 & 7675.08 & 1.03 & 0.005607\\
		MDG-a\_6\_n500\_m50 & 7724.5 & 0.63 & 0.00516\\
		MDG-a\_7\_n500\_m50 & 7684.35 & 1.12 & 0.005209\\
		MDG-a\_8\_n500\_m50 & 7636.8 & 1.47 & 0.004604\\
		MDG-a\_9\_n500\_m50 & 7588.69 & 2.33 & 0.005811\\
		MDG-a\_10\_n500\_m50 & 7639.14 & 1.81 & 0.005155\\
		MDG-b\_21\_n2000\_m200 & 11246174.943997 & 0.48 & 0.279171\\
		MDG-b\_22\_n2000\_m200 & 11234217.903533 & 0.47 & 0.283377\\
		MDG-b\_23\_n2000\_m200 & 11265404.407986 & 0.31 & 0.282715\\
		MDG-b\_24\_n2000\_m200 & 11235595.316972 & 0.49 & 0.278637\\
		MDG-b\_25\_n2000\_m200 & 11238488.875162 & 0.51 & 0.264429\\
		MDG-b\_26\_n2000\_m200 & 11222485.977794 & 0.62 & 0.266735\\
		MDG-b\_27\_n2000\_m200 & 11270651.986493 & 0.31 & 0.271429\\
		MDG-b\_28\_n2000\_m200 & 11206855.439177 & 0.65 & 0.267736\\
		MDG-b\_29\_n2000\_m200 & 11232129.73934 & 0.58 & 0.28129\\
		MDG-b\_30\_n2000\_m200 & 11221257.950393 & 0.67 & 0.268129\\
		MDG-c\_1\_n3000\_m300 & 24799202 & 0.34 & 0.891335\\
		MDG-c\_2\_n3000\_m300 & 24768855 & 0.55 & 0.873298\\
		MDG-c\_8\_n3000\_m400 & 43289507 & 0.34 & 1.848681\\
		MDG-c\_9\_n3000\_m400 & 43310665 & 0.29 & 1.906863\\
		MDG-c\_10\_n3000\_m400 & 43295479 & 0.42 & 1.905886\\
		MDG-c\_13\_n3000\_m500 & 66746057 & 0.4 & 3.34356\\
		MDG-c\_14\_n3000\_m500 & 66829831 & 0.22 & 3.357704\\
		MDG-c\_15\_n3000\_m500 & 66888838 & 0.16 & 3.323805\\
		MDG-c\_19\_n3000\_m600 & 95338561 & 0.31 & 5.247\\
		MDG-c\_20\_n3000\_m600 & 95405963 & 0.25 & 5.039759\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo de Búsqueda Local Reiterada en cada caso de estudio.}
	\label{tab:ils}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		0.69 & 1.02 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

\subsubsection*{Híbrido ILS-ES (Cauchy Modificado)}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7668.88 & 2.11 & 0.018958\\
		MDG-a\_2\_n500\_m50 & 7570.89 & 2.58 & 0.019275\\
		MDG-a\_3\_n500\_m50 & 7629.52 & 1.67 & 0.019115\\
		MDG-a\_4\_n500\_m50 & 7610.35 & 2.06 & 0.019151\\
		MDG-a\_5\_n500\_m50 & 7558.51 & 2.54 & 0.019174\\
		MDG-a\_6\_n500\_m50 & 7611.88 & 2.08 & 0.01904\\
		MDG-a\_7\_n500\_m50 & 7595.01 & 2.27 & 0.018986\\
		MDG-a\_8\_n500\_m50 & 7608.75 & 1.83 & 0.019084\\
		MDG-a\_9\_n500\_m50 & 7637.98 & 1.7 & 0.019134\\
		MDG-a\_10\_n500\_m50 & 7624.97 & 2 & 0.02031\\
		MDG-b\_21\_n2000\_m200 & 11102518.768872 & 1.75 & 0.417906\\
		MDG-b\_22\_n2000\_m200 & 11097704.226095 & 1.68 & 0.434521\\
		MDG-b\_23\_n2000\_m200 & 11107942.10879 & 1.7 & 0.422667\\
		MDG-b\_24\_n2000\_m200 & 11095329.156269 & 1.73 & 0.418913\\
		MDG-b\_25\_n2000\_m200 & 11106612.269199 & 1.68 & 0.407629\\
		MDG-b\_26\_n2000\_m200 & 11115693.739341 & 1.56 & 0.437994\\
		MDG-b\_27\_n2000\_m200 & 11106412.843644 & 1.76 & 0.38352\\
		MDG-b\_28\_n2000\_m200 & 11099474.468795 & 1.6 & 0.377382\\
		MDG-b\_29\_n2000\_m200 & 11090079.958744 & 1.83 & 0.381952\\
		MDG-b\_30\_n2000\_m200 & 11108647.770283 & 1.66 & 0.381864\\
		MDG-c\_1\_n3000\_m300 & 24518332 & 1.47 & 1.087397\\
		MDG-c\_2\_n3000\_m300 & 24539459 & 1.47 & 1.088532\\
		MDG-c\_8\_n3000\_m400 & 42966259 & 1.08 & 1.346259\\
		MDG-c\_9\_n3000\_m400 & 42961477 & 1.1 & 1.343878\\
		MDG-c\_10\_n3000\_m400 & 42931845 & 1.25 & 1.340798\\
		MDG-c\_13\_n3000\_m500 & 66388188 & 0.93 & 1.545965\\
		MDG-c\_14\_n3000\_m500 & 66365061 & 0.92 & 1.549764\\
		MDG-c\_15\_n3000\_m500 & 66443388 & 0.82 & 1.548566\\
		MDG-c\_19\_n3000\_m600 & 94850218 & 0.82 & 1.725036\\
		MDG-c\_20\_n3000\_m600 & 94801190 & 0.88 & 1.74827\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo que combina
		Búsqueda Local Reiterada con Enfriamiento Simulado (con Cauchy Modificado) en cada caso de estudio.}
	\label{tab:ils-es}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		1.62 & 0.62 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

\subsubsection*{Híbrido ILS-ES (Proporcional)}

\begin{table}[H]
	\centering
	\begin{tabular}{|cccc|}
		\hline
		Caso & Coste obtenido & Desv & Tiempo (s)\\ \hline
		MDG-a\_1\_n500\_m50 & 7560.83 & 3.48 & 0.01891\\
		MDG-a\_2\_n500\_m50 & 7563.4 & 2.68 & 0.018826\\
		MDG-a\_3\_n500\_m50 & 7460.16 & 3.86 & 0.019232\\
		MDG-a\_4\_n500\_m50 & 7451.87 & 4.1 & 0.01887\\
		MDG-a\_5\_n500\_m50 & 7436.75 & 4.11 & 0.019018\\
		MDG-a\_6\_n500\_m50 & 7518.25 & 3.29 & 0.018643\\
		MDG-a\_7\_n500\_m50 & 7502.04 & 3.47 & 0.018787\\
		MDG-a\_8\_n500\_m50 & 7495.04 & 3.3 & 0.018996\\
		MDG-a\_9\_n500\_m50 & 7554.54 & 2.77 & 0.018889\\
		MDG-a\_10\_n500\_m50 & 7462.38 & 4.09 & 0.0205\\
		MDG-b\_21\_n2000\_m200 & 10057595.617523 & 10.99 & 0.192389\\
		MDG-b\_22\_n2000\_m200 & 10063542.205813 & 10.84 & 0.192122\\
		MDG-b\_23\_n2000\_m200 & 9993237.92958 & 11.56 & 0.192491\\
		MDG-b\_24\_n2000\_m200 & 10021100.549492 & 11.25 & 0.192892\\
		MDG-b\_25\_n2000\_m200 & 10025313.148476 & 11.25 & 0.192684\\
		MDG-b\_26\_n2000\_m200 & 10051312.29967 & 10.99 & 0.193354\\
		MDG-b\_27\_n2000\_m200 & 10051140.804994 & 11.1 & 0.192243\\
		MDG-b\_28\_n2000\_m200 & 10025336.809131 & 11.12 & 0.193467\\
		MDG-b\_29\_n2000\_m200 & 10047516.382319 & 11.06 & 0.192314\\
		MDG-b\_30\_n2000\_m200 & 9971925.528861 & 11.72 & 0.19205\\
		MDG-c\_1\_n3000\_m300 & 22502085 & 9.57 & 0.405454\\
		MDG-c\_2\_n3000\_m300 & 22535949 & 9.51 & 0.407438\\
		MDG-c\_8\_n3000\_m400 & 40024366 & 7.86 & 0.499524\\
		MDG-c\_9\_n3000\_m400 & 40134952 & 7.6 & 0.497438\\
		MDG-c\_10\_n3000\_m400 & 40082879 & 7.81 & 0.5004\\
		MDG-c\_13\_n3000\_m500 & 62482702 & 6.76 & 0.576292\\
		MDG-c\_14\_n3000\_m500 & 62517590 & 6.66 & 0.571553\\
		MDG-c\_15\_n3000\_m500 & 62559375 & 6.62 & 0.570204\\
		MDG-c\_19\_n3000\_m600 & 90059376 & 5.83 & 0.63464\\
		MDG-c\_20\_n3000\_m600 & 89993465 & 5.91 & 0.633904\\
		\hline
	\end{tabular}
	\caption{Evaluación de las soluciones y estadísticos \emph{Desv} y \emph{Tiempo} obtenidos por el algoritmo que combina
		Búsqueda Local Reiterada con Enfriamiento Simulado (Proporcional) en cada caso de estudio.}
	\label{tab:ils-es-proporcional}
\end{table}

Media de los estadísticos:
\begin{table}[H]
	\centering
	\begin{tabular}{|cc|}
		\hline
		Desv & Tiempo (s)\\ \hline
		7.37 & 0.25 \\
		\hline
	\end{tabular}
\end{table}

\pagebreak

Comparamos los estadísticos medios obtenidos estos algoritmos entre sí y con los obtenidos por los algoritmos
de búsqueda local (con primer mejor) y greedy de la primera práctica.

\begin{table}[H]
	\centering
	\begin{tabular}{|ccc|}
		\hline
		Algoritmo & Desv & Tiempo (s)\\ \hline
		Greedy & 1.63 & 1.19 \\
		BL & 1.3 & 0.69 \\
		ES-CM & 1.41 & 0.25 \\
		ES-prop & 5.96 & 0.24 \\
		BMB & 0.99 & 2.55 \\
		ILS & 0.69 & 1.02 \\
		ILS-ES-CM & 1.62 & 0.62 \\
		ILS-ES-prop & 7.37 & 0.25 \\
		\hline
	\end{tabular}
	\caption{Comparativa de los estadísticos medios obtenidos por los distintos algoritmos.}
	\label{tab:comparativa}
\end{table}

\subsection{Análisis de resultados}

\subsubsection*{Tiempos}

Lo primero que debemos destacar es que los tiempos de estos algoritmos son muy inferiores a los obtenidos por los algoritmos
poblacionales de la práctica anterior (cuyo tiempo medio oscilaba entre 40 y 90 segundos), esto se debe principalmente
a que todos los algoritmos basados en trayectorias utilizan la factorización de la función de fitness. El algoritmo que 
más tiempo consume es BMB, supongo que por tener que generar varias soluciones aleatorias. Sin embargo, su tiempo de cómputo
también es prácticamente despreciable en comparación con los algoritmos poblacionales.

\subsubsection*{Enfriamiento Proporcional vs Cauchy Modificado}
El esquema de enfriamiento de Cauchy Modificado enfría muy rápido al principio. En los ejemplos del grupo MDG-a, la temperatura inicial
ronda los 1400 ó 1500, y tras un enfriamiento es cercana a 0.2, siendo los posteriores enfriamientos más paulatinos. Es por esto
que sospechamos que el Enfriamiento Proporcional, más paulatino, iba a obtener mejores resultados. Ajustamos un coeficiente
de enfriamiento $\alpha=0.9$ a ojo, observando un par de ejecuciones del grupo MDG-a con otras semillas distintas, lo cual
ha resultado ser un fracaso.

Como podemos observar en las Tablas \ref{tab:es} y \ref{tab:es-proporcional}, el enfriamiento proporcional obtiene desviaciones
mucho más bajas en los ejemplos del grupo MDG-a, pero su desempeño es desastroso en los ejemplos de los grupos MDG-b y MDG-c.

Para un grupo de ejemplos concretos, podemos encontrar un coeficiente de modo que el enfriamiento proporcional supere a
Cauchy modificado, al menos en los grupos MDG-a y MDG-c, donde todos los ejemplos tienen los mismos parámetros. Sin embargo,
la gran ventaja del enfriamiento proporcional es que adapta sus parámetros al número de iteraciones esperado (en función
del número de evaluaciones y de la dimensionalidad del problema), mientras que un valor fijo para el enfriamiento proporcional
no produce resultados satisfactorios para los posibles distintos tamaños del problema.

En la Tabla \ref{tab:es-proporcional} observamos que los ejemplos del grupo MDG-b son los peores para el enfriamiento
proporcional. En los ejemplos del grupo MDG-c, la desviación (sin dejar de ser demasiado alta) va decreciendo cuando
mantenemos el parámetro $n$ y vamos incrementando el $m$, lo que parece indicar que su desempeño es peor cuanto menor sea
(en proporción) el subconjunto a seleccionar, al menos para el parámetro $\alpha=0.9$.

En la hibridación de ES con ILS, el número de iteraciones es menor en cada ejecución de ES, por lo que Cauchy modificado
se adapta enfriando aún más rápido mientras que tenemos dificultades para ajustar el parámetro $\alpha=0.5$, con el que ocurre
lo mismo que en el caso anterior, esta vez incluso con resultados peores en los ejemplos del grupo MDG-a (Tablas \ref{tab:ils-es} y \ref{tab:ils-es-proporcional}).

En tiempo no hay mucha diferencia en la ejecución, pero sí que la hay en la inicialización de los parámetros (el esquema
proporcional no requiere inicializar $M$, $T_f$ y $beta$), esto se aprecia al combinarlo con ILS, ya que la inicialización
se realiza 10 veces y el esquema proporcional saca una ventaja de tiempo, que por supuesto no compensa su alta desviación.

Este experimento nos ha servido para apreciar la facilidad de adaptación del esquema de Cauchy modificado a la hora de enfriar.
A partir de ahora, siempre consideraremos este esquema. Ignoraremos los algoritmos ES-prop y ILS-ES-prop por el resto del
análisis.

\subsubsection*{Búsqueda Local vs Enfriamiento Simulado}

Primero los comparamos en sus versiones simples: Tabla \ref{tab:ls-primer-mejor} frente a Tabla \ref{tab:es}.

El algoritmo de Enfriamiento Simulado es bastante más rápido que el de Búsqueda Local, esto se debe principalmente a que ES
busca vecinos aleatorios mientras LS tiene que calcular el menor contribuyente para cada salto. Esto hace que los saltos de
LS produzcan una mayor mejora en la fitness, por lo que sus 100000 iteraciones se invierten en mejorar la solución en mayor
medida que las de ES.

El desempeño de ES es ligeramente peor, pero como acabamos de explicar las iteraciones de LS son más costosas, de modo
que quizá deberíamos haber permitido a ES realizar más iteraciones para que esta comparación fuese más justa.

La cosa cambia cuando los consideramos en combinación con ILS: Tablas \ref{tab:ils} y \ref{tab:ils-es}.

A pesar de que ES sigue siendo ligeramente más rápido, esta diferencia se nota menos en este caso. Probablemente es debido
a que la inicialización de ES es más lenta, y aquí se tiene que inicializar 10 veces en lugar de 1.

Además, aquí si hay una gran mejora de la Búsqueda Local. El ES permite que la solución empeore en sus primeras etapas, y el
número de iteraciones en cada ejecución es demasiado bajo. Aunque el esquema de Cauchy Modificado permite que se adapte para
enfriar más rápido ante un menor número de iteraciones, no tiene suficientes iteraciones para que la fase de explotación
(cuando la temperatura es muy baja) dé sus frutos.

Aun así, ocurre el mismo problema que comentamos antes, puede que esta
comparación no sea justa del todo, ya que una iteración de LS es bastante más costosa por tener que calcular el menor contribuyente. Sin embargo, en esta ocación la diferencia de tiempo no compensa en absoluto la diferencia de desviación.

\subsubsection*{Trayectorias Simples vs Múltiples}

Como hemos comentado antes, todos los algoritmos estudiados en esta práctica son relativamente rápidos. Sin embargo
(ignorando el Greedy, que no es de trayectoria), los algoritmos basados en trayectorias múltiples son algo más lentos
que los basados en trayectorias múltiples: ILS-ES-CM es más lento que ES-CM y ILS y BMB son más lentos que BL. Esto
se debe a que necesitan inicializar la búsqueda 10 veces en lugar de sólo 1, y generar una solución aleatoria lleva tiempo.

TODO

\subsubsection*{ILS vs BMB}

TODO: Es más costoso generar una solución aleatorio nueva que partir de una mutación

\end{document}
